{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdd5eb5",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e3920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import random\n",
    "import torch.optim as opt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import os\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import math\n",
    "import imgviz\n",
    "\n",
    "from thop import profile\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a100e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a30ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IS_Dataset_test(Dataset):\n",
    "  CLASSES = ['background', 'girder', 'net', 'lanyard', 'guardrail']\n",
    "  def __init__(self, data_list, label_list, classes, cm2lbl, transform=None, transform_toTensor=None, resize_size=None):\n",
    "\n",
    "    self.data_list = data_list\n",
    "    self.label_list = label_list\n",
    "    self.transform = transform\n",
    "    self.transform_toTensor = transform_toTensor\n",
    "    self.cm2lbl = cm2lbl\n",
    "    self.resize_size = resize_size\n",
    "    # convert str names to class values on masks\n",
    "    self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "    print('Read ' + str(len(self.data_list)) + ' images')\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    # read data\n",
    "    image = cv2.imread(self.data_list[index])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, self.resize_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "    mask = cv2.imread(self.label_list[index])\n",
    "#     mask = cv2.resize(mask, self.resize_size, interpolation=cv2.INTER_NEAREST)\n",
    "    if self.resize_size:\n",
    "        image = cv2.resize(image, self.resize_size, interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, self.resize_size, interpolation=cv2.INTER_NEAREST)\n",
    "    if image.shape[0] > 1400 or image.shape[1] > 1400 :\n",
    "        ratio = ratioFunction(image.shape[0], image.shape[1])\n",
    "        new_size = (960, int(960*ratio))\n",
    "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "    if image.shape[0]%16 !=0 or image.shape[1]%16 !=0 :\n",
    "        new_size = (960, 720)\n",
    "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "    print(image.shape)\n",
    "    # apply data augmentations\n",
    "    if self.transform:\n",
    "      # ndarray to PIL image\n",
    "      image = Image.fromarray(image)\n",
    "      mask = Image.fromarray(mask)\n",
    "      # apply the transforms\n",
    "      image = self.transform(image)\n",
    "      mask = self.transform(mask)\n",
    "\n",
    "    mask = image2label(mask, self.cm2lbl)\n",
    "    mask = mask.squeeze()\n",
    "    # print(np.unique(mask))\n",
    "    # print(mask.shape)\n",
    "\n",
    "    masks = [(mask == v) for v in self.class_values]\n",
    "    mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "    if self.transform_toTensor:\n",
    "      image = self.transform_toTensor(image)\n",
    "      mask = self.transform_toTensor(mask)\n",
    "\n",
    "    return image, mask\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64ad392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(root_path): \n",
    "  \"\"\" \n",
    "    Args : directory path\n",
    "    Return : list with file path\n",
    "  \"\"\"\n",
    "\n",
    "  for root, dirs, files in os.walk(root_path):\n",
    "    print(\"path：\", root)\n",
    "    print(\"directory：\", dirs)\n",
    "    print(\"file：\", files)\n",
    "    \n",
    "  org_imgs = [(root + \"/\" + file_name) for file_name in tqdm(files)]\n",
    "  org_imgs.sort()\n",
    "  print(\"Read \",len(org_imgs), \" files\")\n",
    "  return org_imgs\n",
    "\n",
    "def make_cm2lbl():\n",
    "\n",
    "  colormap = [[0,0,0], [0,0,128], [0,128,128], [128,0,0], [0,128,0]] # background, grider, net, lanyard, guardrail \n",
    "\n",
    "  cm2lbl = np.zeros(256**3) # for each pixel 0~255 , channel = 3(RGB)\n",
    "  for i,cm in enumerate(colormap):\n",
    "      cm2lbl[(cm[0]*256+cm[1])*256+cm[2]] = i\n",
    "      # print(i)\n",
    "      # print((cm[0]*256+cm[1])*256+cm[2]\n",
    "  return cm2lbl\n",
    "\n",
    "\n",
    "def image2label(img, cm2lbl):\n",
    "  data = np.array(img, dtype='int32')\n",
    "  idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "  # print(np.unique(idx))\n",
    "  # print(cm2lbl[idx])\n",
    "  result = np.array(cm2lbl[idx], dtype='int64')  \n",
    "  return result[:,:,None]\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "  \"\"\"PLot images in one row.\"\"\"\n",
    "  n = len(images)\n",
    "  plt.figure(figsize=(16, 5))\n",
    "  for i, (name, image) in enumerate(images.items()):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(' '.join(name.split('_')).title())\n",
    "    plt.imshow(image)\n",
    "  plt.show()\n",
    "\n",
    "def print_network(net):\n",
    "  num_params = 0\n",
    "  for param in net.parameters():\n",
    "    num_params += param.numel()\n",
    "  print(net)\n",
    "  print('Total number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4791f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ratioFunction(num1, num2):\n",
    "    num1 = int(num1) # Now we are good\n",
    "    num2 = int(num2) # Good, good\n",
    "    if num1 > num2:\n",
    "        ratio12 = num2/num1\n",
    "    else:\n",
    "        ratio12 = num1/num2\n",
    "#     print('The ratio of', num1, 'and', num2,'is', ratio12 + '.')\n",
    "    return ratio12\n",
    "ratioFunction(288, 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d8a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_classes = ['guardrail']\n",
    "classes = ['guardrail']\n",
    "test_features_folder = '/home/user/Desktop/lanyard_segmentation/guardrail/test_data/features'\n",
    "test_labels_folder = '/home/user/Desktop/lanyard_segmentation/guardrail/test_data/labels'\n",
    "orig_features_folder = '/home/user/Desktop/lanyard_segmentation/guardrail/orig_features'\n",
    "orig_labels_folder = '/home/user/Desktop/lanyard_segmentation/guardrail/orig_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6824b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： /home/user/Desktop/lanyard_segmentation/guardrail/test_data/features\n",
      "directory： []\n",
      "file： ['0075.png', '0086.png', '0019.png', '0083.png', '0054.png', '0001.png', '0050.png', '0056.png', '0058.png', '0084.png', '0081.png', '0034.png', '0023.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 181753.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read  13  files\n",
      "path： /home/user/Desktop/lanyard_segmentation/guardrail/test_data/labels\n",
      "directory： []\n",
      "file： ['0075.png', '0086.png', '0019.png', '0083.png', '0054.png', '0001.png', '0050.png', '0056.png', '0058.png', '0084.png', '0081.png', '0034.png', '0023.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 230067.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read  13  files\n",
      "Read 13 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_input_imgs = read_images(test_features_folder)\n",
    "test_output_imgs = read_images(test_labels_folder)\n",
    "\n",
    "transform_toTensor = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "cm2lbl = make_cm2lbl()\n",
    "\n",
    "test_dataset = IS_Dataset_test(\n",
    "      test_input_imgs, \n",
    "      test_output_imgs, \n",
    "#       transform=transform,\n",
    "      transform_toTensor=transform_toTensor,\n",
    "      classes=classes,\n",
    "      cm2lbl=cm2lbl, resize_size=(512,512)\n",
    "   )\n",
    "test_dataloader = DataLoader(test_dataset,2, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de7a61",
   "metadata": {},
   "source": [
    "# EDANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cc03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleBlock(nn.Module):\n",
    "  def __init__(self, nc_input, nc_output):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : Win, number of input channel\n",
    "    nc_output : Wout, number of output channel\n",
    "    '''\n",
    "\n",
    "    super(DownsampleBlock,self).__init__()\n",
    "    self.nc_input = nc_input\n",
    "    self.nc_output = nc_output\n",
    "\n",
    "    if self.nc_input < self.nc_output:\n",
    "      # Win < Wout\n",
    "      self.conv = nn.Conv2d(nc_input, nc_output-nc_input, kernel_size=3, stride=2, padding=1)\n",
    "      self.pool = nn.MaxPool2d(2, stride=2)\n",
    "    else:\n",
    "      # Win > Wout\n",
    "      self.conv = nn.Conv2d(nc_input, nc_output, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    self.batchNorm = nn.BatchNorm2d(nc_output)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.nc_input < self.nc_output:\n",
    "      out = torch.cat([self.conv(x), self.pool(x)], 1)\n",
    "    else:\n",
    "      out = self.conv(x)\n",
    "    \n",
    "    out = self.batchNorm(out)\n",
    "    out = self.relu(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253ff311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDABlock(nn.Module):\n",
    "  def __init__(self, nc_input, dilated, k = 40, dropprob = 0.02):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : number of input channel\n",
    "    k : growth rate\n",
    "    dilated : possible dilated convalution\n",
    "    dropprob : probability, a dropout layer between the last ReLU and the concatenation of each module\n",
    "    '''\n",
    "    super(EDABlock,self).__init__()\n",
    "    self.conv1x1_0 = nn.Conv2d(nc_input, k, kernel_size=1)\n",
    "    self.batchNorm_0 = nn.BatchNorm2d(k)\n",
    "\n",
    "    self.conv3x1_1 = nn.Conv2d(k, k, kernel_size=(3,1), padding=(1,0))\n",
    "    self.conv1x3_1 = nn.Conv2d(k, k, kernel_size=(1,3), padding=(0,1))\n",
    "    self.batchNorm_1 = nn.BatchNorm2d(k)\n",
    "\n",
    "    self.conv3x1_2 = nn.Conv2d(k, k, kernel_size=(3,1), stride=1, padding=(dilated,0), dilation=dilated)\n",
    "    self.conv1x3_2 = nn.Conv2d(k, k, kernel_size=(1,3), stride=1, padding=(0,dilated), dilation=dilated)\n",
    "    self.batchNorm_2 = nn.BatchNorm2d(k)\n",
    "    self.dropout = nn.Dropout2d(dropprob)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    input = x\n",
    "\n",
    "    output = self.conv1x1_0(x)\n",
    "    output = self.batchNorm_0(output)\n",
    "    output = self.relu(output)\n",
    "\n",
    "    output = self.conv3x1_1(output)\n",
    "    output = self.conv1x3_1(output)\n",
    "    output = self.batchNorm_1(output)\n",
    "    output = self.relu(output)\n",
    "\n",
    "    output = self.conv3x1_2(output)\n",
    "    output = self.conv1x3_2(output)\n",
    "    output = self.batchNorm_2(output)\n",
    "    output = self.relu(output)\n",
    "\n",
    "    if (self.dropout.p != 0):\n",
    "      output = self.dropout(output)\n",
    "\n",
    "    output = torch.cat((output, input), 1)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33695a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAnet(nn.Module):\n",
    "  def __init__(self, n_class=1):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : number of input channel\n",
    "    k : growth rate\n",
    "    dilated : possible dilated convalution\n",
    "    dropprob : probability, a dropout layer between the last ReLU and the concatenation of each module\n",
    "    '''\n",
    "    super(EDAnet,self).__init__()\n",
    "    self.layers = nn.ModuleList()\n",
    "    self.dilation1 = [1,1,1,2,2]\n",
    "    self.dilation2 = [2,2,4,4,8,8,16,16]\n",
    "\n",
    "    # DownsampleBlock1\n",
    "    self.layers.append(DownsampleBlock(3, 15))\n",
    "\n",
    "    # DownsampleBlock2\n",
    "    self.layers.append(DownsampleBlock(15, 60))\n",
    "\n",
    "    # EDA module 1-1~1-5\n",
    "    for i in range(len(self.dilation1)):\n",
    "      self.layers.append(EDABlock(60 + 40 * i, self.dilation1[i]))\n",
    "\n",
    "    # DownsampleBlock3\n",
    "    self.layers.append(DownsampleBlock(260, 130))\n",
    "\n",
    "    # EDA module 2-1~2-8\n",
    "    for j in range(len(self.dilation2)):\n",
    "      self.layers.append(EDABlock(130 + 40 * j, self.dilation2[j]))\n",
    "\n",
    "    # Projection layer\n",
    "    self.project_layer = nn.Conv2d(450, n_class, kernel_size = 1)\n",
    "\n",
    "    self.weights_init()\n",
    "  \n",
    "  def weights_init(self):\n",
    "    for index, m in enumerate(self.modules()):\n",
    "      classname = m.__class__.__name__\n",
    "      if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "      elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = x\n",
    "\n",
    "    for layer in self.layers:\n",
    "      output = layer(output)\n",
    "      # print(output.shape)\n",
    "\n",
    "    output = self.project_layer(output)\n",
    "\n",
    "    # Bilinear interpolation x8\n",
    "    output = F.interpolate(output,scale_factor = 8,mode = 'bilinear',align_corners=True)\n",
    "\n",
    "    # # Bilinear interpolation x2 (inference only)\n",
    "    # if not self.training:\n",
    "    #   output = F.interpolate(output, scale_factor=2, mode='bilinear',align_corners=True)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae9d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDAnet(\n",
       "  (layers): ModuleList(\n",
       "    (0): DownsampleBlock(\n",
       "      (conv): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (batchNorm): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): DownsampleBlock(\n",
       "      (conv): Conv2d(15, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (batchNorm): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): EDABlock(\n",
       "      (conv1x1_0): Conv2d(60, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): EDABlock(\n",
       "      (conv1x1_0): Conv2d(100, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): EDABlock(\n",
       "      (conv1x1_0): Conv2d(140, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): EDABlock(\n",
       "      (conv1x1_0): Conv2d(180, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): EDABlock(\n",
       "      (conv1x1_0): Conv2d(220, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): DownsampleBlock(\n",
       "      (conv): Conv2d(260, 130, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batchNorm): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): EDABlock(\n",
       "      (conv1x1_0): Conv2d(130, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): EDABlock(\n",
       "      (conv1x1_0): Conv2d(170, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (10): EDABlock(\n",
       "      (conv1x1_0): Conv2d(210, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (11): EDABlock(\n",
       "      (conv1x1_0): Conv2d(250, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (12): EDABlock(\n",
       "      (conv1x1_0): Conv2d(290, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (13): EDABlock(\n",
       "      (conv1x1_0): Conv2d(330, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (14): EDABlock(\n",
       "      (conv1x1_0): Conv2d(370, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): EDABlock(\n",
       "      (conv1x1_0): Conv2d(410, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batchNorm_0): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_1): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv1x3_1): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (batchNorm_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3x1_2): Conv2d(40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
       "      (conv1x3_2): Conv2d(40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
       "      (batchNorm_2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout2d(p=0.02, inplace=False)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (project_layer): Conv2d(450, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edanet = EDAnet().eval()\n",
    "device = torch.device(\"cuda\")\n",
    "edanet.to(device)\n",
    "\n",
    "# dummy_input = torch.randn(32, 3,512,512, dtype=torch.float).to(device)\n",
    "# repetitions=100\n",
    "# total_time = 0\n",
    "# with torch.no_grad():\n",
    "#     for rep in range(repetitions):\n",
    "#         starter, ender = torch.cuda.Event(enable_timing=True),   torch.cuda.Event(enable_timing=True)\n",
    "#         starter.record()\n",
    "#         _ = edanet(dummy_input)\n",
    "#         ender.record()\n",
    "#         torch.cuda.synchronize()\n",
    "#         curr_time = starter.elapsed_time(ender)/1000\n",
    "#         total_time += curr_time\n",
    "# Throughput =   (repetitions*32)/total_time\n",
    "# print('Final Throughput:',Throughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ea63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0172421932220459\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = edanet(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43a3f5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.DownsampleBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.dropout.Dropout2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.EDABlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.EDAnet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "FLOPs = 4.440788992G\n",
      "Params = 0.681367M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "flops, params = profile(edanet, inputs=(input, ))\n",
    "print('FLOPs = ' + str(flops/1000**3) + 'G')\n",
    "print('Params = ' + str(params/1000**2) + 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78f436f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 131.414617\n",
      "Warning: module DownsampleBlock is treated as a zero-op.\n",
      "Warning: module Dropout2d is treated as a zero-op.\n",
      "Warning: module EDABlock is treated as a zero-op.\n",
      "Warning: module EDAnet is treated as a zero-op.\n",
      "EDAnet(\n",
      "  0.681 M, 100.000% Params, 4.459 GMac, 100.000% MACs, \n",
      "  (layers): ModuleList(\n",
      "    0.681 M, 99.934% Params, 4.457 GMac, 99.959% MACs, \n",
      "    (0): DownsampleBlock(\n",
      "      0.0 M, 0.054% Params, 0.026 GMac, 0.578% MACs, \n",
      "      (conv): Conv2d(0.0 M, 0.049% Params, 0.022 GMac, 0.494% MACs, 3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (pool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.018% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.004% Params, 0.002 GMac, 0.044% MACs, 15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.022% MACs, )\n",
      "    )\n",
      "    (1): DownsampleBlock(\n",
      "      0.006 M, 0.916% Params, 0.104 GMac, 2.337% MACs, \n",
      "      (conv): Conv2d(0.006 M, 0.898% Params, 0.1 GMac, 2.249% MACs, 15, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (pool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.022% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.018% Params, 0.002 GMac, 0.044% MACs, 60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.022% MACs, )\n",
      "    )\n",
      "    (2): EDABlock(\n",
      "      0.022 M, 3.235% Params, 0.363 GMac, 8.143% MACs, \n",
      "      (conv1x1_0): Conv2d(0.002 M, 0.358% Params, 0.04 GMac, 0.897% MACs, 60, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.044% MACs, )\n",
      "    )\n",
      "    (3): EDABlock(\n",
      "      0.024 M, 3.469% Params, 0.389 GMac, 8.731% MACs, \n",
      "      (conv1x1_0): Conv2d(0.004 M, 0.593% Params, 0.066 GMac, 1.485% MACs, 100, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.044% MACs, )\n",
      "    )\n",
      "    (4): EDABlock(\n",
      "      0.025 M, 3.704% Params, 0.415 GMac, 9.319% MACs, \n",
      "      (conv1x1_0): Conv2d(0.006 M, 0.828% Params, 0.092 GMac, 2.072% MACs, 140, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.044% MACs, )\n",
      "    )\n",
      "    (5): EDABlock(\n",
      "      0.027 M, 3.939% Params, 0.442 GMac, 9.906% MACs, \n",
      "      (conv1x1_0): Conv2d(0.007 M, 1.063% Params, 0.119 GMac, 2.660% MACs, 180, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.044% MACs, )\n",
      "    )\n",
      "    (6): EDABlock(\n",
      "      0.028 M, 4.174% Params, 0.468 GMac, 10.494% MACs, \n",
      "      (conv1x1_0): Conv2d(0.009 M, 1.297% Params, 0.145 GMac, 3.248% MACs, 220, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.079 GMac, 1.778% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.001 GMac, 0.029% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.044% MACs, )\n",
      "    )\n",
      "    (7): DownsampleBlock(\n",
      "      0.305 M, 44.703% Params, 1.248 GMac, 27.992% MACs, \n",
      "      (conv): Conv2d(0.304 M, 44.665% Params, 1.247 GMac, 27.957% MACs, 260, 130, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.038% Params, 0.001 GMac, 0.024% MACs, 130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.012% MACs, )\n",
      "    )\n",
      "    (8): EDABlock(\n",
      "      0.025 M, 3.646% Params, 0.102 GMac, 2.293% MACs, \n",
      "      (conv1x1_0): Conv2d(0.005 M, 0.769% Params, 0.021 GMac, 0.481% MACs, 130, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (9): EDABlock(\n",
      "      0.026 M, 3.880% Params, 0.109 GMac, 2.440% MACs, \n",
      "      (conv1x1_0): Conv2d(0.007 M, 1.004% Params, 0.028 GMac, 0.628% MACs, 170, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (10): EDABlock(\n",
      "      0.028 M, 4.115% Params, 0.115 GMac, 2.587% MACs, \n",
      "      (conv1x1_0): Conv2d(0.008 M, 1.239% Params, 0.035 GMac, 0.775% MACs, 210, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (11): EDABlock(\n",
      "      0.03 M, 4.350% Params, 0.122 GMac, 2.734% MACs, \n",
      "      (conv1x1_0): Conv2d(0.01 M, 1.474% Params, 0.041 GMac, 0.922% MACs, 250, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (12): EDABlock(\n",
      "      0.031 M, 4.585% Params, 0.128 GMac, 2.881% MACs, \n",
      "      (conv1x1_0): Conv2d(0.012 M, 1.708% Params, 0.048 GMac, 1.069% MACs, 290, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (13): EDABlock(\n",
      "      0.033 M, 4.820% Params, 0.135 GMac, 3.028% MACs, \n",
      "      (conv1x1_0): Conv2d(0.013 M, 1.943% Params, 0.054 GMac, 1.216% MACs, 330, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (14): EDABlock(\n",
      "      0.034 M, 5.055% Params, 0.142 GMac, 3.175% MACs, \n",
      "      (conv1x1_0): Conv2d(0.015 M, 2.178% Params, 0.061 GMac, 1.363% MACs, 370, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "    (15): EDABlock(\n",
      "      0.036 M, 5.289% Params, 0.148 GMac, 3.322% MACs, \n",
      "      (conv1x1_0): Conv2d(0.016 M, 2.413% Params, 0.067 GMac, 1.510% MACs, 410, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_1): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 0.710% Params, 0.02 GMac, 0.445% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.012% Params, 0.0 GMac, 0.007% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (project_layer): Conv2d(0.0 M, 0.066% Params, 0.002 GMac, 0.041% MACs, 450, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       4.46 GMac\n",
      "Number of parameters:           681.37 k\n"
     ]
    }
   ],
   "source": [
    "edanet = EDAnet().eval().cuda()\n",
    "\n",
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= edanet(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))\n",
    "\n",
    "macs, params = get_model_complexity_info(edanet, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58db646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 12, 256, 256]             336\n",
      "         MaxPool2d-2          [-1, 3, 256, 256]               0\n",
      "       BatchNorm2d-3         [-1, 15, 256, 256]              30\n",
      "              ReLU-4         [-1, 15, 256, 256]               0\n",
      "   DownsampleBlock-5         [-1, 15, 256, 256]               0\n",
      "            Conv2d-6         [-1, 45, 128, 128]           6,120\n",
      "         MaxPool2d-7         [-1, 15, 128, 128]               0\n",
      "       BatchNorm2d-8         [-1, 60, 128, 128]             120\n",
      "              ReLU-9         [-1, 60, 128, 128]               0\n",
      "  DownsampleBlock-10         [-1, 60, 128, 128]               0\n",
      "           Conv2d-11         [-1, 40, 128, 128]           2,440\n",
      "      BatchNorm2d-12         [-1, 40, 128, 128]              80\n",
      "             ReLU-13         [-1, 40, 128, 128]               0\n",
      "           Conv2d-14         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-15         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-16         [-1, 40, 128, 128]              80\n",
      "             ReLU-17         [-1, 40, 128, 128]               0\n",
      "           Conv2d-18         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-19         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-20         [-1, 40, 128, 128]              80\n",
      "             ReLU-21         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-22         [-1, 40, 128, 128]               0\n",
      "         EDABlock-23        [-1, 100, 128, 128]               0\n",
      "           Conv2d-24         [-1, 40, 128, 128]           4,040\n",
      "      BatchNorm2d-25         [-1, 40, 128, 128]              80\n",
      "             ReLU-26         [-1, 40, 128, 128]               0\n",
      "           Conv2d-27         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-28         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-29         [-1, 40, 128, 128]              80\n",
      "             ReLU-30         [-1, 40, 128, 128]               0\n",
      "           Conv2d-31         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-32         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-33         [-1, 40, 128, 128]              80\n",
      "             ReLU-34         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-35         [-1, 40, 128, 128]               0\n",
      "         EDABlock-36        [-1, 140, 128, 128]               0\n",
      "           Conv2d-37         [-1, 40, 128, 128]           5,640\n",
      "      BatchNorm2d-38         [-1, 40, 128, 128]              80\n",
      "             ReLU-39         [-1, 40, 128, 128]               0\n",
      "           Conv2d-40         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-41         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-42         [-1, 40, 128, 128]              80\n",
      "             ReLU-43         [-1, 40, 128, 128]               0\n",
      "           Conv2d-44         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-45         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-46         [-1, 40, 128, 128]              80\n",
      "             ReLU-47         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-48         [-1, 40, 128, 128]               0\n",
      "         EDABlock-49        [-1, 180, 128, 128]               0\n",
      "           Conv2d-50         [-1, 40, 128, 128]           7,240\n",
      "      BatchNorm2d-51         [-1, 40, 128, 128]              80\n",
      "             ReLU-52         [-1, 40, 128, 128]               0\n",
      "           Conv2d-53         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-54         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-55         [-1, 40, 128, 128]              80\n",
      "             ReLU-56         [-1, 40, 128, 128]               0\n",
      "           Conv2d-57         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-58         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-59         [-1, 40, 128, 128]              80\n",
      "             ReLU-60         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-61         [-1, 40, 128, 128]               0\n",
      "         EDABlock-62        [-1, 220, 128, 128]               0\n",
      "           Conv2d-63         [-1, 40, 128, 128]           8,840\n",
      "      BatchNorm2d-64         [-1, 40, 128, 128]              80\n",
      "             ReLU-65         [-1, 40, 128, 128]               0\n",
      "           Conv2d-66         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-67         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-68         [-1, 40, 128, 128]              80\n",
      "             ReLU-69         [-1, 40, 128, 128]               0\n",
      "           Conv2d-70         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-71         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-72         [-1, 40, 128, 128]              80\n",
      "             ReLU-73         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-74         [-1, 40, 128, 128]               0\n",
      "         EDABlock-75        [-1, 260, 128, 128]               0\n",
      "           Conv2d-76          [-1, 130, 64, 64]         304,330\n",
      "      BatchNorm2d-77          [-1, 130, 64, 64]             260\n",
      "             ReLU-78          [-1, 130, 64, 64]               0\n",
      "  DownsampleBlock-79          [-1, 130, 64, 64]               0\n",
      "           Conv2d-80           [-1, 40, 64, 64]           5,240\n",
      "      BatchNorm2d-81           [-1, 40, 64, 64]              80\n",
      "             ReLU-82           [-1, 40, 64, 64]               0\n",
      "           Conv2d-83           [-1, 40, 64, 64]           4,840\n",
      "           Conv2d-84           [-1, 40, 64, 64]           4,840\n",
      "      BatchNorm2d-85           [-1, 40, 64, 64]              80\n",
      "             ReLU-86           [-1, 40, 64, 64]               0\n",
      "           Conv2d-87           [-1, 40, 64, 64]           4,840\n",
      "           Conv2d-88           [-1, 40, 64, 64]           4,840\n",
      "      BatchNorm2d-89           [-1, 40, 64, 64]              80\n",
      "             ReLU-90           [-1, 40, 64, 64]               0\n",
      "        Dropout2d-91           [-1, 40, 64, 64]               0\n",
      "         EDABlock-92          [-1, 170, 64, 64]               0\n",
      "           Conv2d-93           [-1, 40, 64, 64]           6,840\n",
      "      BatchNorm2d-94           [-1, 40, 64, 64]              80\n",
      "             ReLU-95           [-1, 40, 64, 64]               0\n",
      "           Conv2d-96           [-1, 40, 64, 64]           4,840\n",
      "           Conv2d-97           [-1, 40, 64, 64]           4,840\n",
      "      BatchNorm2d-98           [-1, 40, 64, 64]              80\n",
      "             ReLU-99           [-1, 40, 64, 64]               0\n",
      "          Conv2d-100           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-101           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-102           [-1, 40, 64, 64]              80\n",
      "            ReLU-103           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-104           [-1, 40, 64, 64]               0\n",
      "        EDABlock-105          [-1, 210, 64, 64]               0\n",
      "          Conv2d-106           [-1, 40, 64, 64]           8,440\n",
      "     BatchNorm2d-107           [-1, 40, 64, 64]              80\n",
      "            ReLU-108           [-1, 40, 64, 64]               0\n",
      "          Conv2d-109           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-110           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-111           [-1, 40, 64, 64]              80\n",
      "            ReLU-112           [-1, 40, 64, 64]               0\n",
      "          Conv2d-113           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-114           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-115           [-1, 40, 64, 64]              80\n",
      "            ReLU-116           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-117           [-1, 40, 64, 64]               0\n",
      "        EDABlock-118          [-1, 250, 64, 64]               0\n",
      "          Conv2d-119           [-1, 40, 64, 64]          10,040\n",
      "     BatchNorm2d-120           [-1, 40, 64, 64]              80\n",
      "            ReLU-121           [-1, 40, 64, 64]               0\n",
      "          Conv2d-122           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-123           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-124           [-1, 40, 64, 64]              80\n",
      "            ReLU-125           [-1, 40, 64, 64]               0\n",
      "          Conv2d-126           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-127           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-128           [-1, 40, 64, 64]              80\n",
      "            ReLU-129           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-130           [-1, 40, 64, 64]               0\n",
      "        EDABlock-131          [-1, 290, 64, 64]               0\n",
      "          Conv2d-132           [-1, 40, 64, 64]          11,640\n",
      "     BatchNorm2d-133           [-1, 40, 64, 64]              80\n",
      "            ReLU-134           [-1, 40, 64, 64]               0\n",
      "          Conv2d-135           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-136           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-137           [-1, 40, 64, 64]              80\n",
      "            ReLU-138           [-1, 40, 64, 64]               0\n",
      "          Conv2d-139           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-140           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-141           [-1, 40, 64, 64]              80\n",
      "            ReLU-142           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-143           [-1, 40, 64, 64]               0\n",
      "        EDABlock-144          [-1, 330, 64, 64]               0\n",
      "          Conv2d-145           [-1, 40, 64, 64]          13,240\n",
      "     BatchNorm2d-146           [-1, 40, 64, 64]              80\n",
      "            ReLU-147           [-1, 40, 64, 64]               0\n",
      "          Conv2d-148           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-149           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-150           [-1, 40, 64, 64]              80\n",
      "            ReLU-151           [-1, 40, 64, 64]               0\n",
      "          Conv2d-152           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-153           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-154           [-1, 40, 64, 64]              80\n",
      "            ReLU-155           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-156           [-1, 40, 64, 64]               0\n",
      "        EDABlock-157          [-1, 370, 64, 64]               0\n",
      "          Conv2d-158           [-1, 40, 64, 64]          14,840\n",
      "     BatchNorm2d-159           [-1, 40, 64, 64]              80\n",
      "            ReLU-160           [-1, 40, 64, 64]               0\n",
      "          Conv2d-161           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-162           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-163           [-1, 40, 64, 64]              80\n",
      "            ReLU-164           [-1, 40, 64, 64]               0\n",
      "          Conv2d-165           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-166           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-167           [-1, 40, 64, 64]              80\n",
      "            ReLU-168           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-169           [-1, 40, 64, 64]               0\n",
      "        EDABlock-170          [-1, 410, 64, 64]               0\n",
      "          Conv2d-171           [-1, 40, 64, 64]          16,440\n",
      "     BatchNorm2d-172           [-1, 40, 64, 64]              80\n",
      "            ReLU-173           [-1, 40, 64, 64]               0\n",
      "          Conv2d-174           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-175           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-176           [-1, 40, 64, 64]              80\n",
      "            ReLU-177           [-1, 40, 64, 64]               0\n",
      "          Conv2d-178           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-179           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-180           [-1, 40, 64, 64]              80\n",
      "            ReLU-181           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-182           [-1, 40, 64, 64]               0\n",
      "        EDABlock-183          [-1, 450, 64, 64]               0\n",
      "          Conv2d-184            [-1, 1, 64, 64]             451\n",
      "================================================================\n",
      "Total params: 681,367\n",
      "Trainable params: 681,367\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 686.28\n",
      "Params size (MB): 2.60\n",
      "Estimated Total Size (MB): 691.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "edanet = EDAnet().eval().cuda()\n",
    "summary(edanet,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a3a6f",
   "metadata": {},
   "source": [
    "# EDANet ghost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba43f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True, dilated=None):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.oup = oup\n",
    "        init_channels = math.ceil(oup / ratio)\n",
    "        new_channels = init_channels*(ratio-1)\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(init_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "        self.cheap_operation = nn.Sequential(\n",
    "            nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "            nn.BatchNorm2d(new_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = torch.cat([x1,x2], dim=1)\n",
    "        return out[:,:self.oup,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91d5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleBlock(nn.Module):\n",
    "  def __init__(self, nc_input, nc_output):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : Win, number of input channel\n",
    "    nc_output : Wout, number of output channel\n",
    "    '''\n",
    "\n",
    "    super(DownsampleBlock,self).__init__()\n",
    "    self.nc_input = nc_input\n",
    "    self.nc_output = nc_output\n",
    "\n",
    "    if self.nc_input < self.nc_output:\n",
    "      # Win < Wout\n",
    "      self.conv = GhostModule(nc_input, nc_output-nc_input, kernel_size=3, stride=2, relu=True)\n",
    "      # self.conv = nn.Conv2d(nc_input, nc_output-nc_input, kernel_size=3, stride=2, padding=1)\n",
    "      self.pool = nn.MaxPool2d(2, stride=2)\n",
    "    else:\n",
    "      # Win > Wout\n",
    "      self.conv = GhostModule(nc_input, nc_output, kernel_size=3, stride=2, relu=True)\n",
    "      # self.conv = nn.Conv2d(nc_input, nc_output, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    self.batchNorm = nn.BatchNorm2d(nc_output)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.nc_input < self.nc_output:\n",
    "      out = torch.cat([self.conv(x), self.pool(x)], 1)\n",
    "    else:\n",
    "      out = self.conv(x)\n",
    "    \n",
    "    # out = self.batchNorm(out)\n",
    "    # out = self.relu(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f57eb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDABlock_ghost(nn.Module):\n",
    "  def __init__(self, nc_input, dilated, k = 40, dropprob = 0.02):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : number of input channel\n",
    "    k : growth rate\n",
    "    dilated : possible dilated convalution\n",
    "    dropprob : probability, a dropout layer between the last ReLU and the concatenation of each module\n",
    "    '''\n",
    "    # GhostModule(inp, hidden_dim, kernel_size=1, relu=True)\n",
    "    super(EDABlock_ghost,self).__init__()\n",
    "    # self.conv1x1_0 = nn.Conv2d(nc_input, k, kernel_size=1)\n",
    "    self.conv_0 = GhostModule(nc_input, k, kernel_size=1, relu=True)\n",
    "    self.batchNorm_0 = nn.BatchNorm2d(k)\n",
    "\n",
    "    # self.conv3x1_1 = nn.Conv2d(k, k, kernel_size=(3,1), padding=(1,0))\n",
    "    # self.conv1x3_1 = nn.Conv2d(k, k, kernel_size=(1,3), padding=(0,1))\n",
    "    self.conv_1 = GhostModule(k, k, kernel_size=3, relu=True)\n",
    "    self.batchNorm_1 = nn.BatchNorm2d(k)\n",
    "\n",
    "    self.conv3x1_2 = nn.Conv2d(k, k, kernel_size=(3,1), stride=1, padding=(dilated,0), dilation=dilated)\n",
    "    self.conv1x3_2 = nn.Conv2d(k, k, kernel_size=(1,3), stride=1, padding=(0,dilated), dilation=dilated)\n",
    "    self.batchNorm_2 = nn.BatchNorm2d(k)\n",
    "    self.dropout = nn.Dropout2d(dropprob)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    input = x\n",
    "\n",
    "    output = self.conv_0(x)\n",
    "    # output = self.conv1x1_0(x)\n",
    "    # output = self.batchNorm_0(output)\n",
    "    # output = self.relu(output)\n",
    "\n",
    "    output = self.conv_1(output)\n",
    "    # output = self.conv3x1_1(output)\n",
    "    # output = self.conv1x3_1(output)\n",
    "    # output = self.batchNorm_1(output)\n",
    "    # output = self.relu(output)\n",
    "\n",
    "    output = self.conv3x1_2(output)\n",
    "    output = self.conv1x3_2(output)\n",
    "    output = self.batchNorm_2(output)\n",
    "    output = self.relu(output)\n",
    "\n",
    "    if (self.dropout.p != 0):\n",
    "      output = self.dropout(output)\n",
    "\n",
    "    output = torch.cat((output, input), 1)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c32b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAnet_ghost(nn.Module):\n",
    "  def __init__(self, n_class=1):\n",
    "    '''\n",
    "    Arguments:\n",
    "    nc_input : number of input channel\n",
    "    k : growth rate\n",
    "    dilated : possible dilated convalution\n",
    "    dropprob : probability, a dropout layer between the last ReLU and the concatenation of each module\n",
    "    '''\n",
    "    super(EDAnet_ghost,self).__init__()\n",
    "    self.layers = nn.ModuleList()\n",
    "    self.dilation1 = [1,1,1,2,2]\n",
    "    self.dilation2 = [2,2,4,4,8,8,16,16]\n",
    "\n",
    "    # DownsampleBlock1\n",
    "    self.layers.append(DownsampleBlock(3, 15))\n",
    "\n",
    "    # DownsampleBlock2\n",
    "    self.layers.append(DownsampleBlock(15, 60))\n",
    "\n",
    "    # EDA module 1-1~1-5\n",
    "    for i in range(len(self.dilation1)):\n",
    "      self.layers.append(EDABlock_ghost(60 + 40 * i, self.dilation1[i]))\n",
    "\n",
    "    # DownsampleBlock3\n",
    "    self.layers.append(DownsampleBlock(260, 130))\n",
    "\n",
    "    # EDA module 2-1~2-8\n",
    "    for j in range(len(self.dilation2)):\n",
    "      self.layers.append(EDABlock_ghost(130 + 40 * j, self.dilation2[j]))\n",
    "\n",
    "    # Projection layer\n",
    "    self.project_layer = nn.Conv2d(450, n_class, kernel_size = 1)\n",
    "\n",
    "    self.weights_init()\n",
    "  \n",
    "  def weights_init(self):\n",
    "    for index, m in enumerate(self.modules()):\n",
    "      classname = m.__class__.__name__\n",
    "      if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "      elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = x\n",
    "\n",
    "    for layer in self.layers:\n",
    "      output = layer(output)\n",
    "      # print(output.shape)\n",
    "\n",
    "    output = self.project_layer(output)\n",
    "\n",
    "    # Bilinear interpolation x8\n",
    "    output = F.interpolate(output,scale_factor = 8,mode = 'bilinear',align_corners=True)\n",
    "\n",
    "    # # Bilinear interpolation x2 (inference only)\n",
    "    # if not self.training:\n",
    "    #   output = F.interpolate(output, scale_factor=2, mode='bilinear',align_corners=True)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b5f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 256, 256]             162\n",
      "       BatchNorm2d-2          [-1, 6, 256, 256]              12\n",
      "              ReLU-3          [-1, 6, 256, 256]               0\n",
      "            Conv2d-4          [-1, 6, 256, 256]              54\n",
      "       BatchNorm2d-5          [-1, 6, 256, 256]              12\n",
      "              ReLU-6          [-1, 6, 256, 256]               0\n",
      "       GhostModule-7         [-1, 12, 256, 256]               0\n",
      "         MaxPool2d-8          [-1, 3, 256, 256]               0\n",
      "   DownsampleBlock-9         [-1, 15, 256, 256]               0\n",
      "           Conv2d-10         [-1, 23, 128, 128]           3,105\n",
      "      BatchNorm2d-11         [-1, 23, 128, 128]              46\n",
      "             ReLU-12         [-1, 23, 128, 128]               0\n",
      "           Conv2d-13         [-1, 23, 128, 128]             207\n",
      "      BatchNorm2d-14         [-1, 23, 128, 128]              46\n",
      "             ReLU-15         [-1, 23, 128, 128]               0\n",
      "      GhostModule-16         [-1, 45, 128, 128]               0\n",
      "        MaxPool2d-17         [-1, 15, 128, 128]               0\n",
      "  DownsampleBlock-18         [-1, 60, 128, 128]               0\n",
      "           Conv2d-19         [-1, 20, 128, 128]           1,200\n",
      "      BatchNorm2d-20         [-1, 20, 128, 128]              40\n",
      "             ReLU-21         [-1, 20, 128, 128]               0\n",
      "           Conv2d-22         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-23         [-1, 20, 128, 128]              40\n",
      "             ReLU-24         [-1, 20, 128, 128]               0\n",
      "      GhostModule-25         [-1, 40, 128, 128]               0\n",
      "           Conv2d-26         [-1, 20, 128, 128]           7,200\n",
      "      BatchNorm2d-27         [-1, 20, 128, 128]              40\n",
      "             ReLU-28         [-1, 20, 128, 128]               0\n",
      "           Conv2d-29         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-30         [-1, 20, 128, 128]              40\n",
      "             ReLU-31         [-1, 20, 128, 128]               0\n",
      "      GhostModule-32         [-1, 40, 128, 128]               0\n",
      "           Conv2d-33         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-34         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-35         [-1, 40, 128, 128]              80\n",
      "             ReLU-36         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-37         [-1, 40, 128, 128]               0\n",
      "   EDABlock_ghost-38        [-1, 100, 128, 128]               0\n",
      "           Conv2d-39         [-1, 20, 128, 128]           2,000\n",
      "      BatchNorm2d-40         [-1, 20, 128, 128]              40\n",
      "             ReLU-41         [-1, 20, 128, 128]               0\n",
      "           Conv2d-42         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-43         [-1, 20, 128, 128]              40\n",
      "             ReLU-44         [-1, 20, 128, 128]               0\n",
      "      GhostModule-45         [-1, 40, 128, 128]               0\n",
      "           Conv2d-46         [-1, 20, 128, 128]           7,200\n",
      "      BatchNorm2d-47         [-1, 20, 128, 128]              40\n",
      "             ReLU-48         [-1, 20, 128, 128]               0\n",
      "           Conv2d-49         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-50         [-1, 20, 128, 128]              40\n",
      "             ReLU-51         [-1, 20, 128, 128]               0\n",
      "      GhostModule-52         [-1, 40, 128, 128]               0\n",
      "           Conv2d-53         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-54         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-55         [-1, 40, 128, 128]              80\n",
      "             ReLU-56         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-57         [-1, 40, 128, 128]               0\n",
      "   EDABlock_ghost-58        [-1, 140, 128, 128]               0\n",
      "           Conv2d-59         [-1, 20, 128, 128]           2,800\n",
      "      BatchNorm2d-60         [-1, 20, 128, 128]              40\n",
      "             ReLU-61         [-1, 20, 128, 128]               0\n",
      "           Conv2d-62         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-63         [-1, 20, 128, 128]              40\n",
      "             ReLU-64         [-1, 20, 128, 128]               0\n",
      "      GhostModule-65         [-1, 40, 128, 128]               0\n",
      "           Conv2d-66         [-1, 20, 128, 128]           7,200\n",
      "      BatchNorm2d-67         [-1, 20, 128, 128]              40\n",
      "             ReLU-68         [-1, 20, 128, 128]               0\n",
      "           Conv2d-69         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-70         [-1, 20, 128, 128]              40\n",
      "             ReLU-71         [-1, 20, 128, 128]               0\n",
      "      GhostModule-72         [-1, 40, 128, 128]               0\n",
      "           Conv2d-73         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-74         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-75         [-1, 40, 128, 128]              80\n",
      "             ReLU-76         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-77         [-1, 40, 128, 128]               0\n",
      "   EDABlock_ghost-78        [-1, 180, 128, 128]               0\n",
      "           Conv2d-79         [-1, 20, 128, 128]           3,600\n",
      "      BatchNorm2d-80         [-1, 20, 128, 128]              40\n",
      "             ReLU-81         [-1, 20, 128, 128]               0\n",
      "           Conv2d-82         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-83         [-1, 20, 128, 128]              40\n",
      "             ReLU-84         [-1, 20, 128, 128]               0\n",
      "      GhostModule-85         [-1, 40, 128, 128]               0\n",
      "           Conv2d-86         [-1, 20, 128, 128]           7,200\n",
      "      BatchNorm2d-87         [-1, 20, 128, 128]              40\n",
      "             ReLU-88         [-1, 20, 128, 128]               0\n",
      "           Conv2d-89         [-1, 20, 128, 128]             180\n",
      "      BatchNorm2d-90         [-1, 20, 128, 128]              40\n",
      "             ReLU-91         [-1, 20, 128, 128]               0\n",
      "      GhostModule-92         [-1, 40, 128, 128]               0\n",
      "           Conv2d-93         [-1, 40, 128, 128]           4,840\n",
      "           Conv2d-94         [-1, 40, 128, 128]           4,840\n",
      "      BatchNorm2d-95         [-1, 40, 128, 128]              80\n",
      "             ReLU-96         [-1, 40, 128, 128]               0\n",
      "        Dropout2d-97         [-1, 40, 128, 128]               0\n",
      "   EDABlock_ghost-98        [-1, 220, 128, 128]               0\n",
      "           Conv2d-99         [-1, 20, 128, 128]           4,400\n",
      "     BatchNorm2d-100         [-1, 20, 128, 128]              40\n",
      "            ReLU-101         [-1, 20, 128, 128]               0\n",
      "          Conv2d-102         [-1, 20, 128, 128]             180\n",
      "     BatchNorm2d-103         [-1, 20, 128, 128]              40\n",
      "            ReLU-104         [-1, 20, 128, 128]               0\n",
      "     GhostModule-105         [-1, 40, 128, 128]               0\n",
      "          Conv2d-106         [-1, 20, 128, 128]           7,200\n",
      "     BatchNorm2d-107         [-1, 20, 128, 128]              40\n",
      "            ReLU-108         [-1, 20, 128, 128]               0\n",
      "          Conv2d-109         [-1, 20, 128, 128]             180\n",
      "     BatchNorm2d-110         [-1, 20, 128, 128]              40\n",
      "            ReLU-111         [-1, 20, 128, 128]               0\n",
      "     GhostModule-112         [-1, 40, 128, 128]               0\n",
      "          Conv2d-113         [-1, 40, 128, 128]           4,840\n",
      "          Conv2d-114         [-1, 40, 128, 128]           4,840\n",
      "     BatchNorm2d-115         [-1, 40, 128, 128]              80\n",
      "            ReLU-116         [-1, 40, 128, 128]               0\n",
      "       Dropout2d-117         [-1, 40, 128, 128]               0\n",
      "  EDABlock_ghost-118        [-1, 260, 128, 128]               0\n",
      "          Conv2d-119           [-1, 65, 64, 64]         152,100\n",
      "     BatchNorm2d-120           [-1, 65, 64, 64]             130\n",
      "            ReLU-121           [-1, 65, 64, 64]               0\n",
      "          Conv2d-122           [-1, 65, 64, 64]             585\n",
      "     BatchNorm2d-123           [-1, 65, 64, 64]             130\n",
      "            ReLU-124           [-1, 65, 64, 64]               0\n",
      "     GhostModule-125          [-1, 130, 64, 64]               0\n",
      " DownsampleBlock-126          [-1, 130, 64, 64]               0\n",
      "          Conv2d-127           [-1, 20, 64, 64]           2,600\n",
      "     BatchNorm2d-128           [-1, 20, 64, 64]              40\n",
      "            ReLU-129           [-1, 20, 64, 64]               0\n",
      "          Conv2d-130           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-131           [-1, 20, 64, 64]              40\n",
      "            ReLU-132           [-1, 20, 64, 64]               0\n",
      "     GhostModule-133           [-1, 40, 64, 64]               0\n",
      "          Conv2d-134           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-135           [-1, 20, 64, 64]              40\n",
      "            ReLU-136           [-1, 20, 64, 64]               0\n",
      "          Conv2d-137           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-138           [-1, 20, 64, 64]              40\n",
      "            ReLU-139           [-1, 20, 64, 64]               0\n",
      "     GhostModule-140           [-1, 40, 64, 64]               0\n",
      "          Conv2d-141           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-142           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-143           [-1, 40, 64, 64]              80\n",
      "            ReLU-144           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-145           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-146          [-1, 170, 64, 64]               0\n",
      "          Conv2d-147           [-1, 20, 64, 64]           3,400\n",
      "     BatchNorm2d-148           [-1, 20, 64, 64]              40\n",
      "            ReLU-149           [-1, 20, 64, 64]               0\n",
      "          Conv2d-150           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-151           [-1, 20, 64, 64]              40\n",
      "            ReLU-152           [-1, 20, 64, 64]               0\n",
      "     GhostModule-153           [-1, 40, 64, 64]               0\n",
      "          Conv2d-154           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-155           [-1, 20, 64, 64]              40\n",
      "            ReLU-156           [-1, 20, 64, 64]               0\n",
      "          Conv2d-157           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-158           [-1, 20, 64, 64]              40\n",
      "            ReLU-159           [-1, 20, 64, 64]               0\n",
      "     GhostModule-160           [-1, 40, 64, 64]               0\n",
      "          Conv2d-161           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-162           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-163           [-1, 40, 64, 64]              80\n",
      "            ReLU-164           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-165           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-166          [-1, 210, 64, 64]               0\n",
      "          Conv2d-167           [-1, 20, 64, 64]           4,200\n",
      "     BatchNorm2d-168           [-1, 20, 64, 64]              40\n",
      "            ReLU-169           [-1, 20, 64, 64]               0\n",
      "          Conv2d-170           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-171           [-1, 20, 64, 64]              40\n",
      "            ReLU-172           [-1, 20, 64, 64]               0\n",
      "     GhostModule-173           [-1, 40, 64, 64]               0\n",
      "          Conv2d-174           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-175           [-1, 20, 64, 64]              40\n",
      "            ReLU-176           [-1, 20, 64, 64]               0\n",
      "          Conv2d-177           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-178           [-1, 20, 64, 64]              40\n",
      "            ReLU-179           [-1, 20, 64, 64]               0\n",
      "     GhostModule-180           [-1, 40, 64, 64]               0\n",
      "          Conv2d-181           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-182           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-183           [-1, 40, 64, 64]              80\n",
      "            ReLU-184           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-185           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-186          [-1, 250, 64, 64]               0\n",
      "          Conv2d-187           [-1, 20, 64, 64]           5,000\n",
      "     BatchNorm2d-188           [-1, 20, 64, 64]              40\n",
      "            ReLU-189           [-1, 20, 64, 64]               0\n",
      "          Conv2d-190           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-191           [-1, 20, 64, 64]              40\n",
      "            ReLU-192           [-1, 20, 64, 64]               0\n",
      "     GhostModule-193           [-1, 40, 64, 64]               0\n",
      "          Conv2d-194           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-195           [-1, 20, 64, 64]              40\n",
      "            ReLU-196           [-1, 20, 64, 64]               0\n",
      "          Conv2d-197           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-198           [-1, 20, 64, 64]              40\n",
      "            ReLU-199           [-1, 20, 64, 64]               0\n",
      "     GhostModule-200           [-1, 40, 64, 64]               0\n",
      "          Conv2d-201           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-202           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-203           [-1, 40, 64, 64]              80\n",
      "            ReLU-204           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-205           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-206          [-1, 290, 64, 64]               0\n",
      "          Conv2d-207           [-1, 20, 64, 64]           5,800\n",
      "     BatchNorm2d-208           [-1, 20, 64, 64]              40\n",
      "            ReLU-209           [-1, 20, 64, 64]               0\n",
      "          Conv2d-210           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-211           [-1, 20, 64, 64]              40\n",
      "            ReLU-212           [-1, 20, 64, 64]               0\n",
      "     GhostModule-213           [-1, 40, 64, 64]               0\n",
      "          Conv2d-214           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-215           [-1, 20, 64, 64]              40\n",
      "            ReLU-216           [-1, 20, 64, 64]               0\n",
      "          Conv2d-217           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-218           [-1, 20, 64, 64]              40\n",
      "            ReLU-219           [-1, 20, 64, 64]               0\n",
      "     GhostModule-220           [-1, 40, 64, 64]               0\n",
      "          Conv2d-221           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-222           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-223           [-1, 40, 64, 64]              80\n",
      "            ReLU-224           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-225           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-226          [-1, 330, 64, 64]               0\n",
      "          Conv2d-227           [-1, 20, 64, 64]           6,600\n",
      "     BatchNorm2d-228           [-1, 20, 64, 64]              40\n",
      "            ReLU-229           [-1, 20, 64, 64]               0\n",
      "          Conv2d-230           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-231           [-1, 20, 64, 64]              40\n",
      "            ReLU-232           [-1, 20, 64, 64]               0\n",
      "     GhostModule-233           [-1, 40, 64, 64]               0\n",
      "          Conv2d-234           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-235           [-1, 20, 64, 64]              40\n",
      "            ReLU-236           [-1, 20, 64, 64]               0\n",
      "          Conv2d-237           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-238           [-1, 20, 64, 64]              40\n",
      "            ReLU-239           [-1, 20, 64, 64]               0\n",
      "     GhostModule-240           [-1, 40, 64, 64]               0\n",
      "          Conv2d-241           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-242           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-243           [-1, 40, 64, 64]              80\n",
      "            ReLU-244           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-245           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-246          [-1, 370, 64, 64]               0\n",
      "          Conv2d-247           [-1, 20, 64, 64]           7,400\n",
      "     BatchNorm2d-248           [-1, 20, 64, 64]              40\n",
      "            ReLU-249           [-1, 20, 64, 64]               0\n",
      "          Conv2d-250           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-251           [-1, 20, 64, 64]              40\n",
      "            ReLU-252           [-1, 20, 64, 64]               0\n",
      "     GhostModule-253           [-1, 40, 64, 64]               0\n",
      "          Conv2d-254           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-255           [-1, 20, 64, 64]              40\n",
      "            ReLU-256           [-1, 20, 64, 64]               0\n",
      "          Conv2d-257           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-258           [-1, 20, 64, 64]              40\n",
      "            ReLU-259           [-1, 20, 64, 64]               0\n",
      "     GhostModule-260           [-1, 40, 64, 64]               0\n",
      "          Conv2d-261           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-262           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-263           [-1, 40, 64, 64]              80\n",
      "            ReLU-264           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-265           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-266          [-1, 410, 64, 64]               0\n",
      "          Conv2d-267           [-1, 20, 64, 64]           8,200\n",
      "     BatchNorm2d-268           [-1, 20, 64, 64]              40\n",
      "            ReLU-269           [-1, 20, 64, 64]               0\n",
      "          Conv2d-270           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-271           [-1, 20, 64, 64]              40\n",
      "            ReLU-272           [-1, 20, 64, 64]               0\n",
      "     GhostModule-273           [-1, 40, 64, 64]               0\n",
      "          Conv2d-274           [-1, 20, 64, 64]           7,200\n",
      "     BatchNorm2d-275           [-1, 20, 64, 64]              40\n",
      "            ReLU-276           [-1, 20, 64, 64]               0\n",
      "          Conv2d-277           [-1, 20, 64, 64]             180\n",
      "     BatchNorm2d-278           [-1, 20, 64, 64]              40\n",
      "            ReLU-279           [-1, 20, 64, 64]               0\n",
      "     GhostModule-280           [-1, 40, 64, 64]               0\n",
      "          Conv2d-281           [-1, 40, 64, 64]           4,840\n",
      "          Conv2d-282           [-1, 40, 64, 64]           4,840\n",
      "     BatchNorm2d-283           [-1, 40, 64, 64]              80\n",
      "            ReLU-284           [-1, 40, 64, 64]               0\n",
      "       Dropout2d-285           [-1, 40, 64, 64]               0\n",
      "  EDABlock_ghost-286          [-1, 450, 64, 64]               0\n",
      "          Conv2d-287            [-1, 1, 64, 64]             451\n",
      "================================================================\n",
      "Total params: 441,480\n",
      "Trainable params: 441,480\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 730.59\n",
      "Params size (MB): 1.68\n",
      "Estimated Total Size (MB): 735.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "edanet_ghost = EDAnet_ghost().eval().cuda()\n",
    "summary(edanet_ghost,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2bc0f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010745525360107422\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = edanet_ghost(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d6e8640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 102.120053\n",
      "Warning: module GhostModule is treated as a zero-op.\n",
      "Warning: module DownsampleBlock is treated as a zero-op.\n",
      "Warning: module Dropout2d is treated as a zero-op.\n",
      "Warning: module EDABlock_ghost is treated as a zero-op.\n",
      "Warning: module EDAnet_ghost is treated as a zero-op.\n",
      "EDAnet_ghost(\n",
      "  0.444 M, 100.000% Params, 3.128 GMac, 100.000% MACs, \n",
      "  (layers): ModuleList(\n",
      "    0.444 M, 99.898% Params, 3.127 GMac, 99.941% MACs, \n",
      "    (0): DownsampleBlock(\n",
      "      0.0 M, 0.061% Params, 0.017 GMac, 0.553% MACs, \n",
      "      (conv): GhostModule(\n",
      "        0.0 M, 0.054% Params, 0.017 GMac, 0.528% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.0 M, 0.039% Params, 0.012 GMac, 0.377% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.036% Params, 0.011 GMac, 0.339% MACs, 3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.003% Params, 0.001 GMac, 0.025% MACs, 6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.013% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.015% Params, 0.005 GMac, 0.151% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.012% Params, 0.004 GMac, 0.113% MACs, 6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.003% Params, 0.001 GMac, 0.025% MACs, 6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.013% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.025% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.007% Params, 0.0 GMac, 0.000% MACs, 15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    )\n",
      "    (1): DownsampleBlock(\n",
      "      0.004 M, 0.794% Params, 0.058 GMac, 1.838% MACs, \n",
      "      (conv): GhostModule(\n",
      "        0.003 M, 0.767% Params, 0.057 GMac, 1.807% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.003 M, 0.710% Params, 0.052 GMac, 1.662% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.699% Params, 0.051 GMac, 1.626% MACs, 15, 23, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.010% Params, 0.001 GMac, 0.024% MACs, 23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.012% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.057% Params, 0.005 GMac, 0.145% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.047% Params, 0.003 GMac, 0.108% MACs, 23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=23, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.010% Params, 0.001 GMac, 0.024% MACs, 23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.012% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.031% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.027% Params, 0.0 GMac, 0.000% MACs, 60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    )\n",
      "    (2): EDABlock_ghost(\n",
      "      0.019 M, 4.244% Params, 0.308 GMac, 9.846% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.001 M, 0.329% Params, 0.025 GMac, 0.786% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.001 M, 0.279% Params, 0.021 GMac, 0.660% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.270% Params, 0.02 GMac, 0.628% MACs, 60, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.123 GMac, 3.928% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.119 GMac, 3.802% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.118 GMac, 3.771% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.001 GMac, 0.042% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.021% MACs, )\n",
      "    )\n",
      "    (3): EDABlock_ghost(\n",
      "      0.02 M, 4.424% Params, 0.321 GMac, 10.265% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.002 M, 0.509% Params, 0.038 GMac, 1.205% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.002 M, 0.459% Params, 0.034 GMac, 1.079% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.450% Params, 0.033 GMac, 1.047% MACs, 100, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.123 GMac, 3.928% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.119 GMac, 3.802% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.118 GMac, 3.771% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.001 GMac, 0.042% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.021% MACs, )\n",
      "    )\n",
      "    (4): EDABlock_ghost(\n",
      "      0.02 M, 4.604% Params, 0.334 GMac, 10.684% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.003 M, 0.689% Params, 0.051 GMac, 1.623% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.003 M, 0.640% Params, 0.047 GMac, 1.498% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.631% Params, 0.046 GMac, 1.466% MACs, 140, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.123 GMac, 3.928% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.119 GMac, 3.802% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.118 GMac, 3.771% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.001 GMac, 0.042% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.021% MACs, )\n",
      "    )\n",
      "    (5): EDABlock_ghost(\n",
      "      0.021 M, 4.784% Params, 0.347 GMac, 11.103% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.004 M, 0.869% Params, 0.064 GMac, 2.042% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.004 M, 0.820% Params, 0.06 GMac, 1.917% MACs, \n",
      "          (0): Conv2d(0.004 M, 0.811% Params, 0.059 GMac, 1.885% MACs, 180, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.123 GMac, 3.928% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.119 GMac, 3.802% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.118 GMac, 3.771% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.001 GMac, 0.042% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.021% MACs, )\n",
      "    )\n",
      "    (6): EDABlock_ghost(\n",
      "      0.022 M, 4.964% Params, 0.36 GMac, 11.521% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.005 M, 1.050% Params, 0.077 GMac, 2.461% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.004 M, 1.000% Params, 0.073 GMac, 2.336% MACs, \n",
      "          (0): Conv2d(0.004 M, 0.991% Params, 0.072 GMac, 2.304% MACs, 220, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.123 GMac, 3.928% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.119 GMac, 3.802% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.118 GMac, 3.771% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.004 GMac, 0.126% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.003 GMac, 0.094% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.001 GMac, 0.021% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.010% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.079 GMac, 2.535% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.001 GMac, 0.042% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.021% MACs, )\n",
      "    )\n",
      "    (7): DownsampleBlock(\n",
      "      0.153 M, 34.508% Params, 0.627 GMac, 20.042% MACs, \n",
      "      (conv): GhostModule(\n",
      "        0.153 M, 34.449% Params, 0.627 GMac, 20.042% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.152 M, 34.288% Params, 0.624 GMac, 19.939% MACs, \n",
      "          (0): Conv2d(0.152 M, 34.259% Params, 0.623 GMac, 19.914% MACs, 260, 65, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.029% Params, 0.001 GMac, 0.017% MACs, 65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.001 M, 0.161% Params, 0.003 GMac, 0.102% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.132% Params, 0.002 GMac, 0.077% MACs, 65, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=65, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.029% Params, 0.001 GMac, 0.017% MACs, 65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm): BatchNorm2d(0.0 M, 0.059% Params, 0.0 GMac, 0.000% MACs, 130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    )\n",
      "    (8): EDABlock_ghost(\n",
      "      0.02 M, 4.559% Params, 0.083 GMac, 2.645% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.003 M, 0.644% Params, 0.012 GMac, 0.380% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.003 M, 0.595% Params, 0.011 GMac, 0.348% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.586% Params, 0.011 GMac, 0.340% MACs, 130, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (9): EDABlock_ghost(\n",
      "      0.021 M, 4.739% Params, 0.086 GMac, 2.749% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.004 M, 0.824% Params, 0.015 GMac, 0.484% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.003 M, 0.775% Params, 0.014 GMac, 0.453% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.766% Params, 0.014 GMac, 0.445% MACs, 170, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 2))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(2, 2))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (10): EDABlock_ghost(\n",
      "      0.022 M, 4.919% Params, 0.089 GMac, 2.854% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.004 M, 1.005% Params, 0.018 GMac, 0.589% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.004 M, 0.955% Params, 0.017 GMac, 0.558% MACs, \n",
      "          (0): Conv2d(0.004 M, 0.946% Params, 0.017 GMac, 0.550% MACs, 210, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (11): EDABlock_ghost(\n",
      "      0.023 M, 5.099% Params, 0.093 GMac, 2.959% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.005 M, 1.185% Params, 0.022 GMac, 0.694% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.005 M, 1.135% Params, 0.021 GMac, 0.662% MACs, \n",
      "          (0): Conv2d(0.005 M, 1.126% Params, 0.02 GMac, 0.655% MACs, 250, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 4))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(4, 4))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (12): EDABlock_ghost(\n",
      "      0.023 M, 5.280% Params, 0.096 GMac, 3.064% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.006 M, 1.365% Params, 0.025 GMac, 0.799% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.006 M, 1.315% Params, 0.024 GMac, 0.767% MACs, \n",
      "          (0): Conv2d(0.006 M, 1.306% Params, 0.024 GMac, 0.759% MACs, 290, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (13): EDABlock_ghost(\n",
      "      0.024 M, 5.460% Params, 0.099 GMac, 3.168% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.007 M, 1.545% Params, 0.028 GMac, 0.903% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.496% Params, 0.027 GMac, 0.872% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.487% Params, 0.027 GMac, 0.864% MACs, 330, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 8))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(8, 8))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (14): EDABlock_ghost(\n",
      "      0.025 M, 5.640% Params, 0.102 GMac, 3.273% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.008 M, 1.725% Params, 0.032 GMac, 1.008% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.676% Params, 0.031 GMac, 0.977% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.667% Params, 0.03 GMac, 0.969% MACs, 370, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "    (15): EDABlock_ghost(\n",
      "      0.026 M, 5.820% Params, 0.106 GMac, 3.378% MACs, \n",
      "      (conv_0): GhostModule(\n",
      "        0.008 M, 1.906% Params, 0.035 GMac, 1.113% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.008 M, 1.856% Params, 0.034 GMac, 1.081% MACs, \n",
      "          (0): Conv2d(0.008 M, 1.847% Params, 0.034 GMac, 1.074% MACs, 410, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_0): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_1): GhostModule(\n",
      "        0.007 M, 1.680% Params, 0.031 GMac, 0.982% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.007 M, 1.631% Params, 0.03 GMac, 0.951% MACs, \n",
      "          (0): Conv2d(0.007 M, 1.622% Params, 0.029 GMac, 0.943% MACs, 40, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.0 M, 0.050% Params, 0.001 GMac, 0.031% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.041% Params, 0.001 GMac, 0.024% MACs, 20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.009% Params, 0.0 GMac, 0.005% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (batchNorm_1): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.000% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3x1_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(3, 1), stride=(1, 1), padding=(16, 0), dilation=(16, 16))\n",
      "      (conv1x3_2): Conv2d(0.005 M, 1.090% Params, 0.02 GMac, 0.634% MACs, 40, 40, kernel_size=(1, 3), stride=(1, 1), padding=(0, 16), dilation=(16, 16))\n",
      "      (batchNorm_2): BatchNorm2d(0.0 M, 0.018% Params, 0.0 GMac, 0.010% MACs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.02, inplace=False)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (project_layer): Conv2d(0.0 M, 0.102% Params, 0.002 GMac, 0.059% MACs, 450, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       3.13 GMac\n",
      "Number of parameters:           443.97 k\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= edanet_ghost(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))\n",
    "\n",
    "macs, params = get_model_complexity_info(edanet_ghost, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422440f4",
   "metadata": {},
   "source": [
    "# DeepLabV3Plus-Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "680e1dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 16, 1, 1], [6, 24, 2, 2], [6, 32, 3, 2], [6, 64, 4, 2]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b2a22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp, oup, stride, BatchNorm):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        BatchNorm(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, dilation, expand_ratio, BatchNorm):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "        self.kernel_size = 3\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 0, dilation, groups=hidden_dim, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, 1, 1, bias=False),\n",
    "                BatchNorm(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, 1, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 0, dilation, groups=hidden_dim, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, 1, bias=False),\n",
    "                BatchNorm(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pad = fixed_padding(x, self.kernel_size, dilation=self.dilation)\n",
    "        if self.use_res_connect:\n",
    "            x = x + self.conv(x_pad)\n",
    "        else:\n",
    "            x = self.conv(x_pad)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, output_stride=16, BatchNorm=None, width_mult=1., pretrained=False):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        current_stride = 1\n",
    "        rate = 1\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.features = [conv_bn(3, input_channel, 2, BatchNorm)]\n",
    "        current_stride *= 2\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            if current_stride == output_stride:\n",
    "                stride = 1\n",
    "                dilation = rate\n",
    "                rate *= s\n",
    "            else:\n",
    "                stride = s\n",
    "                dilation = 1\n",
    "                current_stride *= s\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, stride, dilation, t, BatchNorm))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, dilation, t, BatchNorm))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if pretrained:\n",
    "            self._load_pretrained_model()\n",
    "        print(len(self.features))\n",
    "        self.low_level_features = self.features[0:4]\n",
    "        self.high_level_features = self.features[4:]\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        low_level_feat = self.low_level_features(x)\n",
    "        print('low_level_feat shape', low_level_feat.shape)\n",
    "        x = self.high_level_features(low_level_feat)\n",
    "        print('x1 shape', x.shape)\n",
    "\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _load_pretrained_model(self):\n",
    "        pretrain_dict = model_zoo.load_url('http://jeff95.me/models/mobilenet_v2-6a65762b.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "        for k, v in pretrain_dict.items():\n",
    "            if k in state_dict:\n",
    "                model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            # elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "            #     m.weight.data.fill_(1)\n",
    "            #     m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f77f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, rate):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fcc10db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabv3_plus_mobilenet(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus_mobilenet, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.efficient_features = MobileNetV2(output_stride=16, BatchNorm=nn.BatchNorm2d)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(320, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP_module(320, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP_module(320, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP_module(320, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(320, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(24, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.efficient_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                # torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f459cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters of the net except for\n",
    "    the last classification layer. Note that for each batchnorm layer,\n",
    "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
    "    any batchnorm parameter\n",
    "    \"\"\"\n",
    "    b = [model.xception_features]\n",
    "    for i in range(len(b)):\n",
    "        for k in b[i].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k\n",
    "\n",
    "\n",
    "def get_10x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the last layer of the net,\n",
    "    which does the classification of pixel into classes\n",
    "    \"\"\"\n",
    "    b = [model.aspp1, model.aspp2, model.aspp3, model.aspp4, model.conv1, model.conv2, model.last_conv]\n",
    "    for j in range(len(b)):\n",
    "        for k in b[j].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e684066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (low_level_features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (high_level_features): Sequential(\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficient_features = MobileNetV2(output_stride=16, BatchNorm=nn.BatchNorm2d)\n",
    "efficient_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73c6f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_level_feat shape torch.Size([2, 24, 128, 128])\n",
      "x1 shape torch.Size([2, 320, 32, 32])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             864\n",
      "            Conv2d-2         [-1, 32, 256, 256]             864\n",
      "       BatchNorm2d-3         [-1, 32, 256, 256]              64\n",
      "       BatchNorm2d-4         [-1, 32, 256, 256]              64\n",
      "             ReLU6-5         [-1, 32, 256, 256]               0\n",
      "             ReLU6-6         [-1, 32, 256, 256]               0\n",
      "            Conv2d-7         [-1, 32, 256, 256]             288\n",
      "            Conv2d-8         [-1, 32, 256, 256]             288\n",
      "       BatchNorm2d-9         [-1, 32, 256, 256]              64\n",
      "      BatchNorm2d-10         [-1, 32, 256, 256]              64\n",
      "            ReLU6-11         [-1, 32, 256, 256]               0\n",
      "            ReLU6-12         [-1, 32, 256, 256]               0\n",
      "           Conv2d-13         [-1, 16, 256, 256]             512\n",
      "           Conv2d-14         [-1, 16, 256, 256]             512\n",
      "      BatchNorm2d-15         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-16         [-1, 16, 256, 256]              32\n",
      " InvertedResidual-17         [-1, 16, 256, 256]               0\n",
      " InvertedResidual-18         [-1, 16, 256, 256]               0\n",
      "           Conv2d-19         [-1, 96, 258, 258]           1,536\n",
      "           Conv2d-20         [-1, 96, 258, 258]           1,536\n",
      "      BatchNorm2d-21         [-1, 96, 258, 258]             192\n",
      "      BatchNorm2d-22         [-1, 96, 258, 258]             192\n",
      "            ReLU6-23         [-1, 96, 258, 258]               0\n",
      "            ReLU6-24         [-1, 96, 258, 258]               0\n",
      "           Conv2d-25         [-1, 96, 128, 128]             864\n",
      "           Conv2d-26         [-1, 96, 128, 128]             864\n",
      "      BatchNorm2d-27         [-1, 96, 128, 128]             192\n",
      "      BatchNorm2d-28         [-1, 96, 128, 128]             192\n",
      "            ReLU6-29         [-1, 96, 128, 128]               0\n",
      "            ReLU6-30         [-1, 96, 128, 128]               0\n",
      "           Conv2d-31         [-1, 24, 128, 128]           2,304\n",
      "           Conv2d-32         [-1, 24, 128, 128]           2,304\n",
      "      BatchNorm2d-33         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-34         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-35         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-36         [-1, 24, 128, 128]               0\n",
      "           Conv2d-37        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-38        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-39        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-40        [-1, 144, 130, 130]             288\n",
      "            ReLU6-41        [-1, 144, 130, 130]               0\n",
      "            ReLU6-42        [-1, 144, 130, 130]               0\n",
      "           Conv2d-43        [-1, 144, 128, 128]           1,296\n",
      "           Conv2d-44        [-1, 144, 128, 128]           1,296\n",
      "      BatchNorm2d-45        [-1, 144, 128, 128]             288\n",
      "      BatchNorm2d-46        [-1, 144, 128, 128]             288\n",
      "            ReLU6-47        [-1, 144, 128, 128]               0\n",
      "            ReLU6-48        [-1, 144, 128, 128]               0\n",
      "           Conv2d-49         [-1, 24, 128, 128]           3,456\n",
      "           Conv2d-50         [-1, 24, 128, 128]           3,456\n",
      "      BatchNorm2d-51         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-52         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-53         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-54         [-1, 24, 128, 128]               0\n",
      "           Conv2d-55        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-56        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-57        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-58        [-1, 144, 130, 130]             288\n",
      "            ReLU6-59        [-1, 144, 130, 130]               0\n",
      "            ReLU6-60        [-1, 144, 130, 130]               0\n",
      "           Conv2d-61          [-1, 144, 64, 64]           1,296\n",
      "           Conv2d-62          [-1, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-63          [-1, 144, 64, 64]             288\n",
      "      BatchNorm2d-64          [-1, 144, 64, 64]             288\n",
      "            ReLU6-65          [-1, 144, 64, 64]               0\n",
      "            ReLU6-66          [-1, 144, 64, 64]               0\n",
      "           Conv2d-67           [-1, 32, 64, 64]           4,608\n",
      "           Conv2d-68           [-1, 32, 64, 64]           4,608\n",
      "      BatchNorm2d-69           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-70           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-71           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-72           [-1, 32, 64, 64]               0\n",
      "           Conv2d-73          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-74          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-75          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-76          [-1, 192, 66, 66]             384\n",
      "            ReLU6-77          [-1, 192, 66, 66]               0\n",
      "            ReLU6-78          [-1, 192, 66, 66]               0\n",
      "           Conv2d-79          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-80          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-81          [-1, 192, 64, 64]             384\n",
      "      BatchNorm2d-82          [-1, 192, 64, 64]             384\n",
      "            ReLU6-83          [-1, 192, 64, 64]               0\n",
      "            ReLU6-84          [-1, 192, 64, 64]               0\n",
      "           Conv2d-85           [-1, 32, 64, 64]           6,144\n",
      "           Conv2d-86           [-1, 32, 64, 64]           6,144\n",
      "      BatchNorm2d-87           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-88           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-89           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-90           [-1, 32, 64, 64]               0\n",
      "           Conv2d-91          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-92          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-93          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-94          [-1, 192, 66, 66]             384\n",
      "            ReLU6-95          [-1, 192, 66, 66]               0\n",
      "            ReLU6-96          [-1, 192, 66, 66]               0\n",
      "           Conv2d-97          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-98          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-99          [-1, 192, 64, 64]             384\n",
      "     BatchNorm2d-100          [-1, 192, 64, 64]             384\n",
      "           ReLU6-101          [-1, 192, 64, 64]               0\n",
      "           ReLU6-102          [-1, 192, 64, 64]               0\n",
      "          Conv2d-103           [-1, 32, 64, 64]           6,144\n",
      "          Conv2d-104           [-1, 32, 64, 64]           6,144\n",
      "     BatchNorm2d-105           [-1, 32, 64, 64]              64\n",
      "     BatchNorm2d-106           [-1, 32, 64, 64]              64\n",
      "InvertedResidual-107           [-1, 32, 64, 64]               0\n",
      "InvertedResidual-108           [-1, 32, 64, 64]               0\n",
      "          Conv2d-109          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-110          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-111          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-112          [-1, 192, 66, 66]             384\n",
      "           ReLU6-113          [-1, 192, 66, 66]               0\n",
      "           ReLU6-114          [-1, 192, 66, 66]               0\n",
      "          Conv2d-115          [-1, 192, 32, 32]           1,728\n",
      "          Conv2d-116          [-1, 192, 32, 32]           1,728\n",
      "     BatchNorm2d-117          [-1, 192, 32, 32]             384\n",
      "     BatchNorm2d-118          [-1, 192, 32, 32]             384\n",
      "           ReLU6-119          [-1, 192, 32, 32]               0\n",
      "           ReLU6-120          [-1, 192, 32, 32]               0\n",
      "          Conv2d-121           [-1, 64, 32, 32]          12,288\n",
      "          Conv2d-122           [-1, 64, 32, 32]          12,288\n",
      "     BatchNorm2d-123           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-124           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-125           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-126           [-1, 64, 32, 32]               0\n",
      "          Conv2d-127          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-128          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-129          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-130          [-1, 384, 34, 34]             768\n",
      "           ReLU6-131          [-1, 384, 34, 34]               0\n",
      "           ReLU6-132          [-1, 384, 34, 34]               0\n",
      "          Conv2d-133          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-134          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-135          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-136          [-1, 384, 32, 32]             768\n",
      "           ReLU6-137          [-1, 384, 32, 32]               0\n",
      "           ReLU6-138          [-1, 384, 32, 32]               0\n",
      "          Conv2d-139           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-140           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-141           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-142           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-143           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-144           [-1, 64, 32, 32]               0\n",
      "          Conv2d-145          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-146          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-147          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-148          [-1, 384, 34, 34]             768\n",
      "           ReLU6-149          [-1, 384, 34, 34]               0\n",
      "           ReLU6-150          [-1, 384, 34, 34]               0\n",
      "          Conv2d-151          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-152          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-153          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-154          [-1, 384, 32, 32]             768\n",
      "           ReLU6-155          [-1, 384, 32, 32]               0\n",
      "           ReLU6-156          [-1, 384, 32, 32]               0\n",
      "          Conv2d-157           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-158           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-159           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-160           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-161           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-162           [-1, 64, 32, 32]               0\n",
      "          Conv2d-163          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-164          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-165          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-166          [-1, 384, 34, 34]             768\n",
      "           ReLU6-167          [-1, 384, 34, 34]               0\n",
      "           ReLU6-168          [-1, 384, 34, 34]               0\n",
      "          Conv2d-169          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-170          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-171          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-172          [-1, 384, 32, 32]             768\n",
      "           ReLU6-173          [-1, 384, 32, 32]               0\n",
      "           ReLU6-174          [-1, 384, 32, 32]               0\n",
      "          Conv2d-175           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-176           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-177           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-178           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-179           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-180           [-1, 64, 32, 32]               0\n",
      "          Conv2d-181          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-182          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-183          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-184          [-1, 384, 34, 34]             768\n",
      "           ReLU6-185          [-1, 384, 34, 34]               0\n",
      "           ReLU6-186          [-1, 384, 34, 34]               0\n",
      "          Conv2d-187          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-188          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-190          [-1, 384, 32, 32]             768\n",
      "           ReLU6-191          [-1, 384, 32, 32]               0\n",
      "           ReLU6-192          [-1, 384, 32, 32]               0\n",
      "          Conv2d-193           [-1, 96, 32, 32]          36,864\n",
      "          Conv2d-194           [-1, 96, 32, 32]          36,864\n",
      "     BatchNorm2d-195           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-196           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-197           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-198           [-1, 96, 32, 32]               0\n",
      "          Conv2d-199          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-200          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-201          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-202          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-203          [-1, 576, 34, 34]               0\n",
      "           ReLU6-204          [-1, 576, 34, 34]               0\n",
      "          Conv2d-205          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-206          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-207          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-208          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-209          [-1, 576, 32, 32]               0\n",
      "           ReLU6-210          [-1, 576, 32, 32]               0\n",
      "          Conv2d-211           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-212           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-213           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-214           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-215           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-216           [-1, 96, 32, 32]               0\n",
      "          Conv2d-217          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-218          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-219          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-220          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-221          [-1, 576, 34, 34]               0\n",
      "           ReLU6-222          [-1, 576, 34, 34]               0\n",
      "          Conv2d-223          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-224          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-225          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-226          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-227          [-1, 576, 32, 32]               0\n",
      "           ReLU6-228          [-1, 576, 32, 32]               0\n",
      "          Conv2d-229           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-230           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-231           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-232           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-233           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-234           [-1, 96, 32, 32]               0\n",
      "          Conv2d-235          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-236          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-237          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-238          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-239          [-1, 576, 34, 34]               0\n",
      "           ReLU6-240          [-1, 576, 34, 34]               0\n",
      "          Conv2d-241          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-242          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-243          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-244          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-245          [-1, 576, 32, 32]               0\n",
      "           ReLU6-246          [-1, 576, 32, 32]               0\n",
      "          Conv2d-247          [-1, 160, 32, 32]          92,160\n",
      "          Conv2d-248          [-1, 160, 32, 32]          92,160\n",
      "     BatchNorm2d-249          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-250          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-251          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-252          [-1, 160, 32, 32]               0\n",
      "          Conv2d-253          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-254          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-255          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-256          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-257          [-1, 960, 34, 34]               0\n",
      "           ReLU6-258          [-1, 960, 34, 34]               0\n",
      "          Conv2d-259          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-260          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-261          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-262          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-263          [-1, 960, 32, 32]               0\n",
      "           ReLU6-264          [-1, 960, 32, 32]               0\n",
      "          Conv2d-265          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-266          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-267          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-268          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-269          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-270          [-1, 160, 32, 32]               0\n",
      "          Conv2d-271          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-272          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-273          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-274          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-275          [-1, 960, 34, 34]               0\n",
      "           ReLU6-276          [-1, 960, 34, 34]               0\n",
      "          Conv2d-277          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-278          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-279          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-280          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-281          [-1, 960, 32, 32]               0\n",
      "           ReLU6-282          [-1, 960, 32, 32]               0\n",
      "          Conv2d-283          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-284          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-285          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-286          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-287          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-288          [-1, 160, 32, 32]               0\n",
      "          Conv2d-289          [-1, 960, 36, 36]         153,600\n",
      "          Conv2d-290          [-1, 960, 36, 36]         153,600\n",
      "     BatchNorm2d-291          [-1, 960, 36, 36]           1,920\n",
      "     BatchNorm2d-292          [-1, 960, 36, 36]           1,920\n",
      "           ReLU6-293          [-1, 960, 36, 36]               0\n",
      "           ReLU6-294          [-1, 960, 36, 36]               0\n",
      "          Conv2d-295          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-296          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-297          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-298          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-299          [-1, 960, 32, 32]               0\n",
      "           ReLU6-300          [-1, 960, 32, 32]               0\n",
      "          Conv2d-301          [-1, 320, 32, 32]         307,200\n",
      "          Conv2d-302          [-1, 320, 32, 32]         307,200\n",
      "     BatchNorm2d-303          [-1, 320, 32, 32]             640\n",
      "     BatchNorm2d-304          [-1, 320, 32, 32]             640\n",
      "InvertedResidual-305          [-1, 320, 32, 32]               0\n",
      "InvertedResidual-306          [-1, 320, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 3,623,424\n",
      "Trainable params: 3,623,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 1894.45\n",
      "Params size (MB): 13.82\n",
      "Estimated Total Size (MB): 1911.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(efficient_features.cuda(),  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "677926ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_level_feat shape torch.Size([1, 24, 128, 128])\n",
      "x1 shape torch.Size([1, 320, 32, 32])\n",
      "torch.Size([1, 320, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,512,512).cuda()\n",
    "\n",
    "\n",
    "output = efficient_features(input)\n",
    "\n",
    "print(output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b00332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             864\n",
      "            Conv2d-2         [-1, 32, 256, 256]             864\n",
      "       BatchNorm2d-3         [-1, 32, 256, 256]              64\n",
      "       BatchNorm2d-4         [-1, 32, 256, 256]              64\n",
      "             ReLU6-5         [-1, 32, 256, 256]               0\n",
      "             ReLU6-6         [-1, 32, 256, 256]               0\n",
      "            Conv2d-7         [-1, 32, 256, 256]             288\n",
      "            Conv2d-8         [-1, 32, 256, 256]             288\n",
      "       BatchNorm2d-9         [-1, 32, 256, 256]              64\n",
      "      BatchNorm2d-10         [-1, 32, 256, 256]              64\n",
      "            ReLU6-11         [-1, 32, 256, 256]               0\n",
      "            ReLU6-12         [-1, 32, 256, 256]               0\n",
      "           Conv2d-13         [-1, 16, 256, 256]             512\n",
      "           Conv2d-14         [-1, 16, 256, 256]             512\n",
      "      BatchNorm2d-15         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-16         [-1, 16, 256, 256]              32\n",
      " InvertedResidual-17         [-1, 16, 256, 256]               0\n",
      " InvertedResidual-18         [-1, 16, 256, 256]               0\n",
      "           Conv2d-19         [-1, 96, 258, 258]           1,536\n",
      "           Conv2d-20         [-1, 96, 258, 258]           1,536\n",
      "      BatchNorm2d-21         [-1, 96, 258, 258]             192\n",
      "      BatchNorm2d-22         [-1, 96, 258, 258]             192\n",
      "            ReLU6-23         [-1, 96, 258, 258]               0\n",
      "            ReLU6-24         [-1, 96, 258, 258]               0\n",
      "           Conv2d-25         [-1, 96, 128, 128]             864\n",
      "           Conv2d-26         [-1, 96, 128, 128]             864\n",
      "      BatchNorm2d-27         [-1, 96, 128, 128]             192\n",
      "      BatchNorm2d-28         [-1, 96, 128, 128]             192\n",
      "            ReLU6-29         [-1, 96, 128, 128]               0\n",
      "            ReLU6-30         [-1, 96, 128, 128]               0\n",
      "           Conv2d-31         [-1, 24, 128, 128]           2,304\n",
      "           Conv2d-32         [-1, 24, 128, 128]           2,304\n",
      "      BatchNorm2d-33         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-34         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-35         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-36         [-1, 24, 128, 128]               0\n",
      "           Conv2d-37        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-38        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-39        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-40        [-1, 144, 130, 130]             288\n",
      "            ReLU6-41        [-1, 144, 130, 130]               0\n",
      "            ReLU6-42        [-1, 144, 130, 130]               0\n",
      "           Conv2d-43        [-1, 144, 128, 128]           1,296\n",
      "           Conv2d-44        [-1, 144, 128, 128]           1,296\n",
      "      BatchNorm2d-45        [-1, 144, 128, 128]             288\n",
      "      BatchNorm2d-46        [-1, 144, 128, 128]             288\n",
      "            ReLU6-47        [-1, 144, 128, 128]               0\n",
      "            ReLU6-48        [-1, 144, 128, 128]               0\n",
      "           Conv2d-49         [-1, 24, 128, 128]           3,456\n",
      "           Conv2d-50         [-1, 24, 128, 128]           3,456\n",
      "      BatchNorm2d-51         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-52         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-53         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-54         [-1, 24, 128, 128]               0\n",
      "           Conv2d-55        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-56        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-57        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-58        [-1, 144, 130, 130]             288\n",
      "            ReLU6-59        [-1, 144, 130, 130]               0\n",
      "            ReLU6-60        [-1, 144, 130, 130]               0\n",
      "           Conv2d-61          [-1, 144, 64, 64]           1,296\n",
      "           Conv2d-62          [-1, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-63          [-1, 144, 64, 64]             288\n",
      "      BatchNorm2d-64          [-1, 144, 64, 64]             288\n",
      "            ReLU6-65          [-1, 144, 64, 64]               0\n",
      "            ReLU6-66          [-1, 144, 64, 64]               0\n",
      "           Conv2d-67           [-1, 32, 64, 64]           4,608\n",
      "           Conv2d-68           [-1, 32, 64, 64]           4,608\n",
      "      BatchNorm2d-69           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-70           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-71           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-72           [-1, 32, 64, 64]               0\n",
      "           Conv2d-73          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-74          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-75          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-76          [-1, 192, 66, 66]             384\n",
      "            ReLU6-77          [-1, 192, 66, 66]               0\n",
      "            ReLU6-78          [-1, 192, 66, 66]               0\n",
      "           Conv2d-79          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-80          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-81          [-1, 192, 64, 64]             384\n",
      "      BatchNorm2d-82          [-1, 192, 64, 64]             384\n",
      "            ReLU6-83          [-1, 192, 64, 64]               0\n",
      "            ReLU6-84          [-1, 192, 64, 64]               0\n",
      "           Conv2d-85           [-1, 32, 64, 64]           6,144\n",
      "           Conv2d-86           [-1, 32, 64, 64]           6,144\n",
      "      BatchNorm2d-87           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-88           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-89           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-90           [-1, 32, 64, 64]               0\n",
      "           Conv2d-91          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-92          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-93          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-94          [-1, 192, 66, 66]             384\n",
      "            ReLU6-95          [-1, 192, 66, 66]               0\n",
      "            ReLU6-96          [-1, 192, 66, 66]               0\n",
      "           Conv2d-97          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-98          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-99          [-1, 192, 64, 64]             384\n",
      "     BatchNorm2d-100          [-1, 192, 64, 64]             384\n",
      "           ReLU6-101          [-1, 192, 64, 64]               0\n",
      "           ReLU6-102          [-1, 192, 64, 64]               0\n",
      "          Conv2d-103           [-1, 32, 64, 64]           6,144\n",
      "          Conv2d-104           [-1, 32, 64, 64]           6,144\n",
      "     BatchNorm2d-105           [-1, 32, 64, 64]              64\n",
      "     BatchNorm2d-106           [-1, 32, 64, 64]              64\n",
      "InvertedResidual-107           [-1, 32, 64, 64]               0\n",
      "InvertedResidual-108           [-1, 32, 64, 64]               0\n",
      "          Conv2d-109          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-110          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-111          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-112          [-1, 192, 66, 66]             384\n",
      "           ReLU6-113          [-1, 192, 66, 66]               0\n",
      "           ReLU6-114          [-1, 192, 66, 66]               0\n",
      "          Conv2d-115          [-1, 192, 32, 32]           1,728\n",
      "          Conv2d-116          [-1, 192, 32, 32]           1,728\n",
      "     BatchNorm2d-117          [-1, 192, 32, 32]             384\n",
      "     BatchNorm2d-118          [-1, 192, 32, 32]             384\n",
      "           ReLU6-119          [-1, 192, 32, 32]               0\n",
      "           ReLU6-120          [-1, 192, 32, 32]               0\n",
      "          Conv2d-121           [-1, 64, 32, 32]          12,288\n",
      "          Conv2d-122           [-1, 64, 32, 32]          12,288\n",
      "     BatchNorm2d-123           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-124           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-125           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-126           [-1, 64, 32, 32]               0\n",
      "          Conv2d-127          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-128          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-129          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-130          [-1, 384, 34, 34]             768\n",
      "           ReLU6-131          [-1, 384, 34, 34]               0\n",
      "           ReLU6-132          [-1, 384, 34, 34]               0\n",
      "          Conv2d-133          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-134          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-135          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-136          [-1, 384, 32, 32]             768\n",
      "           ReLU6-137          [-1, 384, 32, 32]               0\n",
      "           ReLU6-138          [-1, 384, 32, 32]               0\n",
      "          Conv2d-139           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-140           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-141           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-142           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-143           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-144           [-1, 64, 32, 32]               0\n",
      "          Conv2d-145          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-146          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-147          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-148          [-1, 384, 34, 34]             768\n",
      "           ReLU6-149          [-1, 384, 34, 34]               0\n",
      "           ReLU6-150          [-1, 384, 34, 34]               0\n",
      "          Conv2d-151          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-152          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-153          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-154          [-1, 384, 32, 32]             768\n",
      "           ReLU6-155          [-1, 384, 32, 32]               0\n",
      "           ReLU6-156          [-1, 384, 32, 32]               0\n",
      "          Conv2d-157           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-158           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-159           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-160           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-161           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-162           [-1, 64, 32, 32]               0\n",
      "          Conv2d-163          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-164          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-165          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-166          [-1, 384, 34, 34]             768\n",
      "           ReLU6-167          [-1, 384, 34, 34]               0\n",
      "           ReLU6-168          [-1, 384, 34, 34]               0\n",
      "          Conv2d-169          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-170          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-171          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-172          [-1, 384, 32, 32]             768\n",
      "           ReLU6-173          [-1, 384, 32, 32]               0\n",
      "           ReLU6-174          [-1, 384, 32, 32]               0\n",
      "          Conv2d-175           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-176           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-177           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-178           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-179           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-180           [-1, 64, 32, 32]               0\n",
      "          Conv2d-181          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-182          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-183          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-184          [-1, 384, 34, 34]             768\n",
      "           ReLU6-185          [-1, 384, 34, 34]               0\n",
      "           ReLU6-186          [-1, 384, 34, 34]               0\n",
      "          Conv2d-187          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-188          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-190          [-1, 384, 32, 32]             768\n",
      "           ReLU6-191          [-1, 384, 32, 32]               0\n",
      "           ReLU6-192          [-1, 384, 32, 32]               0\n",
      "          Conv2d-193           [-1, 96, 32, 32]          36,864\n",
      "          Conv2d-194           [-1, 96, 32, 32]          36,864\n",
      "     BatchNorm2d-195           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-196           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-197           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-198           [-1, 96, 32, 32]               0\n",
      "          Conv2d-199          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-200          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-201          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-202          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-203          [-1, 576, 34, 34]               0\n",
      "           ReLU6-204          [-1, 576, 34, 34]               0\n",
      "          Conv2d-205          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-206          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-207          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-208          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-209          [-1, 576, 32, 32]               0\n",
      "           ReLU6-210          [-1, 576, 32, 32]               0\n",
      "          Conv2d-211           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-212           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-213           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-214           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-215           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-216           [-1, 96, 32, 32]               0\n",
      "          Conv2d-217          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-218          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-219          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-220          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-221          [-1, 576, 34, 34]               0\n",
      "           ReLU6-222          [-1, 576, 34, 34]               0\n",
      "          Conv2d-223          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-224          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-225          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-226          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-227          [-1, 576, 32, 32]               0\n",
      "           ReLU6-228          [-1, 576, 32, 32]               0\n",
      "          Conv2d-229           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-230           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-231           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-232           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-233           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-234           [-1, 96, 32, 32]               0\n",
      "          Conv2d-235          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-236          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-237          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-238          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-239          [-1, 576, 34, 34]               0\n",
      "           ReLU6-240          [-1, 576, 34, 34]               0\n",
      "          Conv2d-241          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-242          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-243          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-244          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-245          [-1, 576, 32, 32]               0\n",
      "           ReLU6-246          [-1, 576, 32, 32]               0\n",
      "          Conv2d-247          [-1, 160, 32, 32]          92,160\n",
      "          Conv2d-248          [-1, 160, 32, 32]          92,160\n",
      "     BatchNorm2d-249          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-250          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-251          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-252          [-1, 160, 32, 32]               0\n",
      "          Conv2d-253          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-254          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-255          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-256          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-257          [-1, 960, 34, 34]               0\n",
      "           ReLU6-258          [-1, 960, 34, 34]               0\n",
      "          Conv2d-259          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-260          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-261          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-262          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-263          [-1, 960, 32, 32]               0\n",
      "           ReLU6-264          [-1, 960, 32, 32]               0\n",
      "          Conv2d-265          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-266          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-267          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-268          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-269          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-270          [-1, 160, 32, 32]               0\n",
      "          Conv2d-271          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-272          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-273          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-274          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-275          [-1, 960, 34, 34]               0\n",
      "           ReLU6-276          [-1, 960, 34, 34]               0\n",
      "          Conv2d-277          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-278          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-279          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-280          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-281          [-1, 960, 32, 32]               0\n",
      "           ReLU6-282          [-1, 960, 32, 32]               0\n",
      "          Conv2d-283          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-284          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-285          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-286          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-287          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-288          [-1, 160, 32, 32]               0\n",
      "          Conv2d-289          [-1, 960, 36, 36]         153,600\n",
      "          Conv2d-290          [-1, 960, 36, 36]         153,600\n",
      "     BatchNorm2d-291          [-1, 960, 36, 36]           1,920\n",
      "     BatchNorm2d-292          [-1, 960, 36, 36]           1,920\n",
      "           ReLU6-293          [-1, 960, 36, 36]               0\n",
      "           ReLU6-294          [-1, 960, 36, 36]               0\n",
      "          Conv2d-295          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-296          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-297          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-298          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-299          [-1, 960, 32, 32]               0\n",
      "           ReLU6-300          [-1, 960, 32, 32]               0\n",
      "          Conv2d-301          [-1, 320, 32, 32]         307,200\n",
      "          Conv2d-302          [-1, 320, 32, 32]         307,200\n",
      "     BatchNorm2d-303          [-1, 320, 32, 32]             640\n",
      "     BatchNorm2d-304          [-1, 320, 32, 32]             640\n",
      "InvertedResidual-305          [-1, 320, 32, 32]               0\n",
      "InvertedResidual-306          [-1, 320, 32, 32]               0\n",
      "     MobileNetV2-307  [[-1, 320, 32, 32], [-1, 24, 128, 128]]               0\n",
      "          Conv2d-308          [-1, 256, 32, 32]          81,920\n",
      "     BatchNorm2d-309          [-1, 256, 32, 32]             512\n",
      "            ReLU-310          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-311          [-1, 256, 32, 32]               0\n",
      "          Conv2d-312          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-313          [-1, 256, 32, 32]             512\n",
      "            ReLU-314          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-315          [-1, 256, 32, 32]               0\n",
      "          Conv2d-316          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-317          [-1, 256, 32, 32]             512\n",
      "            ReLU-318          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-319          [-1, 256, 32, 32]               0\n",
      "          Conv2d-320          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-321          [-1, 256, 32, 32]             512\n",
      "            ReLU-322          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-323          [-1, 256, 32, 32]               0\n",
      "AdaptiveAvgPool2d-324            [-1, 320, 1, 1]               0\n",
      "          Conv2d-325            [-1, 256, 1, 1]          81,920\n",
      "     BatchNorm2d-326            [-1, 256, 1, 1]             512\n",
      "            ReLU-327            [-1, 256, 1, 1]               0\n",
      "          Conv2d-328          [-1, 256, 32, 32]         327,680\n",
      "     BatchNorm2d-329          [-1, 256, 32, 32]             512\n",
      "            ReLU-330          [-1, 256, 32, 32]               0\n",
      "          Conv2d-331         [-1, 48, 128, 128]           1,152\n",
      "     BatchNorm2d-332         [-1, 48, 128, 128]              96\n",
      "            ReLU-333         [-1, 48, 128, 128]               0\n",
      "          Conv2d-334        [-1, 256, 128, 128]         700,416\n",
      "     BatchNorm2d-335        [-1, 256, 128, 128]             512\n",
      "            ReLU-336        [-1, 256, 128, 128]               0\n",
      "          Conv2d-337        [-1, 256, 128, 128]         589,824\n",
      "     BatchNorm2d-338        [-1, 256, 128, 128]             512\n",
      "            ReLU-339        [-1, 256, 128, 128]               0\n",
      "          Conv2d-340          [-1, 1, 128, 128]             257\n",
      "================================================================\n",
      "Total params: 7,622,625\n",
      "Trainable params: 7,622,625\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 980897.41\n",
      "Params size (MB): 29.08\n",
      "Estimated Total Size (MB): 980929.49\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "deeplab_mobilenet = DeepLabv3_plus_mobilenet(nInputChannels=3, n_classes=1, os=16, pretrained=False, _print=True).eval().cuda()\n",
    "summary(deeplab_mobilenet,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f87c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019766807556152344\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = deeplab_mobilenet(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "008e1f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 66.869966\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: module InvertedResidual is treated as a zero-op.\n",
      "Warning: module MobileNetV2 is treated as a zero-op.\n",
      "Warning: module ASPP_module is treated as a zero-op.\n",
      "Warning: module DeepLabv3_plus_mobilenet is treated as a zero-op.\n",
      "DeepLabv3_plus_mobilenet(\n",
      "  7.623 M, 131.178% Params, 29.135 GMac, 100.000% MACs, \n",
      "  (efficient_features): MobileNetV2(\n",
      "    3.623 M, 62.356% Params, 5.256 GMac, 18.040% MACs, \n",
      "    (features): Sequential(\n",
      "      1.812 M, 31.178% Params, 2.628 GMac, 9.020% MACs, \n",
      "      (0): Sequential(\n",
      "        0.001 M, 0.016% Params, 0.063 GMac, 0.216% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.015% Params, 0.057 GMac, 0.194% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.014% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.007% MACs, inplace=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        0.001 M, 0.015% Params, 0.061 GMac, 0.209% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.001 M, 0.015% Params, 0.061 GMac, 0.209% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.005% Params, 0.019 GMac, 0.065% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.014% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.007% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.009% Params, 0.034 GMac, 0.115% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.007% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        0.005 M, 0.088% Params, 0.179 GMac, 0.614% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.005 M, 0.088% Params, 0.179 GMac, 0.614% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.026% Params, 0.102 GMac, 0.351% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.003% Params, 0.013 GMac, 0.044% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.006 GMac, 0.022% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.015% Params, 0.014 GMac, 0.049% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.003% Params, 0.003 GMac, 0.011% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.002 M, 0.040% Params, 0.038 GMac, 0.130% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.003% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        0.009 M, 0.152% Params, 0.151 GMac, 0.520% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.009 M, 0.152% Params, 0.151 GMac, 0.520% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.059% Params, 0.058 GMac, 0.200% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.017% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.022% Params, 0.021 GMac, 0.073% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.016% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (6): Conv2d(0.003 M, 0.059% Params, 0.057 GMac, 0.194% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.003% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        0.01 M, 0.172% Params, 0.092 GMac, 0.316% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.01 M, 0.172% Params, 0.092 GMac, 0.316% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.059% Params, 0.058 GMac, 0.200% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.017% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.022% Params, 0.005 GMac, 0.018% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.005% Params, 0.001 GMac, 0.004% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.005 M, 0.079% Params, 0.019 GMac, 0.065% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.007 GMac, 0.024% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.005% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.106% Params, 0.025 GMac, 0.086% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.007 GMac, 0.024% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.005% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.106% Params, 0.025 GMac, 0.086% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        0.021 M, 0.362% Params, 0.044 GMac, 0.152% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.021 M, 0.362% Params, 0.044 GMac, 0.152% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.002 GMac, 0.006% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.0 GMac, 0.001% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.012 M, 0.211% Params, 0.013 GMac, 0.043% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        0.067 M, 1.147% Params, 0.072 GMac, 0.249% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.067 M, 1.147% Params, 0.072 GMac, 0.249% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.037 M, 0.634% Params, 0.038 GMac, 0.130% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 0.952% Params, 0.057 GMac, 0.194% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 0.952% Params, 0.057 GMac, 0.194% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        0.155 M, 2.672% Params, 0.168 GMac, 0.576% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.155 M, 2.672% Params, 0.168 GMac, 0.576% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.092 M, 1.586% Params, 0.094 GMac, 0.324% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.178 GMac, 0.609% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.008% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.643% Params, 0.157 GMac, 0.540% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): InvertedResidual(\n",
      "        0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.178 GMac, 0.609% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.008% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.643% Params, 0.157 GMac, 0.540% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): InvertedResidual(\n",
      "        0.474 M, 8.156% Params, 0.53 GMac, 1.819% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.474 M, 8.156% Params, 0.53 GMac, 1.819% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.199 GMac, 0.683% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.009% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.307 M, 5.287% Params, 0.315 GMac, 1.080% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.002% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (low_level_features): Sequential(\n",
      "      0.016 M, 0.272% Params, 0.454 GMac, 1.558% MACs, \n",
      "      (0): Sequential(\n",
      "        0.001 M, 0.016% Params, 0.063 GMac, 0.216% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.015% Params, 0.057 GMac, 0.194% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.014% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.007% MACs, inplace=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        0.001 M, 0.015% Params, 0.061 GMac, 0.209% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.001 M, 0.015% Params, 0.061 GMac, 0.209% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.005% Params, 0.019 GMac, 0.065% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.014% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.007% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.009% Params, 0.034 GMac, 0.115% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.007% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        0.005 M, 0.088% Params, 0.179 GMac, 0.614% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.005 M, 0.088% Params, 0.179 GMac, 0.614% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.026% Params, 0.102 GMac, 0.351% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.003% Params, 0.013 GMac, 0.044% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.006 GMac, 0.022% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.015% Params, 0.014 GMac, 0.049% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.003% Params, 0.003 GMac, 0.011% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.002 M, 0.040% Params, 0.038 GMac, 0.130% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.003% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        0.009 M, 0.152% Params, 0.151 GMac, 0.520% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.009 M, 0.152% Params, 0.151 GMac, 0.520% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.059% Params, 0.058 GMac, 0.200% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.017% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.022% Params, 0.021 GMac, 0.073% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.016% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (6): Conv2d(0.003 M, 0.059% Params, 0.057 GMac, 0.194% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.003% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (high_level_features): Sequential(\n",
      "      1.796 M, 30.906% Params, 2.174 GMac, 7.462% MACs, \n",
      "      (4): InvertedResidual(\n",
      "        0.01 M, 0.172% Params, 0.092 GMac, 0.316% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.01 M, 0.172% Params, 0.092 GMac, 0.316% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.059% Params, 0.058 GMac, 0.200% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.005% Params, 0.005 GMac, 0.017% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.022% Params, 0.005 GMac, 0.018% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.005% Params, 0.001 GMac, 0.004% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.005 M, 0.079% Params, 0.019 GMac, 0.065% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.007 GMac, 0.024% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.005% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.106% Params, 0.025 GMac, 0.086% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.256% Params, 0.064 GMac, 0.220% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.007 GMac, 0.024% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.005% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.106% Params, 0.025 GMac, 0.086% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        0.021 M, 0.362% Params, 0.044 GMac, 0.152% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.021 M, 0.362% Params, 0.044 GMac, 0.152% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.106% Params, 0.027 GMac, 0.092% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.006% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.030% Params, 0.002 GMac, 0.006% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.0 GMac, 0.001% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.012 M, 0.211% Params, 0.013 GMac, 0.043% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 0.934% Params, 0.06 GMac, 0.205% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.423% Params, 0.025 GMac, 0.086% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        0.067 M, 1.147% Params, 0.072 GMac, 0.249% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.067 M, 1.147% Params, 0.072 GMac, 0.249% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.423% Params, 0.028 GMac, 0.098% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.059% Params, 0.004 GMac, 0.012% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.013% Params, 0.001 GMac, 0.003% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.037 M, 0.634% Params, 0.038 GMac, 0.130% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 0.952% Params, 0.057 GMac, 0.194% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.035% Params, 0.13 GMac, 0.446% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 0.952% Params, 0.057 GMac, 0.194% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.003% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        0.155 M, 2.672% Params, 0.168 GMac, 0.576% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.155 M, 2.672% Params, 0.168 GMac, 0.576% MACs, \n",
      "          (0): Conv2d(0.055 M, 0.952% Params, 0.064 GMac, 0.219% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.005% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.089% Params, 0.005 GMac, 0.018% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.020% Params, 0.001 GMac, 0.004% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.092 M, 1.586% Params, 0.094 GMac, 0.324% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.178 GMac, 0.609% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.008% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.643% Params, 0.157 GMac, 0.540% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): InvertedResidual(\n",
      "        0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 5.507% Params, 0.35 GMac, 1.202% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.178 GMac, 0.609% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.008% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.643% Params, 0.157 GMac, 0.540% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): InvertedResidual(\n",
      "        0.474 M, 8.156% Params, 0.53 GMac, 1.819% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.474 M, 8.156% Params, 0.53 GMac, 1.819% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.643% Params, 0.199 GMac, 0.683% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.009% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.149% Params, 0.009 GMac, 0.030% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.033% Params, 0.002 GMac, 0.007% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.307 M, 5.287% Params, 0.315 GMac, 1.080% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.002% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aspp1): ASPP_module(\n",
      "    0.082 M, 1.419% Params, 0.085 GMac, 0.291% MACs, \n",
      "    (atrous_convolution): Conv2d(0.082 M, 1.410% Params, 0.084 GMac, 0.288% MACs, 320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.009% Params, 0.001 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp2): ASPP_module(\n",
      "    0.738 M, 12.697% Params, 0.756 GMac, 2.594% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 12.688% Params, 0.755 GMac, 2.591% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.009% Params, 0.001 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp3): ASPP_module(\n",
      "    0.738 M, 12.697% Params, 0.756 GMac, 2.594% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 12.688% Params, 0.755 GMac, 2.591% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.009% Params, 0.001 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp4): ASPP_module(\n",
      "    0.738 M, 12.697% Params, 0.756 GMac, 2.594% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 12.688% Params, 0.755 GMac, 2.591% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.009% Params, 0.001 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, )\n",
      "  (global_avg_pool): Sequential(\n",
      "    0.082 M, 1.419% Params, 0.0 GMac, 0.001% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, output_size=(1, 1))\n",
      "    (1): Conv2d(0.082 M, 1.410% Params, 0.0 GMac, 0.000% MACs, 320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(0.001 M, 0.009% Params, 0.0 GMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (conv1): Conv2d(0.328 M, 5.639% Params, 0.336 GMac, 1.152% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(0.001 M, 0.009% Params, 0.001 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(0.001 M, 0.020% Params, 0.019 GMac, 0.065% MACs, 24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(0.0 M, 0.002% Params, 0.002 GMac, 0.005% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (last_conv): Sequential(\n",
      "    1.292 M, 22.226% Params, 21.169 GMac, 72.658% MACs, \n",
      "    (0): Conv2d(0.7 M, 12.053% Params, 11.476 GMac, 39.388% MACs, 304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(0.001 M, 0.009% Params, 0.008 GMac, 0.029% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.014% MACs, )\n",
      "    (3): Conv2d(0.59 M, 10.150% Params, 9.664 GMac, 33.169% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(0.001 M, 0.009% Params, 0.008 GMac, 0.029% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.014% MACs, )\n",
      "    (6): Conv2d(0.0 M, 0.004% Params, 0.004 GMac, 0.014% MACs, 256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Computational complexity:       29.13 GMac\n",
      "Number of parameters:           5.81 M  \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= deeplab_mobilenet(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))\n",
    "\n",
    "macs, params = get_model_complexity_info(deeplab_mobilenet, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e263d",
   "metadata": {},
   "source": [
    "# DeepLabV3+ Mobilenet ghost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9789dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True, is_relu6=False):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.oup = oup\n",
    "        init_channels = math.ceil(oup / ratio)\n",
    "        new_channels = init_channels*(ratio-1)\n",
    "        if is_relu6:\n",
    "            self.primary_conv = nn.Sequential(\n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "                nn.BatchNorm2d(init_channels),\n",
    "                nn.ReLU6(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels),\n",
    "                nn.ReLU6(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "        else:\n",
    "            self.primary_conv = nn.Sequential(\n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "                nn.BatchNorm2d(init_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )            \n",
    "    def forward(self, x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = torch.cat([x1,x2], dim=1)\n",
    "        return out[:,:self.oup,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1434fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp, oup, stride, BatchNorm):\n",
    "    return nn.Sequential(\n",
    "        GhostModule(inp, oup, kernel_size=3, stride=stride, relu=True, is_relu6=True)\n",
    "#         nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "#         BatchNorm(oup),\n",
    "#         nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, dilation, expand_ratio, BatchNorm):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "        self.kernel_size = 3\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 0, dilation, groups=hidden_dim, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, 1, 1, bias=False),\n",
    "                BatchNorm(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, 1, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 0, dilation, groups=hidden_dim, bias=False),\n",
    "                BatchNorm(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, 1, bias=False),\n",
    "                BatchNorm(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pad = fixed_padding(x, self.kernel_size, dilation=self.dilation)\n",
    "        if self.use_res_connect:\n",
    "            x = x + self.conv(x_pad)\n",
    "        else:\n",
    "            x = self.conv(x_pad)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, output_stride=16, BatchNorm=None, width_mult=1., pretrained=False):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        current_stride = 1\n",
    "        rate = 1\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.features = [conv_bn(3, input_channel, 2, BatchNorm)]\n",
    "        current_stride *= 2\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            if current_stride == output_stride:\n",
    "                stride = 1\n",
    "                dilation = rate\n",
    "                rate *= s\n",
    "            else:\n",
    "                stride = s\n",
    "                dilation = 1\n",
    "                current_stride *= s\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, stride, dilation, t, BatchNorm))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, dilation, t, BatchNorm))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if pretrained:\n",
    "            self._load_pretrained_model()\n",
    "\n",
    "        self.low_level_features = self.features[0:4]\n",
    "        self.high_level_features = self.features[4:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        low_level_feat = self.low_level_features(x)\n",
    "        x = self.high_level_features(low_level_feat)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _load_pretrained_model(self):\n",
    "        pretrain_dict = model_zoo.load_url('http://jeff95.me/models/mobilenet_v2-6a65762b.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "        for k, v in pretrain_dict.items():\n",
    "            if k in state_dict:\n",
    "                model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            # elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "            #     m.weight.data.fill_(1)\n",
    "            #     m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "670eaca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, rate):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "742162f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabv3_plus_mobilenet_ghost(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus_mobilenet_ghost, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.efficient_features = MobileNetV2(output_stride=16, BatchNorm=nn.BatchNorm2d)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(320, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP_module(320, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP_module(320, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP_module(320, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             GhostModule(320, 256, kernel_size=1, stride=1, relu=True)\n",
    "#                                              nn.Conv2d(320, 256, 1, stride=1, bias=False),\n",
    "#                                              nn.BatchNorm2d(256),\n",
    "#                                              nn.ReLU()\n",
    "                                            )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(24, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(GhostModule(304, 256, kernel_size=3, stride=1, relu=True),\n",
    "                                       GhostModule(256, 256, kernel_size=3, stride=1, relu=True),\n",
    "#             nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "#                                        nn.BatchNorm2d(256),\n",
    "#                                        nn.ReLU(),\n",
    "#                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "#                                        nn.BatchNorm2d(256),\n",
    "#                                        nn.ReLU(),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.efficient_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                # torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "042dee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             432\n",
      "            Conv2d-2         [-1, 16, 256, 256]             432\n",
      "       BatchNorm2d-3         [-1, 16, 256, 256]              32\n",
      "       BatchNorm2d-4         [-1, 16, 256, 256]              32\n",
      "             ReLU6-5         [-1, 16, 256, 256]               0\n",
      "             ReLU6-6         [-1, 16, 256, 256]               0\n",
      "            Conv2d-7         [-1, 16, 256, 256]             144\n",
      "            Conv2d-8         [-1, 16, 256, 256]             144\n",
      "       BatchNorm2d-9         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-10         [-1, 16, 256, 256]              32\n",
      "            ReLU6-11         [-1, 16, 256, 256]               0\n",
      "            ReLU6-12         [-1, 16, 256, 256]               0\n",
      "      GhostModule-13         [-1, 32, 256, 256]               0\n",
      "      GhostModule-14         [-1, 32, 256, 256]               0\n",
      "           Conv2d-15         [-1, 32, 256, 256]             288\n",
      "           Conv2d-16         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-17         [-1, 32, 256, 256]              64\n",
      "      BatchNorm2d-18         [-1, 32, 256, 256]              64\n",
      "            ReLU6-19         [-1, 32, 256, 256]               0\n",
      "            ReLU6-20         [-1, 32, 256, 256]               0\n",
      "           Conv2d-21         [-1, 16, 256, 256]             512\n",
      "           Conv2d-22         [-1, 16, 256, 256]             512\n",
      "      BatchNorm2d-23         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-24         [-1, 16, 256, 256]              32\n",
      " InvertedResidual-25         [-1, 16, 256, 256]               0\n",
      " InvertedResidual-26         [-1, 16, 256, 256]               0\n",
      "           Conv2d-27         [-1, 96, 258, 258]           1,536\n",
      "           Conv2d-28         [-1, 96, 258, 258]           1,536\n",
      "      BatchNorm2d-29         [-1, 96, 258, 258]             192\n",
      "      BatchNorm2d-30         [-1, 96, 258, 258]             192\n",
      "            ReLU6-31         [-1, 96, 258, 258]               0\n",
      "            ReLU6-32         [-1, 96, 258, 258]               0\n",
      "           Conv2d-33         [-1, 96, 128, 128]             864\n",
      "           Conv2d-34         [-1, 96, 128, 128]             864\n",
      "      BatchNorm2d-35         [-1, 96, 128, 128]             192\n",
      "      BatchNorm2d-36         [-1, 96, 128, 128]             192\n",
      "            ReLU6-37         [-1, 96, 128, 128]               0\n",
      "            ReLU6-38         [-1, 96, 128, 128]               0\n",
      "           Conv2d-39         [-1, 24, 128, 128]           2,304\n",
      "           Conv2d-40         [-1, 24, 128, 128]           2,304\n",
      "      BatchNorm2d-41         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-42         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-43         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-44         [-1, 24, 128, 128]               0\n",
      "           Conv2d-45        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-46        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-47        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-48        [-1, 144, 130, 130]             288\n",
      "            ReLU6-49        [-1, 144, 130, 130]               0\n",
      "            ReLU6-50        [-1, 144, 130, 130]               0\n",
      "           Conv2d-51        [-1, 144, 128, 128]           1,296\n",
      "           Conv2d-52        [-1, 144, 128, 128]           1,296\n",
      "      BatchNorm2d-53        [-1, 144, 128, 128]             288\n",
      "      BatchNorm2d-54        [-1, 144, 128, 128]             288\n",
      "            ReLU6-55        [-1, 144, 128, 128]               0\n",
      "            ReLU6-56        [-1, 144, 128, 128]               0\n",
      "           Conv2d-57         [-1, 24, 128, 128]           3,456\n",
      "           Conv2d-58         [-1, 24, 128, 128]           3,456\n",
      "      BatchNorm2d-59         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-60         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-61         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-62         [-1, 24, 128, 128]               0\n",
      "           Conv2d-63        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-64        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-65        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-66        [-1, 144, 130, 130]             288\n",
      "            ReLU6-67        [-1, 144, 130, 130]               0\n",
      "            ReLU6-68        [-1, 144, 130, 130]               0\n",
      "           Conv2d-69          [-1, 144, 64, 64]           1,296\n",
      "           Conv2d-70          [-1, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-71          [-1, 144, 64, 64]             288\n",
      "      BatchNorm2d-72          [-1, 144, 64, 64]             288\n",
      "            ReLU6-73          [-1, 144, 64, 64]               0\n",
      "            ReLU6-74          [-1, 144, 64, 64]               0\n",
      "           Conv2d-75           [-1, 32, 64, 64]           4,608\n",
      "           Conv2d-76           [-1, 32, 64, 64]           4,608\n",
      "      BatchNorm2d-77           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-78           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-79           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-80           [-1, 32, 64, 64]               0\n",
      "           Conv2d-81          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-82          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-83          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-84          [-1, 192, 66, 66]             384\n",
      "            ReLU6-85          [-1, 192, 66, 66]               0\n",
      "            ReLU6-86          [-1, 192, 66, 66]               0\n",
      "           Conv2d-87          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-88          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-89          [-1, 192, 64, 64]             384\n",
      "      BatchNorm2d-90          [-1, 192, 64, 64]             384\n",
      "            ReLU6-91          [-1, 192, 64, 64]               0\n",
      "            ReLU6-92          [-1, 192, 64, 64]               0\n",
      "           Conv2d-93           [-1, 32, 64, 64]           6,144\n",
      "           Conv2d-94           [-1, 32, 64, 64]           6,144\n",
      "      BatchNorm2d-95           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-96           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-97           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-98           [-1, 32, 64, 64]               0\n",
      "           Conv2d-99          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-100          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-101          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-102          [-1, 192, 66, 66]             384\n",
      "           ReLU6-103          [-1, 192, 66, 66]               0\n",
      "           ReLU6-104          [-1, 192, 66, 66]               0\n",
      "          Conv2d-105          [-1, 192, 64, 64]           1,728\n",
      "          Conv2d-106          [-1, 192, 64, 64]           1,728\n",
      "     BatchNorm2d-107          [-1, 192, 64, 64]             384\n",
      "     BatchNorm2d-108          [-1, 192, 64, 64]             384\n",
      "           ReLU6-109          [-1, 192, 64, 64]               0\n",
      "           ReLU6-110          [-1, 192, 64, 64]               0\n",
      "          Conv2d-111           [-1, 32, 64, 64]           6,144\n",
      "          Conv2d-112           [-1, 32, 64, 64]           6,144\n",
      "     BatchNorm2d-113           [-1, 32, 64, 64]              64\n",
      "     BatchNorm2d-114           [-1, 32, 64, 64]              64\n",
      "InvertedResidual-115           [-1, 32, 64, 64]               0\n",
      "InvertedResidual-116           [-1, 32, 64, 64]               0\n",
      "          Conv2d-117          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-118          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-119          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-120          [-1, 192, 66, 66]             384\n",
      "           ReLU6-121          [-1, 192, 66, 66]               0\n",
      "           ReLU6-122          [-1, 192, 66, 66]               0\n",
      "          Conv2d-123          [-1, 192, 32, 32]           1,728\n",
      "          Conv2d-124          [-1, 192, 32, 32]           1,728\n",
      "     BatchNorm2d-125          [-1, 192, 32, 32]             384\n",
      "     BatchNorm2d-126          [-1, 192, 32, 32]             384\n",
      "           ReLU6-127          [-1, 192, 32, 32]               0\n",
      "           ReLU6-128          [-1, 192, 32, 32]               0\n",
      "          Conv2d-129           [-1, 64, 32, 32]          12,288\n",
      "          Conv2d-130           [-1, 64, 32, 32]          12,288\n",
      "     BatchNorm2d-131           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-132           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-133           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-134           [-1, 64, 32, 32]               0\n",
      "          Conv2d-135          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-136          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-137          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-138          [-1, 384, 34, 34]             768\n",
      "           ReLU6-139          [-1, 384, 34, 34]               0\n",
      "           ReLU6-140          [-1, 384, 34, 34]               0\n",
      "          Conv2d-141          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-142          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-143          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-144          [-1, 384, 32, 32]             768\n",
      "           ReLU6-145          [-1, 384, 32, 32]               0\n",
      "           ReLU6-146          [-1, 384, 32, 32]               0\n",
      "          Conv2d-147           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-148           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-149           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-150           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-151           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-152           [-1, 64, 32, 32]               0\n",
      "          Conv2d-153          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-154          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-155          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-156          [-1, 384, 34, 34]             768\n",
      "           ReLU6-157          [-1, 384, 34, 34]               0\n",
      "           ReLU6-158          [-1, 384, 34, 34]               0\n",
      "          Conv2d-159          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-160          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-161          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-162          [-1, 384, 32, 32]             768\n",
      "           ReLU6-163          [-1, 384, 32, 32]               0\n",
      "           ReLU6-164          [-1, 384, 32, 32]               0\n",
      "          Conv2d-165           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-166           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-167           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-168           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-169           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-170           [-1, 64, 32, 32]               0\n",
      "          Conv2d-171          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-172          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-173          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-174          [-1, 384, 34, 34]             768\n",
      "           ReLU6-175          [-1, 384, 34, 34]               0\n",
      "           ReLU6-176          [-1, 384, 34, 34]               0\n",
      "          Conv2d-177          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-178          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-179          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-180          [-1, 384, 32, 32]             768\n",
      "           ReLU6-181          [-1, 384, 32, 32]               0\n",
      "           ReLU6-182          [-1, 384, 32, 32]               0\n",
      "          Conv2d-183           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-184           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-185           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-186           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-187           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-188           [-1, 64, 32, 32]               0\n",
      "          Conv2d-189          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-190          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-191          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-192          [-1, 384, 34, 34]             768\n",
      "           ReLU6-193          [-1, 384, 34, 34]               0\n",
      "           ReLU6-194          [-1, 384, 34, 34]               0\n",
      "          Conv2d-195          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-196          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-197          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-198          [-1, 384, 32, 32]             768\n",
      "           ReLU6-199          [-1, 384, 32, 32]               0\n",
      "           ReLU6-200          [-1, 384, 32, 32]               0\n",
      "          Conv2d-201           [-1, 96, 32, 32]          36,864\n",
      "          Conv2d-202           [-1, 96, 32, 32]          36,864\n",
      "     BatchNorm2d-203           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-204           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-205           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-206           [-1, 96, 32, 32]               0\n",
      "          Conv2d-207          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-208          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-209          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-210          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-211          [-1, 576, 34, 34]               0\n",
      "           ReLU6-212          [-1, 576, 34, 34]               0\n",
      "          Conv2d-213          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-214          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-215          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-216          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-217          [-1, 576, 32, 32]               0\n",
      "           ReLU6-218          [-1, 576, 32, 32]               0\n",
      "          Conv2d-219           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-220           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-221           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-222           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-223           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-224           [-1, 96, 32, 32]               0\n",
      "          Conv2d-225          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-226          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-227          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-228          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-229          [-1, 576, 34, 34]               0\n",
      "           ReLU6-230          [-1, 576, 34, 34]               0\n",
      "          Conv2d-231          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-232          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-233          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-234          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-235          [-1, 576, 32, 32]               0\n",
      "           ReLU6-236          [-1, 576, 32, 32]               0\n",
      "          Conv2d-237           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-238           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-239           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-240           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-241           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-242           [-1, 96, 32, 32]               0\n",
      "          Conv2d-243          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-244          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-245          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-246          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-247          [-1, 576, 34, 34]               0\n",
      "           ReLU6-248          [-1, 576, 34, 34]               0\n",
      "          Conv2d-249          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-250          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-251          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-252          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-253          [-1, 576, 32, 32]               0\n",
      "           ReLU6-254          [-1, 576, 32, 32]               0\n",
      "          Conv2d-255          [-1, 160, 32, 32]          92,160\n",
      "          Conv2d-256          [-1, 160, 32, 32]          92,160\n",
      "     BatchNorm2d-257          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-258          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-259          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-260          [-1, 160, 32, 32]               0\n",
      "          Conv2d-261          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-262          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-263          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-264          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-265          [-1, 960, 34, 34]               0\n",
      "           ReLU6-266          [-1, 960, 34, 34]               0\n",
      "          Conv2d-267          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-268          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-269          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-270          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-271          [-1, 960, 32, 32]               0\n",
      "           ReLU6-272          [-1, 960, 32, 32]               0\n",
      "          Conv2d-273          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-274          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-275          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-276          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-277          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-278          [-1, 160, 32, 32]               0\n",
      "          Conv2d-279          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-280          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-281          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-282          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-283          [-1, 960, 34, 34]               0\n",
      "           ReLU6-284          [-1, 960, 34, 34]               0\n",
      "          Conv2d-285          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-286          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-287          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-288          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-289          [-1, 960, 32, 32]               0\n",
      "           ReLU6-290          [-1, 960, 32, 32]               0\n",
      "          Conv2d-291          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-292          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-293          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-294          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-295          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-296          [-1, 160, 32, 32]               0\n",
      "          Conv2d-297          [-1, 960, 36, 36]         153,600\n",
      "          Conv2d-298          [-1, 960, 36, 36]         153,600\n",
      "     BatchNorm2d-299          [-1, 960, 36, 36]           1,920\n",
      "     BatchNorm2d-300          [-1, 960, 36, 36]           1,920\n",
      "           ReLU6-301          [-1, 960, 36, 36]               0\n",
      "           ReLU6-302          [-1, 960, 36, 36]               0\n",
      "          Conv2d-303          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-304          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-305          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-306          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-307          [-1, 960, 32, 32]               0\n",
      "           ReLU6-308          [-1, 960, 32, 32]               0\n",
      "          Conv2d-309          [-1, 320, 32, 32]         307,200\n",
      "          Conv2d-310          [-1, 320, 32, 32]         307,200\n",
      "     BatchNorm2d-311          [-1, 320, 32, 32]             640\n",
      "     BatchNorm2d-312          [-1, 320, 32, 32]             640\n",
      "InvertedResidual-313          [-1, 320, 32, 32]               0\n",
      "InvertedResidual-314          [-1, 320, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 3,622,848\n",
      "Trainable params: 3,622,848\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 1926.45\n",
      "Params size (MB): 13.82\n",
      "Estimated Total Size (MB): 1943.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "efficient_features = MobileNetV2(output_stride=16, BatchNorm=nn.BatchNorm2d).cuda()\n",
    "summary(efficient_features,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5e0c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): GhostModule(\n",
       "        (primary_conv): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (cheap_operation): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (low_level_features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): GhostModule(\n",
       "        (primary_conv): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (cheap_operation): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (high_level_features): Sequential(\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficient_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ac7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             432\n",
      "            Conv2d-2         [-1, 16, 256, 256]             432\n",
      "       BatchNorm2d-3         [-1, 16, 256, 256]              32\n",
      "       BatchNorm2d-4         [-1, 16, 256, 256]              32\n",
      "             ReLU6-5         [-1, 16, 256, 256]               0\n",
      "             ReLU6-6         [-1, 16, 256, 256]               0\n",
      "            Conv2d-7         [-1, 16, 256, 256]             144\n",
      "            Conv2d-8         [-1, 16, 256, 256]             144\n",
      "       BatchNorm2d-9         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-10         [-1, 16, 256, 256]              32\n",
      "            ReLU6-11         [-1, 16, 256, 256]               0\n",
      "            ReLU6-12         [-1, 16, 256, 256]               0\n",
      "      GhostModule-13         [-1, 32, 256, 256]               0\n",
      "      GhostModule-14         [-1, 32, 256, 256]               0\n",
      "           Conv2d-15         [-1, 32, 256, 256]             288\n",
      "           Conv2d-16         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-17         [-1, 32, 256, 256]              64\n",
      "      BatchNorm2d-18         [-1, 32, 256, 256]              64\n",
      "            ReLU6-19         [-1, 32, 256, 256]               0\n",
      "            ReLU6-20         [-1, 32, 256, 256]               0\n",
      "           Conv2d-21         [-1, 16, 256, 256]             512\n",
      "           Conv2d-22         [-1, 16, 256, 256]             512\n",
      "      BatchNorm2d-23         [-1, 16, 256, 256]              32\n",
      "      BatchNorm2d-24         [-1, 16, 256, 256]              32\n",
      " InvertedResidual-25         [-1, 16, 256, 256]               0\n",
      " InvertedResidual-26         [-1, 16, 256, 256]               0\n",
      "           Conv2d-27         [-1, 96, 258, 258]           1,536\n",
      "           Conv2d-28         [-1, 96, 258, 258]           1,536\n",
      "      BatchNorm2d-29         [-1, 96, 258, 258]             192\n",
      "      BatchNorm2d-30         [-1, 96, 258, 258]             192\n",
      "            ReLU6-31         [-1, 96, 258, 258]               0\n",
      "            ReLU6-32         [-1, 96, 258, 258]               0\n",
      "           Conv2d-33         [-1, 96, 128, 128]             864\n",
      "           Conv2d-34         [-1, 96, 128, 128]             864\n",
      "      BatchNorm2d-35         [-1, 96, 128, 128]             192\n",
      "      BatchNorm2d-36         [-1, 96, 128, 128]             192\n",
      "            ReLU6-37         [-1, 96, 128, 128]               0\n",
      "            ReLU6-38         [-1, 96, 128, 128]               0\n",
      "           Conv2d-39         [-1, 24, 128, 128]           2,304\n",
      "           Conv2d-40         [-1, 24, 128, 128]           2,304\n",
      "      BatchNorm2d-41         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-42         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-43         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-44         [-1, 24, 128, 128]               0\n",
      "           Conv2d-45        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-46        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-47        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-48        [-1, 144, 130, 130]             288\n",
      "            ReLU6-49        [-1, 144, 130, 130]               0\n",
      "            ReLU6-50        [-1, 144, 130, 130]               0\n",
      "           Conv2d-51        [-1, 144, 128, 128]           1,296\n",
      "           Conv2d-52        [-1, 144, 128, 128]           1,296\n",
      "      BatchNorm2d-53        [-1, 144, 128, 128]             288\n",
      "      BatchNorm2d-54        [-1, 144, 128, 128]             288\n",
      "            ReLU6-55        [-1, 144, 128, 128]               0\n",
      "            ReLU6-56        [-1, 144, 128, 128]               0\n",
      "           Conv2d-57         [-1, 24, 128, 128]           3,456\n",
      "           Conv2d-58         [-1, 24, 128, 128]           3,456\n",
      "      BatchNorm2d-59         [-1, 24, 128, 128]              48\n",
      "      BatchNorm2d-60         [-1, 24, 128, 128]              48\n",
      " InvertedResidual-61         [-1, 24, 128, 128]               0\n",
      " InvertedResidual-62         [-1, 24, 128, 128]               0\n",
      "           Conv2d-63        [-1, 144, 130, 130]           3,456\n",
      "           Conv2d-64        [-1, 144, 130, 130]           3,456\n",
      "      BatchNorm2d-65        [-1, 144, 130, 130]             288\n",
      "      BatchNorm2d-66        [-1, 144, 130, 130]             288\n",
      "            ReLU6-67        [-1, 144, 130, 130]               0\n",
      "            ReLU6-68        [-1, 144, 130, 130]               0\n",
      "           Conv2d-69          [-1, 144, 64, 64]           1,296\n",
      "           Conv2d-70          [-1, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-71          [-1, 144, 64, 64]             288\n",
      "      BatchNorm2d-72          [-1, 144, 64, 64]             288\n",
      "            ReLU6-73          [-1, 144, 64, 64]               0\n",
      "            ReLU6-74          [-1, 144, 64, 64]               0\n",
      "           Conv2d-75           [-1, 32, 64, 64]           4,608\n",
      "           Conv2d-76           [-1, 32, 64, 64]           4,608\n",
      "      BatchNorm2d-77           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-78           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-79           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-80           [-1, 32, 64, 64]               0\n",
      "           Conv2d-81          [-1, 192, 66, 66]           6,144\n",
      "           Conv2d-82          [-1, 192, 66, 66]           6,144\n",
      "      BatchNorm2d-83          [-1, 192, 66, 66]             384\n",
      "      BatchNorm2d-84          [-1, 192, 66, 66]             384\n",
      "            ReLU6-85          [-1, 192, 66, 66]               0\n",
      "            ReLU6-86          [-1, 192, 66, 66]               0\n",
      "           Conv2d-87          [-1, 192, 64, 64]           1,728\n",
      "           Conv2d-88          [-1, 192, 64, 64]           1,728\n",
      "      BatchNorm2d-89          [-1, 192, 64, 64]             384\n",
      "      BatchNorm2d-90          [-1, 192, 64, 64]             384\n",
      "            ReLU6-91          [-1, 192, 64, 64]               0\n",
      "            ReLU6-92          [-1, 192, 64, 64]               0\n",
      "           Conv2d-93           [-1, 32, 64, 64]           6,144\n",
      "           Conv2d-94           [-1, 32, 64, 64]           6,144\n",
      "      BatchNorm2d-95           [-1, 32, 64, 64]              64\n",
      "      BatchNorm2d-96           [-1, 32, 64, 64]              64\n",
      " InvertedResidual-97           [-1, 32, 64, 64]               0\n",
      " InvertedResidual-98           [-1, 32, 64, 64]               0\n",
      "           Conv2d-99          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-100          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-101          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-102          [-1, 192, 66, 66]             384\n",
      "           ReLU6-103          [-1, 192, 66, 66]               0\n",
      "           ReLU6-104          [-1, 192, 66, 66]               0\n",
      "          Conv2d-105          [-1, 192, 64, 64]           1,728\n",
      "          Conv2d-106          [-1, 192, 64, 64]           1,728\n",
      "     BatchNorm2d-107          [-1, 192, 64, 64]             384\n",
      "     BatchNorm2d-108          [-1, 192, 64, 64]             384\n",
      "           ReLU6-109          [-1, 192, 64, 64]               0\n",
      "           ReLU6-110          [-1, 192, 64, 64]               0\n",
      "          Conv2d-111           [-1, 32, 64, 64]           6,144\n",
      "          Conv2d-112           [-1, 32, 64, 64]           6,144\n",
      "     BatchNorm2d-113           [-1, 32, 64, 64]              64\n",
      "     BatchNorm2d-114           [-1, 32, 64, 64]              64\n",
      "InvertedResidual-115           [-1, 32, 64, 64]               0\n",
      "InvertedResidual-116           [-1, 32, 64, 64]               0\n",
      "          Conv2d-117          [-1, 192, 66, 66]           6,144\n",
      "          Conv2d-118          [-1, 192, 66, 66]           6,144\n",
      "     BatchNorm2d-119          [-1, 192, 66, 66]             384\n",
      "     BatchNorm2d-120          [-1, 192, 66, 66]             384\n",
      "           ReLU6-121          [-1, 192, 66, 66]               0\n",
      "           ReLU6-122          [-1, 192, 66, 66]               0\n",
      "          Conv2d-123          [-1, 192, 32, 32]           1,728\n",
      "          Conv2d-124          [-1, 192, 32, 32]           1,728\n",
      "     BatchNorm2d-125          [-1, 192, 32, 32]             384\n",
      "     BatchNorm2d-126          [-1, 192, 32, 32]             384\n",
      "           ReLU6-127          [-1, 192, 32, 32]               0\n",
      "           ReLU6-128          [-1, 192, 32, 32]               0\n",
      "          Conv2d-129           [-1, 64, 32, 32]          12,288\n",
      "          Conv2d-130           [-1, 64, 32, 32]          12,288\n",
      "     BatchNorm2d-131           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-132           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-133           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-134           [-1, 64, 32, 32]               0\n",
      "          Conv2d-135          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-136          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-137          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-138          [-1, 384, 34, 34]             768\n",
      "           ReLU6-139          [-1, 384, 34, 34]               0\n",
      "           ReLU6-140          [-1, 384, 34, 34]               0\n",
      "          Conv2d-141          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-142          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-143          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-144          [-1, 384, 32, 32]             768\n",
      "           ReLU6-145          [-1, 384, 32, 32]               0\n",
      "           ReLU6-146          [-1, 384, 32, 32]               0\n",
      "          Conv2d-147           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-148           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-149           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-150           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-151           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-152           [-1, 64, 32, 32]               0\n",
      "          Conv2d-153          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-154          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-155          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-156          [-1, 384, 34, 34]             768\n",
      "           ReLU6-157          [-1, 384, 34, 34]               0\n",
      "           ReLU6-158          [-1, 384, 34, 34]               0\n",
      "          Conv2d-159          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-160          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-161          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-162          [-1, 384, 32, 32]             768\n",
      "           ReLU6-163          [-1, 384, 32, 32]               0\n",
      "           ReLU6-164          [-1, 384, 32, 32]               0\n",
      "          Conv2d-165           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-166           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-167           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-168           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-169           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-170           [-1, 64, 32, 32]               0\n",
      "          Conv2d-171          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-172          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-173          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-174          [-1, 384, 34, 34]             768\n",
      "           ReLU6-175          [-1, 384, 34, 34]               0\n",
      "           ReLU6-176          [-1, 384, 34, 34]               0\n",
      "          Conv2d-177          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-178          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-179          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-180          [-1, 384, 32, 32]             768\n",
      "           ReLU6-181          [-1, 384, 32, 32]               0\n",
      "           ReLU6-182          [-1, 384, 32, 32]               0\n",
      "          Conv2d-183           [-1, 64, 32, 32]          24,576\n",
      "          Conv2d-184           [-1, 64, 32, 32]          24,576\n",
      "     BatchNorm2d-185           [-1, 64, 32, 32]             128\n",
      "     BatchNorm2d-186           [-1, 64, 32, 32]             128\n",
      "InvertedResidual-187           [-1, 64, 32, 32]               0\n",
      "InvertedResidual-188           [-1, 64, 32, 32]               0\n",
      "          Conv2d-189          [-1, 384, 34, 34]          24,576\n",
      "          Conv2d-190          [-1, 384, 34, 34]          24,576\n",
      "     BatchNorm2d-191          [-1, 384, 34, 34]             768\n",
      "     BatchNorm2d-192          [-1, 384, 34, 34]             768\n",
      "           ReLU6-193          [-1, 384, 34, 34]               0\n",
      "           ReLU6-194          [-1, 384, 34, 34]               0\n",
      "          Conv2d-195          [-1, 384, 32, 32]           3,456\n",
      "          Conv2d-196          [-1, 384, 32, 32]           3,456\n",
      "     BatchNorm2d-197          [-1, 384, 32, 32]             768\n",
      "     BatchNorm2d-198          [-1, 384, 32, 32]             768\n",
      "           ReLU6-199          [-1, 384, 32, 32]               0\n",
      "           ReLU6-200          [-1, 384, 32, 32]               0\n",
      "          Conv2d-201           [-1, 96, 32, 32]          36,864\n",
      "          Conv2d-202           [-1, 96, 32, 32]          36,864\n",
      "     BatchNorm2d-203           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-204           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-205           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-206           [-1, 96, 32, 32]               0\n",
      "          Conv2d-207          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-208          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-209          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-210          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-211          [-1, 576, 34, 34]               0\n",
      "           ReLU6-212          [-1, 576, 34, 34]               0\n",
      "          Conv2d-213          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-214          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-215          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-216          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-217          [-1, 576, 32, 32]               0\n",
      "           ReLU6-218          [-1, 576, 32, 32]               0\n",
      "          Conv2d-219           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-220           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-221           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-222           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-223           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-224           [-1, 96, 32, 32]               0\n",
      "          Conv2d-225          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-226          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-227          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-228          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-229          [-1, 576, 34, 34]               0\n",
      "           ReLU6-230          [-1, 576, 34, 34]               0\n",
      "          Conv2d-231          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-232          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-233          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-234          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-235          [-1, 576, 32, 32]               0\n",
      "           ReLU6-236          [-1, 576, 32, 32]               0\n",
      "          Conv2d-237           [-1, 96, 32, 32]          55,296\n",
      "          Conv2d-238           [-1, 96, 32, 32]          55,296\n",
      "     BatchNorm2d-239           [-1, 96, 32, 32]             192\n",
      "     BatchNorm2d-240           [-1, 96, 32, 32]             192\n",
      "InvertedResidual-241           [-1, 96, 32, 32]               0\n",
      "InvertedResidual-242           [-1, 96, 32, 32]               0\n",
      "          Conv2d-243          [-1, 576, 34, 34]          55,296\n",
      "          Conv2d-244          [-1, 576, 34, 34]          55,296\n",
      "     BatchNorm2d-245          [-1, 576, 34, 34]           1,152\n",
      "     BatchNorm2d-246          [-1, 576, 34, 34]           1,152\n",
      "           ReLU6-247          [-1, 576, 34, 34]               0\n",
      "           ReLU6-248          [-1, 576, 34, 34]               0\n",
      "          Conv2d-249          [-1, 576, 32, 32]           5,184\n",
      "          Conv2d-250          [-1, 576, 32, 32]           5,184\n",
      "     BatchNorm2d-251          [-1, 576, 32, 32]           1,152\n",
      "     BatchNorm2d-252          [-1, 576, 32, 32]           1,152\n",
      "           ReLU6-253          [-1, 576, 32, 32]               0\n",
      "           ReLU6-254          [-1, 576, 32, 32]               0\n",
      "          Conv2d-255          [-1, 160, 32, 32]          92,160\n",
      "          Conv2d-256          [-1, 160, 32, 32]          92,160\n",
      "     BatchNorm2d-257          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-258          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-259          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-260          [-1, 160, 32, 32]               0\n",
      "          Conv2d-261          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-262          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-263          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-264          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-265          [-1, 960, 34, 34]               0\n",
      "           ReLU6-266          [-1, 960, 34, 34]               0\n",
      "          Conv2d-267          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-268          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-269          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-270          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-271          [-1, 960, 32, 32]               0\n",
      "           ReLU6-272          [-1, 960, 32, 32]               0\n",
      "          Conv2d-273          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-274          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-275          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-276          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-277          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-278          [-1, 160, 32, 32]               0\n",
      "          Conv2d-279          [-1, 960, 34, 34]         153,600\n",
      "          Conv2d-280          [-1, 960, 34, 34]         153,600\n",
      "     BatchNorm2d-281          [-1, 960, 34, 34]           1,920\n",
      "     BatchNorm2d-282          [-1, 960, 34, 34]           1,920\n",
      "           ReLU6-283          [-1, 960, 34, 34]               0\n",
      "           ReLU6-284          [-1, 960, 34, 34]               0\n",
      "          Conv2d-285          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-286          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-287          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-288          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-289          [-1, 960, 32, 32]               0\n",
      "           ReLU6-290          [-1, 960, 32, 32]               0\n",
      "          Conv2d-291          [-1, 160, 32, 32]         153,600\n",
      "          Conv2d-292          [-1, 160, 32, 32]         153,600\n",
      "     BatchNorm2d-293          [-1, 160, 32, 32]             320\n",
      "     BatchNorm2d-294          [-1, 160, 32, 32]             320\n",
      "InvertedResidual-295          [-1, 160, 32, 32]               0\n",
      "InvertedResidual-296          [-1, 160, 32, 32]               0\n",
      "          Conv2d-297          [-1, 960, 36, 36]         153,600\n",
      "          Conv2d-298          [-1, 960, 36, 36]         153,600\n",
      "     BatchNorm2d-299          [-1, 960, 36, 36]           1,920\n",
      "     BatchNorm2d-300          [-1, 960, 36, 36]           1,920\n",
      "           ReLU6-301          [-1, 960, 36, 36]               0\n",
      "           ReLU6-302          [-1, 960, 36, 36]               0\n",
      "          Conv2d-303          [-1, 960, 32, 32]           8,640\n",
      "          Conv2d-304          [-1, 960, 32, 32]           8,640\n",
      "     BatchNorm2d-305          [-1, 960, 32, 32]           1,920\n",
      "     BatchNorm2d-306          [-1, 960, 32, 32]           1,920\n",
      "           ReLU6-307          [-1, 960, 32, 32]               0\n",
      "           ReLU6-308          [-1, 960, 32, 32]               0\n",
      "          Conv2d-309          [-1, 320, 32, 32]         307,200\n",
      "          Conv2d-310          [-1, 320, 32, 32]         307,200\n",
      "     BatchNorm2d-311          [-1, 320, 32, 32]             640\n",
      "     BatchNorm2d-312          [-1, 320, 32, 32]             640\n",
      "InvertedResidual-313          [-1, 320, 32, 32]               0\n",
      "InvertedResidual-314          [-1, 320, 32, 32]               0\n",
      "     MobileNetV2-315  [[-1, 320, 32, 32], [-1, 24, 128, 128]]               0\n",
      "          Conv2d-316          [-1, 256, 32, 32]          81,920\n",
      "     BatchNorm2d-317          [-1, 256, 32, 32]             512\n",
      "            ReLU-318          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-319          [-1, 256, 32, 32]               0\n",
      "          Conv2d-320          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-321          [-1, 256, 32, 32]             512\n",
      "            ReLU-322          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-323          [-1, 256, 32, 32]               0\n",
      "          Conv2d-324          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-325          [-1, 256, 32, 32]             512\n",
      "            ReLU-326          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-327          [-1, 256, 32, 32]               0\n",
      "          Conv2d-328          [-1, 256, 32, 32]         737,280\n",
      "     BatchNorm2d-329          [-1, 256, 32, 32]             512\n",
      "            ReLU-330          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-331          [-1, 256, 32, 32]               0\n",
      "AdaptiveAvgPool2d-332            [-1, 320, 1, 1]               0\n",
      "          Conv2d-333            [-1, 128, 1, 1]          40,960\n",
      "     BatchNorm2d-334            [-1, 128, 1, 1]             256\n",
      "            ReLU-335            [-1, 128, 1, 1]               0\n",
      "          Conv2d-336            [-1, 128, 1, 1]           1,152\n",
      "     BatchNorm2d-337            [-1, 128, 1, 1]             256\n",
      "            ReLU-338            [-1, 128, 1, 1]               0\n",
      "     GhostModule-339            [-1, 256, 1, 1]               0\n",
      "          Conv2d-340          [-1, 256, 32, 32]         327,680\n",
      "     BatchNorm2d-341          [-1, 256, 32, 32]             512\n",
      "            ReLU-342          [-1, 256, 32, 32]               0\n",
      "          Conv2d-343         [-1, 48, 128, 128]           1,152\n",
      "     BatchNorm2d-344         [-1, 48, 128, 128]              96\n",
      "            ReLU-345         [-1, 48, 128, 128]               0\n",
      "          Conv2d-346        [-1, 128, 128, 128]         350,208\n",
      "     BatchNorm2d-347        [-1, 128, 128, 128]             256\n",
      "            ReLU-348        [-1, 128, 128, 128]               0\n",
      "          Conv2d-349        [-1, 128, 128, 128]           1,152\n",
      "     BatchNorm2d-350        [-1, 128, 128, 128]             256\n",
      "            ReLU-351        [-1, 128, 128, 128]               0\n",
      "     GhostModule-352        [-1, 256, 128, 128]               0\n",
      "          Conv2d-353        [-1, 128, 128, 128]         294,912\n",
      "     BatchNorm2d-354        [-1, 128, 128, 128]             256\n",
      "            ReLU-355        [-1, 128, 128, 128]               0\n",
      "          Conv2d-356        [-1, 128, 128, 128]           1,152\n",
      "     BatchNorm2d-357        [-1, 128, 128, 128]             256\n",
      "            ReLU-358        [-1, 128, 128, 128]               0\n",
      "     GhostModule-359        [-1, 256, 128, 128]               0\n",
      "          Conv2d-360          [-1, 1, 128, 128]             257\n",
      "================================================================\n",
      "Total params: 6,939,425\n",
      "Trainable params: 6,939,425\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 980801.41\n",
      "Params size (MB): 26.47\n",
      "Estimated Total Size (MB): 980830.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "deeplab_mobilenet_ghost = DeepLabv3_plus_mobilenet_ghost(nInputChannels=3, n_classes=1, os=16, pretrained=False, _print=True).eval().cuda()\n",
    "summary(deeplab_mobilenet_ghost,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0811b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01770472526550293\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = deeplab_mobilenet_ghost(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31224f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = []\n",
    "# for i in tqdm(range(13)):\n",
    "#     inputs, _ = test_dataset[i]\n",
    "#     inputs = inputs.cuda().unsqueeze(0)\n",
    "\n",
    "#     torch.cuda.synchronize()\n",
    "#     start = time.time()\n",
    "#     predict= deeplab_mobilenet_ghost(inputs).data\n",
    "#     torch.cuda.synchronize()\n",
    "#     end = time.time()\n",
    "#     res.append(end-start)\n",
    "# time_sum = 0\n",
    "# for i in res:\n",
    "#     time_sum += i\n",
    "    \n",
    "# print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5586cbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 75.185217\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU6 ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: module GhostModule is treated as a zero-op.\n",
      "Warning: module InvertedResidual is treated as a zero-op.\n",
      "Warning: module MobileNetV2 is treated as a zero-op.\n",
      "Warning: module ASPP_module is treated as a zero-op.\n",
      "Warning: module DeepLabv3_plus_mobilenet_ghost is treated as a zero-op.\n",
      "DeepLabv3_plus_mobilenet_ghost(\n",
      "  6.939 M, 135.324% Params, 18.565 GMac, 100.000% MACs, \n",
      "  (efficient_features): MobileNetV2(\n",
      "    3.623 M, 70.648% Params, 5.218 GMac, 28.108% MACs, \n",
      "    (features): Sequential(\n",
      "      1.811 M, 35.324% Params, 2.609 GMac, 14.054% MACs, \n",
      "      (0): Sequential(\n",
      "        0.001 M, 0.012% Params, 0.044 GMac, 0.237% MACs, \n",
      "        (0): GhostModule(\n",
      "          0.001 M, 0.012% Params, 0.044 GMac, 0.237% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            0.0 M, 0.009% Params, 0.031 GMac, 0.169% MACs, \n",
      "            (0): Conv2d(0.0 M, 0.008% Params, 0.028 GMac, 0.153% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.0 M, 0.003% Params, 0.013 GMac, 0.068% MACs, \n",
      "            (0): Conv2d(0.0 M, 0.003% Params, 0.009 GMac, 0.051% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        0.001 M, 0.017% Params, 0.061 GMac, 0.328% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.001 M, 0.017% Params, 0.061 GMac, 0.328% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.102% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.023% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.010% Params, 0.034 GMac, 0.181% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        0.005 M, 0.100% Params, 0.179 GMac, 0.963% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.005 M, 0.100% Params, 0.179 GMac, 0.963% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.030% Params, 0.102 GMac, 0.551% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.004% Params, 0.013 GMac, 0.069% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.006 GMac, 0.034% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.017% Params, 0.014 GMac, 0.076% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.004% Params, 0.003 GMac, 0.017% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (6): Conv2d(0.002 M, 0.045% Params, 0.038 GMac, 0.203% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.004% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        0.009 M, 0.172% Params, 0.151 GMac, 0.816% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.009 M, 0.172% Params, 0.151 GMac, 0.816% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.067% Params, 0.058 GMac, 0.315% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.026% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.025% Params, 0.021 GMac, 0.114% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.025% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (6): Conv2d(0.003 M, 0.067% Params, 0.057 GMac, 0.305% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.004% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        0.01 M, 0.195% Params, 0.092 GMac, 0.495% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.01 M, 0.195% Params, 0.092 GMac, 0.495% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.067% Params, 0.058 GMac, 0.315% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.026% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.029% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.006% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.005 M, 0.090% Params, 0.019 GMac, 0.102% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.007 GMac, 0.038% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.008% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.120% Params, 0.025 GMac, 0.136% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.007 GMac, 0.038% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.008% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.120% Params, 0.025 GMac, 0.136% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        0.021 M, 0.411% Params, 0.044 GMac, 0.239% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.021 M, 0.411% Params, 0.044 GMac, 0.239% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.002 GMac, 0.010% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.0 GMac, 0.002% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.012 M, 0.240% Params, 0.013 GMac, 0.068% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        0.067 M, 1.299% Params, 0.072 GMac, 0.390% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.067 M, 1.299% Params, 0.072 GMac, 0.390% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.037 M, 0.719% Params, 0.038 GMac, 0.203% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 1.078% Params, 0.057 GMac, 0.305% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 1.078% Params, 0.057 GMac, 0.305% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        0.155 M, 3.028% Params, 0.168 GMac, 0.903% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.155 M, 3.028% Params, 0.168 GMac, 0.903% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.092 M, 1.797% Params, 0.094 GMac, 0.508% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.178 GMac, 0.956% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.012% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.995% Params, 0.157 GMac, 0.847% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): InvertedResidual(\n",
      "        0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.178 GMac, 0.956% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.012% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.995% Params, 0.157 GMac, 0.847% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): InvertedResidual(\n",
      "        0.474 M, 9.242% Params, 0.53 GMac, 2.854% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.474 M, 9.242% Params, 0.53 GMac, 2.854% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.199 GMac, 1.072% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.013% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.007% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.307 M, 5.991% Params, 0.315 GMac, 1.694% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.004% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (low_level_features): Sequential(\n",
      "      0.016 M, 0.302% Params, 0.435 GMac, 2.344% MACs, \n",
      "      (0): Sequential(\n",
      "        0.001 M, 0.012% Params, 0.044 GMac, 0.237% MACs, \n",
      "        (0): GhostModule(\n",
      "          0.001 M, 0.012% Params, 0.044 GMac, 0.237% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            0.0 M, 0.009% Params, 0.031 GMac, 0.169% MACs, \n",
      "            (0): Conv2d(0.0 M, 0.008% Params, 0.028 GMac, 0.153% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.0 M, 0.003% Params, 0.013 GMac, 0.068% MACs, \n",
      "            (0): Conv2d(0.0 M, 0.003% Params, 0.009 GMac, 0.051% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        0.001 M, 0.017% Params, 0.061 GMac, 0.328% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.001 M, 0.017% Params, 0.061 GMac, 0.328% MACs, \n",
      "          (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.102% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.023% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.010% Params, 0.034 GMac, 0.181% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.011% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        0.005 M, 0.100% Params, 0.179 GMac, 0.963% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.005 M, 0.100% Params, 0.179 GMac, 0.963% MACs, \n",
      "          (0): Conv2d(0.002 M, 0.030% Params, 0.102 GMac, 0.551% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.004% Params, 0.013 GMac, 0.069% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.006 GMac, 0.034% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.017% Params, 0.014 GMac, 0.076% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.004% Params, 0.003 GMac, 0.017% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.008% MACs, inplace=True)\n",
      "          (6): Conv2d(0.002 M, 0.045% Params, 0.038 GMac, 0.203% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.004% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        0.009 M, 0.172% Params, 0.151 GMac, 0.816% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.009 M, 0.172% Params, 0.151 GMac, 0.816% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.067% Params, 0.058 GMac, 0.315% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.026% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.025% Params, 0.021 GMac, 0.114% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.025% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (6): Conv2d(0.003 M, 0.067% Params, 0.057 GMac, 0.305% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.004% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (high_level_features): Sequential(\n",
      "      1.796 M, 35.022% Params, 2.174 GMac, 11.710% MACs, \n",
      "      (4): InvertedResidual(\n",
      "        0.01 M, 0.195% Params, 0.092 GMac, 0.495% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.01 M, 0.195% Params, 0.092 GMac, 0.495% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.067% Params, 0.058 GMac, 0.315% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.006% Params, 0.005 GMac, 0.026% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.002 GMac, 0.013% MACs, inplace=True)\n",
      "          (3): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.029% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.006% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.005 M, 0.090% Params, 0.019 GMac, 0.102% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.007 GMac, 0.038% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.008% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.120% Params, 0.025 GMac, 0.136% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.015 M, 0.290% Params, 0.064 GMac, 0.345% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.007 GMac, 0.038% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.008% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (6): Conv2d(0.006 M, 0.120% Params, 0.025 GMac, 0.136% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.001% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        0.021 M, 0.411% Params, 0.044 GMac, 0.239% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.021 M, 0.411% Params, 0.044 GMac, 0.239% MACs, \n",
      "          (0): Conv2d(0.006 M, 0.120% Params, 0.027 GMac, 0.144% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.007% Params, 0.002 GMac, 0.009% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (3): Conv2d(0.002 M, 0.034% Params, 0.002 GMac, 0.010% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(0.0 M, 0.007% Params, 0.0 GMac, 0.002% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "          (6): Conv2d(0.012 M, 0.240% Params, 0.013 GMac, 0.068% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.054 M, 1.058% Params, 0.06 GMac, 0.322% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.025 M, 0.479% Params, 0.025 GMac, 0.136% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        0.067 M, 1.299% Params, 0.072 GMac, 0.390% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.067 M, 1.299% Params, 0.072 GMac, 0.390% MACs, \n",
      "          (0): Conv2d(0.025 M, 0.479% Params, 0.028 GMac, 0.153% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.005% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (3): Conv2d(0.003 M, 0.067% Params, 0.004 GMac, 0.019% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.015% Params, 0.001 GMac, 0.004% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, inplace=True)\n",
      "          (6): Conv2d(0.037 M, 0.719% Params, 0.038 GMac, 0.203% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 1.078% Params, 0.057 GMac, 0.305% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.118 M, 2.306% Params, 0.13 GMac, 0.699% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.055 M, 1.078% Params, 0.057 GMac, 0.305% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        0.155 M, 3.028% Params, 0.168 GMac, 0.903% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.155 M, 3.028% Params, 0.168 GMac, 0.903% MACs, \n",
      "          (0): Conv2d(0.055 M, 1.078% Params, 0.064 GMac, 0.344% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.007% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.004% MACs, inplace=True)\n",
      "          (3): Conv2d(0.005 M, 0.101% Params, 0.005 GMac, 0.029% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(0.001 M, 0.022% Params, 0.001 GMac, 0.006% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.003% MACs, inplace=True)\n",
      "          (6): Conv2d(0.092 M, 1.797% Params, 0.094 GMac, 0.508% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.178 GMac, 0.956% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.012% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.995% Params, 0.157 GMac, 0.847% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): InvertedResidual(\n",
      "        0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.32 M, 6.240% Params, 0.35 GMac, 1.887% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.178 GMac, 0.956% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.012% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.154 M, 2.995% Params, 0.157 GMac, 0.847% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.0 M, 0.006% Params, 0.0 GMac, 0.002% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): InvertedResidual(\n",
      "        0.474 M, 9.242% Params, 0.53 GMac, 2.854% MACs, \n",
      "        (conv): Sequential(\n",
      "          0.474 M, 9.242% Params, 0.53 GMac, 2.854% MACs, \n",
      "          (0): Conv2d(0.154 M, 2.995% Params, 0.199 GMac, 1.072% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.013% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.007% MACs, inplace=True)\n",
      "          (3): Conv2d(0.009 M, 0.168% Params, 0.009 GMac, 0.048% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(0.002 M, 0.037% Params, 0.002 GMac, 0.011% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU6(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "          (6): Conv2d(0.307 M, 5.991% Params, 0.315 GMac, 1.694% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.004% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aspp1): ASPP_module(\n",
      "    0.082 M, 1.607% Params, 0.085 GMac, 0.456% MACs, \n",
      "    (atrous_convolution): Conv2d(0.082 M, 1.598% Params, 0.084 GMac, 0.452% MACs, 320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.010% Params, 0.001 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp2): ASPP_module(\n",
      "    0.738 M, 14.388% Params, 0.756 GMac, 4.071% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 14.378% Params, 0.755 GMac, 4.067% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.010% Params, 0.001 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp3): ASPP_module(\n",
      "    0.738 M, 14.388% Params, 0.756 GMac, 4.071% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 14.378% Params, 0.755 GMac, 4.067% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.010% Params, 0.001 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (aspp4): ASPP_module(\n",
      "    0.738 M, 14.388% Params, 0.756 GMac, 4.071% MACs, \n",
      "    (atrous_convolution): Conv2d(0.737 M, 14.378% Params, 0.755 GMac, 4.067% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.010% Params, 0.001 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, )\n",
      "  )\n",
      "  (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.006% MACs, )\n",
      "  (global_avg_pool): Sequential(\n",
      "    0.043 M, 0.831% Params, 0.0 GMac, 0.002% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, output_size=(1, 1))\n",
      "    (1): GhostModule(\n",
      "      0.043 M, 0.831% Params, 0.0 GMac, 0.000% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.041 M, 0.804% Params, 0.0 GMac, 0.000% MACs, \n",
      "        (0): Conv2d(0.041 M, 0.799% Params, 0.0 GMac, 0.000% MACs, 320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.027% Params, 0.0 GMac, 0.000% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.022% Params, 0.0 GMac, 0.000% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(0.328 M, 6.390% Params, 0.336 GMac, 1.807% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(0.001 M, 0.010% Params, 0.001 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(0.001 M, 0.022% Params, 0.019 GMac, 0.102% MACs, 24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(0.0 M, 0.002% Params, 0.002 GMac, 0.008% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (last_conv): Sequential(\n",
      "    0.649 M, 12.650% Params, 10.637 GMac, 57.295% MACs, \n",
      "    (0): GhostModule(\n",
      "      0.352 M, 6.862% Params, 5.769 GMac, 31.076% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.35 M, 6.834% Params, 5.744 GMac, 30.941% MACs, \n",
      "        (0): Conv2d(0.35 M, 6.829% Params, 5.738 GMac, 30.907% MACs, 304, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.004 GMac, 0.023% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.027% Params, 0.025 GMac, 0.136% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.022% Params, 0.019 GMac, 0.102% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.004 GMac, 0.023% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): GhostModule(\n",
      "      0.297 M, 5.783% Params, 4.863 GMac, 26.196% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.295 M, 5.756% Params, 4.838 GMac, 26.061% MACs, \n",
      "        (0): Conv2d(0.295 M, 5.751% Params, 4.832 GMac, 26.027% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.004 GMac, 0.023% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.027% Params, 0.025 GMac, 0.136% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.022% Params, 0.019 GMac, 0.102% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.005% Params, 0.004 GMac, 0.023% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.011% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Conv2d(0.0 M, 0.005% Params, 0.004 GMac, 0.023% MACs, 256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Computational complexity:       18.56 GMac\n",
      "Number of parameters:           5.13 M  \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= deeplab_mobilenet_ghost(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))\n",
    "macs, params = get_model_complexity_info(deeplab_mobilenet_ghost, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c020df",
   "metadata": {},
   "source": [
    "# Unet++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a09a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block_nested(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(conv_block_nested, self).__init__()\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3x1_1 = nn.Conv2d(in_ch, in_ch, kernel_size=(3,1), padding=(1,0), bias=True)\n",
    "        self.conv1x3_1 = nn.Conv2d(in_ch, mid_ch, kernel_size=(1,3), padding=(0,1), bias=True)\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
    "    \n",
    "        self.conv3x1_2 = nn.Conv2d(mid_ch, mid_ch, kernel_size=(3,1), padding=(1,0), bias=True)\n",
    "        self.conv1x3_2 = nn.Conv2d(mid_ch, out_ch, kernel_size=(1,3), padding=(0,1), bias=True)\n",
    "#         self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "        x = self.conv3x1_1(x)\n",
    "        x = self.conv1x3_1(x)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "#         x = self.conv2(x)\n",
    "        x = self.conv3x1_2(x)\n",
    "        x = self.conv1x3_2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.activation(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "class Nested_UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(Nested_UNet, self).__init__()\n",
    "\n",
    "        n1 = 32\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
    "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
    "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
    "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
    "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
    "\n",
    "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])\n",
    "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])\n",
    "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])\n",
    "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])\n",
    "\n",
    "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])\n",
    "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])\n",
    "\n",
    "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])\n",
    "\n",
    "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])\n",
    "\n",
    "        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334b0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 512, 512]              30\n",
      "            Conv2d-2         [-1, 32, 512, 512]             320\n",
      "       BatchNorm2d-3         [-1, 32, 512, 512]              64\n",
      "              ReLU-4         [-1, 32, 512, 512]               0\n",
      "            Conv2d-5         [-1, 32, 512, 512]           3,104\n",
      "            Conv2d-6         [-1, 32, 512, 512]           3,104\n",
      "       BatchNorm2d-7         [-1, 32, 512, 512]              64\n",
      "              ReLU-8         [-1, 32, 512, 512]               0\n",
      " conv_block_nested-9         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-10         [-1, 32, 256, 256]               0\n",
      "           Conv2d-11         [-1, 32, 256, 256]           3,104\n",
      "           Conv2d-12         [-1, 64, 256, 256]           6,208\n",
      "      BatchNorm2d-13         [-1, 64, 256, 256]             128\n",
      "             ReLU-14         [-1, 64, 256, 256]               0\n",
      "           Conv2d-15         [-1, 64, 256, 256]          12,352\n",
      "           Conv2d-16         [-1, 64, 256, 256]          12,352\n",
      "      BatchNorm2d-17         [-1, 64, 256, 256]             128\n",
      "             ReLU-18         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-19         [-1, 64, 256, 256]               0\n",
      "         Upsample-20         [-1, 64, 512, 512]               0\n",
      "           Conv2d-21         [-1, 96, 512, 512]          27,744\n",
      "           Conv2d-22         [-1, 32, 512, 512]           9,248\n",
      "      BatchNorm2d-23         [-1, 32, 512, 512]              64\n",
      "             ReLU-24         [-1, 32, 512, 512]               0\n",
      "           Conv2d-25         [-1, 32, 512, 512]           3,104\n",
      "           Conv2d-26         [-1, 32, 512, 512]           3,104\n",
      "      BatchNorm2d-27         [-1, 32, 512, 512]              64\n",
      "             ReLU-28         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-29         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-30         [-1, 64, 128, 128]               0\n",
      "           Conv2d-31         [-1, 64, 128, 128]          12,352\n",
      "           Conv2d-32        [-1, 128, 128, 128]          24,704\n",
      "      BatchNorm2d-33        [-1, 128, 128, 128]             256\n",
      "             ReLU-34        [-1, 128, 128, 128]               0\n",
      "           Conv2d-35        [-1, 128, 128, 128]          49,280\n",
      "           Conv2d-36        [-1, 128, 128, 128]          49,280\n",
      "      BatchNorm2d-37        [-1, 128, 128, 128]             256\n",
      "             ReLU-38        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-39        [-1, 128, 128, 128]               0\n",
      "         Upsample-40        [-1, 128, 256, 256]               0\n",
      "           Conv2d-41        [-1, 192, 256, 256]         110,784\n",
      "           Conv2d-42         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-43         [-1, 64, 256, 256]             128\n",
      "             ReLU-44         [-1, 64, 256, 256]               0\n",
      "           Conv2d-45         [-1, 64, 256, 256]          12,352\n",
      "           Conv2d-46         [-1, 64, 256, 256]          12,352\n",
      "      BatchNorm2d-47         [-1, 64, 256, 256]             128\n",
      "             ReLU-48         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-49         [-1, 64, 256, 256]               0\n",
      "         Upsample-50         [-1, 64, 512, 512]               0\n",
      "           Conv2d-51        [-1, 128, 512, 512]          49,280\n",
      "           Conv2d-52         [-1, 32, 512, 512]          12,320\n",
      "      BatchNorm2d-53         [-1, 32, 512, 512]              64\n",
      "             ReLU-54         [-1, 32, 512, 512]               0\n",
      "           Conv2d-55         [-1, 32, 512, 512]           3,104\n",
      "           Conv2d-56         [-1, 32, 512, 512]           3,104\n",
      "      BatchNorm2d-57         [-1, 32, 512, 512]              64\n",
      "             ReLU-58         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-59         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-60          [-1, 128, 64, 64]               0\n",
      "           Conv2d-61          [-1, 128, 64, 64]          49,280\n",
      "           Conv2d-62          [-1, 256, 64, 64]          98,560\n",
      "      BatchNorm2d-63          [-1, 256, 64, 64]             512\n",
      "             ReLU-64          [-1, 256, 64, 64]               0\n",
      "           Conv2d-65          [-1, 256, 64, 64]         196,864\n",
      "           Conv2d-66          [-1, 256, 64, 64]         196,864\n",
      "      BatchNorm2d-67          [-1, 256, 64, 64]             512\n",
      "             ReLU-68          [-1, 256, 64, 64]               0\n",
      "conv_block_nested-69          [-1, 256, 64, 64]               0\n",
      "         Upsample-70        [-1, 256, 128, 128]               0\n",
      "           Conv2d-71        [-1, 384, 128, 128]         442,752\n",
      "           Conv2d-72        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-73        [-1, 128, 128, 128]             256\n",
      "             ReLU-74        [-1, 128, 128, 128]               0\n",
      "           Conv2d-75        [-1, 128, 128, 128]          49,280\n",
      "           Conv2d-76        [-1, 128, 128, 128]          49,280\n",
      "      BatchNorm2d-77        [-1, 128, 128, 128]             256\n",
      "             ReLU-78        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-79        [-1, 128, 128, 128]               0\n",
      "         Upsample-80        [-1, 128, 256, 256]               0\n",
      "           Conv2d-81        [-1, 256, 256, 256]         196,864\n",
      "           Conv2d-82         [-1, 64, 256, 256]          49,216\n",
      "      BatchNorm2d-83         [-1, 64, 256, 256]             128\n",
      "             ReLU-84         [-1, 64, 256, 256]               0\n",
      "           Conv2d-85         [-1, 64, 256, 256]          12,352\n",
      "           Conv2d-86         [-1, 64, 256, 256]          12,352\n",
      "      BatchNorm2d-87         [-1, 64, 256, 256]             128\n",
      "             ReLU-88         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-89         [-1, 64, 256, 256]               0\n",
      "         Upsample-90         [-1, 64, 512, 512]               0\n",
      "           Conv2d-91        [-1, 160, 512, 512]          76,960\n",
      "           Conv2d-92         [-1, 32, 512, 512]          15,392\n",
      "      BatchNorm2d-93         [-1, 32, 512, 512]              64\n",
      "             ReLU-94         [-1, 32, 512, 512]               0\n",
      "           Conv2d-95         [-1, 32, 512, 512]           3,104\n",
      "           Conv2d-96         [-1, 32, 512, 512]           3,104\n",
      "      BatchNorm2d-97         [-1, 32, 512, 512]              64\n",
      "             ReLU-98         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-99         [-1, 32, 512, 512]               0\n",
      "       MaxPool2d-100          [-1, 256, 32, 32]               0\n",
      "          Conv2d-101          [-1, 256, 32, 32]         196,864\n",
      "          Conv2d-102          [-1, 512, 32, 32]         393,728\n",
      "     BatchNorm2d-103          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-104          [-1, 512, 32, 32]               0\n",
      "          Conv2d-105          [-1, 512, 32, 32]         786,944\n",
      "          Conv2d-106          [-1, 512, 32, 32]         786,944\n",
      "     BatchNorm2d-107          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-108          [-1, 512, 32, 32]               0\n",
      "conv_block_nested-109          [-1, 512, 32, 32]               0\n",
      "        Upsample-110          [-1, 512, 64, 64]               0\n",
      "          Conv2d-111          [-1, 768, 64, 64]       1,770,240\n",
      "          Conv2d-112          [-1, 256, 64, 64]         590,080\n",
      "     BatchNorm2d-113          [-1, 256, 64, 64]             512\n",
      "            ReLU-114          [-1, 256, 64, 64]               0\n",
      "          Conv2d-115          [-1, 256, 64, 64]         196,864\n",
      "          Conv2d-116          [-1, 256, 64, 64]         196,864\n",
      "     BatchNorm2d-117          [-1, 256, 64, 64]             512\n",
      "            ReLU-118          [-1, 256, 64, 64]               0\n",
      "conv_block_nested-119          [-1, 256, 64, 64]               0\n",
      "        Upsample-120        [-1, 256, 128, 128]               0\n",
      "          Conv2d-121        [-1, 512, 128, 128]         786,944\n",
      "          Conv2d-122        [-1, 128, 128, 128]         196,736\n",
      "     BatchNorm2d-123        [-1, 128, 128, 128]             256\n",
      "            ReLU-124        [-1, 128, 128, 128]               0\n",
      "          Conv2d-125        [-1, 128, 128, 128]          49,280\n",
      "          Conv2d-126        [-1, 128, 128, 128]          49,280\n",
      "     BatchNorm2d-127        [-1, 128, 128, 128]             256\n",
      "            ReLU-128        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-129        [-1, 128, 128, 128]               0\n",
      "        Upsample-130        [-1, 128, 256, 256]               0\n",
      "          Conv2d-131        [-1, 320, 256, 256]         307,520\n",
      "          Conv2d-132         [-1, 64, 256, 256]          61,504\n",
      "     BatchNorm2d-133         [-1, 64, 256, 256]             128\n",
      "            ReLU-134         [-1, 64, 256, 256]               0\n",
      "          Conv2d-135         [-1, 64, 256, 256]          12,352\n",
      "          Conv2d-136         [-1, 64, 256, 256]          12,352\n",
      "     BatchNorm2d-137         [-1, 64, 256, 256]             128\n",
      "            ReLU-138         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-139         [-1, 64, 256, 256]               0\n",
      "        Upsample-140         [-1, 64, 512, 512]               0\n",
      "          Conv2d-141        [-1, 192, 512, 512]         110,784\n",
      "          Conv2d-142         [-1, 32, 512, 512]          18,464\n",
      "     BatchNorm2d-143         [-1, 32, 512, 512]              64\n",
      "            ReLU-144         [-1, 32, 512, 512]               0\n",
      "          Conv2d-145         [-1, 32, 512, 512]           3,104\n",
      "          Conv2d-146         [-1, 32, 512, 512]           3,104\n",
      "     BatchNorm2d-147         [-1, 32, 512, 512]              64\n",
      "            ReLU-148         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-149         [-1, 32, 512, 512]               0\n",
      "          Conv2d-150          [-1, 1, 512, 512]              33\n",
      "================================================================\n",
      "Total params: 8,596,703\n",
      "Trainable params: 8,596,703\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 6652.00\n",
      "Params size (MB): 32.79\n",
      "Estimated Total Size (MB): 6687.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "unetplusplus = Nested_UNet().eval().cuda()\n",
    "summary(unetplusplus,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518b7526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16598844528198242\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = unetplusplus(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "044dd242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module conv_block_nested is treated as a zero-op.\n",
      "Warning: module Nested_UNet is treated as a zero-op.\n",
      "Nested_UNet(\n",
      "  8.597 M, 100.000% Params, 196.732 GMac, 100.000% MACs, \n",
      "  (pool): MaxPool2d(0.0 M, 0.000% Params, 0.016 GMac, 0.008% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Up): Upsample(0.0 M, 0.000% Params, 0.103 GMac, 0.052% MACs, scale_factor=2.0, mode=bilinear)\n",
      "  (conv0_0): conv_block_nested(\n",
      "    0.007 M, 0.078% Params, 1.769 GMac, 0.899% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.017 GMac, 0.009% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.0 M, 0.000% Params, 0.008 GMac, 0.004% MACs, 3, 3, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.0 M, 0.004% Params, 0.084 GMac, 0.043% MACs, 3, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1_0): conv_block_nested(\n",
      "    0.034 M, 0.399% Params, 2.254 GMac, 1.146% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.004% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.003 M, 0.036% Params, 0.203 GMac, 0.103% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.006 M, 0.072% Params, 0.407 GMac, 0.207% MACs, 32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2_0): conv_block_nested(\n",
      "    0.136 M, 1.583% Params, 2.235 GMac, 1.136% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.002% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.012 M, 0.144% Params, 0.202 GMac, 0.103% MACs, 64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.025 M, 0.287% Params, 0.405 GMac, 0.206% MACs, 64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3_0): conv_block_nested(\n",
      "    0.543 M, 6.312% Params, 2.225 GMac, 1.131% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.001% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.049 M, 0.573% Params, 0.202 GMac, 0.103% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.099 M, 1.146% Params, 0.404 GMac, 0.205% MACs, 128, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.197 M, 2.290% Params, 0.806 GMac, 0.410% MACs, 256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.197 M, 2.290% Params, 0.806 GMac, 0.410% MACs, 256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4_0): conv_block_nested(\n",
      "    2.167 M, 25.202% Params, 2.22 GMac, 1.128% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.197 M, 2.290% Params, 0.202 GMac, 0.102% MACs, 256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.394 M, 4.580% Params, 0.403 GMac, 0.205% MACs, 256, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.787 M, 9.154% Params, 0.806 GMac, 0.410% MACs, 512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.787 M, 9.154% Params, 0.806 GMac, 0.410% MACs, 512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv0_1): conv_block_nested(\n",
      "    0.043 M, 0.504% Params, 11.375 GMac, 5.782% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.017 GMac, 0.009% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.028 M, 0.323% Params, 7.273 GMac, 3.697% MACs, 96, 96, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.009 M, 0.108% Params, 2.424 GMac, 1.232% MACs, 96, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1_1): conv_block_nested(\n",
      "    0.173 M, 2.009% Params, 11.325 GMac, 5.756% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.004% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.111 M, 1.289% Params, 7.26 GMac, 3.690% MACs, 192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.037 M, 0.430% Params, 2.42 GMac, 1.230% MACs, 192, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2_1): conv_block_nested(\n",
      "    0.689 M, 8.019% Params, 11.299 GMac, 5.744% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.002% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.443 M, 5.150% Params, 7.254 GMac, 3.687% MACs, 384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.148 M, 1.717% Params, 2.418 GMac, 1.229% MACs, 384, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3_1): conv_block_nested(\n",
      "    2.755 M, 32.048% Params, 11.287 GMac, 5.737% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.001% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(1.77 M, 20.592% Params, 7.251 GMac, 3.686% MACs, 768, 768, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.59 M, 6.864% Params, 2.417 GMac, 1.229% MACs, 768, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.197 M, 2.290% Params, 0.806 GMac, 0.410% MACs, 256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.197 M, 2.290% Params, 0.806 GMac, 0.410% MACs, 256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv0_2): conv_block_nested(\n",
      "    0.068 M, 0.790% Params, 17.826 GMac, 9.061% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.017 GMac, 0.009% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.049 M, 0.573% Params, 12.918 GMac, 6.567% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.012 M, 0.143% Params, 3.23 GMac, 1.642% MACs, 128, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1_2): conv_block_nested(\n",
      "    0.271 M, 3.153% Params, 17.771 GMac, 9.033% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.004% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.197 M, 2.290% Params, 12.902 GMac, 6.558% MACs, 256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.049 M, 0.572% Params, 3.225 GMac, 1.640% MACs, 256, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2_2): conv_block_nested(\n",
      "    1.083 M, 12.595% Params, 17.744 GMac, 9.019% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.002% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.787 M, 9.154% Params, 12.893 GMac, 6.554% MACs, 512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.197 M, 2.289% Params, 3.223 GMac, 1.638% MACs, 512, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.049 M, 0.573% Params, 0.807 GMac, 0.410% MACs, 128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv0_3): conv_block_nested(\n",
      "    0.099 M, 1.148% Params, 25.887 GMac, 13.159% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.017 GMac, 0.009% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.077 M, 0.895% Params, 20.175 GMac, 10.255% MACs, 160, 160, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.015 M, 0.179% Params, 4.035 GMac, 2.051% MACs, 160, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1_3): conv_block_nested(\n",
      "    0.394 M, 4.583% Params, 25.829 GMac, 13.129% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.004% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.308 M, 3.577% Params, 20.154 GMac, 10.244% MACs, 320, 320, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.062 M, 0.715% Params, 4.031 GMac, 2.049% MACs, 320, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.012 M, 0.144% Params, 0.81 GMac, 0.411% MACs, 64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.004% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv0_4): conv_block_nested(\n",
      "    0.136 M, 1.577% Params, 35.559 GMac, 18.075% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.017 GMac, 0.009% MACs, inplace=True)\n",
      "    (conv3x1_1): Conv2d(0.111 M, 1.289% Params, 29.041 GMac, 14.762% MACs, 192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_1): Conv2d(0.018 M, 0.215% Params, 4.84 GMac, 2.460% MACs, 192, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3x1_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (conv1x3_2): Conv2d(0.003 M, 0.036% Params, 0.814 GMac, 0.414% MACs, 32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.017 GMac, 0.009% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (final): Conv2d(0.0 M, 0.000% Params, 0.009 GMac, 0.004% MACs, 32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       196.73 GMac\n",
      "Number of parameters:           8.6 M   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "macs, params = get_model_complexity_info(unetplusplus, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09732ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 10.75 GiB total capacity; 9.38 GiB already allocated; 51.69 MiB free; 9.41 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-63de5903cdc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0munetplusplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b76ee0de7a0b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mx0_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mx1_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx0_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b76ee0de7a0b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         x = self.conv1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3x1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x3_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 10.75 GiB total capacity; 9.38 GiB already allocated; 51.69 MiB free; 9.41 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= unetplusplus(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "    print('-')\n",
    "    \n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc27bca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0cebb5437ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtime_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FPS: %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in tqdm(range(13)):\n",
    "    inputs, _ = test_dataset[i]\n",
    "    inputs = inputs.cuda().unsqueeze(0)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= unetplusplus(inputs).data\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b67478",
   "metadata": {},
   "source": [
    "# Unet++ Ghost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1a2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True, dilated=None):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.oup = oup\n",
    "        init_channels = math.ceil(oup / ratio)\n",
    "        new_channels = init_channels*(ratio-1)\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(init_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "        self.cheap_operation = nn.Sequential(\n",
    "            nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "            nn.BatchNorm2d(new_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = torch.cat([x1,x2], dim=1)\n",
    "        return out[:,:self.oup,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d862170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block_nested(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(conv_block_nested, self).__init__()\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv1 = GhostModule(in_ch, mid_ch, kernel_size=3, relu=True)\n",
    "#         self.conv3x1_1 = nn.Conv2d(in_ch, in_ch, kernel_size=(3,1), padding=(1,0), bias=True)\n",
    "#         self.conv1x3_1 = nn.Conv2d(in_ch, mid_ch, kernel_size=(1,3), padding=(0,1), bias=True)\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
    "#         self.bn1 = nn.BatchNorm2d(mid_ch)\n",
    "        \n",
    "        self.conv2 = GhostModule(mid_ch, out_ch, kernel_size=3, relu=True)\n",
    "#         self.conv3x1_2 = nn.Conv2d(mid_ch, mid_ch, kernel_size=(3,1), padding=(1,0), bias=True)\n",
    "#         self.conv1x3_2 = nn.Conv2d(mid_ch, out_ch, kernel_size=(1,3), padding=(0,1), bias=True)\n",
    "#         self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "#         x = self.conv3x1_1(x)\n",
    "#         x = self.conv1x3_1(x)\n",
    "        \n",
    "#         x = self.bn1(x)\n",
    "#         x = self.activation(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "#         x = self.conv3x1_2(x)\n",
    "#         x = self.conv1x3_2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         output = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Nested_UNet_ghost(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(Nested_UNet_ghost, self).__init__()\n",
    "\n",
    "        n1 = 32\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
    "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
    "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
    "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
    "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
    "\n",
    "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])\n",
    "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])\n",
    "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])\n",
    "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])\n",
    "\n",
    "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])\n",
    "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])\n",
    "\n",
    "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])\n",
    "\n",
    "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])\n",
    "\n",
    "        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc11999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             432\n",
      "       BatchNorm2d-2         [-1, 16, 512, 512]              32\n",
      "              ReLU-3         [-1, 16, 512, 512]               0\n",
      "            Conv2d-4         [-1, 16, 512, 512]             144\n",
      "       BatchNorm2d-5         [-1, 16, 512, 512]              32\n",
      "              ReLU-6         [-1, 16, 512, 512]               0\n",
      "       GhostModule-7         [-1, 32, 512, 512]               0\n",
      "            Conv2d-8         [-1, 16, 512, 512]           4,608\n",
      "       BatchNorm2d-9         [-1, 16, 512, 512]              32\n",
      "             ReLU-10         [-1, 16, 512, 512]               0\n",
      "           Conv2d-11         [-1, 16, 512, 512]             144\n",
      "      BatchNorm2d-12         [-1, 16, 512, 512]              32\n",
      "             ReLU-13         [-1, 16, 512, 512]               0\n",
      "      GhostModule-14         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-15         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-16         [-1, 32, 256, 256]               0\n",
      "           Conv2d-17         [-1, 32, 256, 256]           9,216\n",
      "      BatchNorm2d-18         [-1, 32, 256, 256]              64\n",
      "             ReLU-19         [-1, 32, 256, 256]               0\n",
      "           Conv2d-20         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-21         [-1, 32, 256, 256]              64\n",
      "             ReLU-22         [-1, 32, 256, 256]               0\n",
      "      GhostModule-23         [-1, 64, 256, 256]               0\n",
      "           Conv2d-24         [-1, 32, 256, 256]          18,432\n",
      "      BatchNorm2d-25         [-1, 32, 256, 256]              64\n",
      "             ReLU-26         [-1, 32, 256, 256]               0\n",
      "           Conv2d-27         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-28         [-1, 32, 256, 256]              64\n",
      "             ReLU-29         [-1, 32, 256, 256]               0\n",
      "      GhostModule-30         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-31         [-1, 64, 256, 256]               0\n",
      "         Upsample-32         [-1, 64, 512, 512]               0\n",
      "           Conv2d-33         [-1, 16, 512, 512]          13,824\n",
      "      BatchNorm2d-34         [-1, 16, 512, 512]              32\n",
      "             ReLU-35         [-1, 16, 512, 512]               0\n",
      "           Conv2d-36         [-1, 16, 512, 512]             144\n",
      "      BatchNorm2d-37         [-1, 16, 512, 512]              32\n",
      "             ReLU-38         [-1, 16, 512, 512]               0\n",
      "      GhostModule-39         [-1, 32, 512, 512]               0\n",
      "           Conv2d-40         [-1, 16, 512, 512]           4,608\n",
      "      BatchNorm2d-41         [-1, 16, 512, 512]              32\n",
      "             ReLU-42         [-1, 16, 512, 512]               0\n",
      "           Conv2d-43         [-1, 16, 512, 512]             144\n",
      "      BatchNorm2d-44         [-1, 16, 512, 512]              32\n",
      "             ReLU-45         [-1, 16, 512, 512]               0\n",
      "      GhostModule-46         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-47         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-48         [-1, 64, 128, 128]               0\n",
      "           Conv2d-49         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-50         [-1, 64, 128, 128]             128\n",
      "             ReLU-51         [-1, 64, 128, 128]               0\n",
      "           Conv2d-52         [-1, 64, 128, 128]             576\n",
      "      BatchNorm2d-53         [-1, 64, 128, 128]             128\n",
      "             ReLU-54         [-1, 64, 128, 128]               0\n",
      "      GhostModule-55        [-1, 128, 128, 128]               0\n",
      "           Conv2d-56         [-1, 64, 128, 128]          73,728\n",
      "      BatchNorm2d-57         [-1, 64, 128, 128]             128\n",
      "             ReLU-58         [-1, 64, 128, 128]               0\n",
      "           Conv2d-59         [-1, 64, 128, 128]             576\n",
      "      BatchNorm2d-60         [-1, 64, 128, 128]             128\n",
      "             ReLU-61         [-1, 64, 128, 128]               0\n",
      "      GhostModule-62        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-63        [-1, 128, 128, 128]               0\n",
      "         Upsample-64        [-1, 128, 256, 256]               0\n",
      "           Conv2d-65         [-1, 32, 256, 256]          55,296\n",
      "      BatchNorm2d-66         [-1, 32, 256, 256]              64\n",
      "             ReLU-67         [-1, 32, 256, 256]               0\n",
      "           Conv2d-68         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-69         [-1, 32, 256, 256]              64\n",
      "             ReLU-70         [-1, 32, 256, 256]               0\n",
      "      GhostModule-71         [-1, 64, 256, 256]               0\n",
      "           Conv2d-72         [-1, 32, 256, 256]          18,432\n",
      "      BatchNorm2d-73         [-1, 32, 256, 256]              64\n",
      "             ReLU-74         [-1, 32, 256, 256]               0\n",
      "           Conv2d-75         [-1, 32, 256, 256]             288\n",
      "      BatchNorm2d-76         [-1, 32, 256, 256]              64\n",
      "             ReLU-77         [-1, 32, 256, 256]               0\n",
      "      GhostModule-78         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-79         [-1, 64, 256, 256]               0\n",
      "         Upsample-80         [-1, 64, 512, 512]               0\n",
      "           Conv2d-81         [-1, 16, 512, 512]          18,432\n",
      "      BatchNorm2d-82         [-1, 16, 512, 512]              32\n",
      "             ReLU-83         [-1, 16, 512, 512]               0\n",
      "           Conv2d-84         [-1, 16, 512, 512]             144\n",
      "      BatchNorm2d-85         [-1, 16, 512, 512]              32\n",
      "             ReLU-86         [-1, 16, 512, 512]               0\n",
      "      GhostModule-87         [-1, 32, 512, 512]               0\n",
      "           Conv2d-88         [-1, 16, 512, 512]           4,608\n",
      "      BatchNorm2d-89         [-1, 16, 512, 512]              32\n",
      "             ReLU-90         [-1, 16, 512, 512]               0\n",
      "           Conv2d-91         [-1, 16, 512, 512]             144\n",
      "      BatchNorm2d-92         [-1, 16, 512, 512]              32\n",
      "             ReLU-93         [-1, 16, 512, 512]               0\n",
      "      GhostModule-94         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-95         [-1, 32, 512, 512]               0\n",
      "        MaxPool2d-96          [-1, 128, 64, 64]               0\n",
      "           Conv2d-97          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-98          [-1, 128, 64, 64]             256\n",
      "             ReLU-99          [-1, 128, 64, 64]               0\n",
      "          Conv2d-100          [-1, 128, 64, 64]           1,152\n",
      "     BatchNorm2d-101          [-1, 128, 64, 64]             256\n",
      "            ReLU-102          [-1, 128, 64, 64]               0\n",
      "     GhostModule-103          [-1, 256, 64, 64]               0\n",
      "          Conv2d-104          [-1, 128, 64, 64]         294,912\n",
      "     BatchNorm2d-105          [-1, 128, 64, 64]             256\n",
      "            ReLU-106          [-1, 128, 64, 64]               0\n",
      "          Conv2d-107          [-1, 128, 64, 64]           1,152\n",
      "     BatchNorm2d-108          [-1, 128, 64, 64]             256\n",
      "            ReLU-109          [-1, 128, 64, 64]               0\n",
      "     GhostModule-110          [-1, 256, 64, 64]               0\n",
      "conv_block_nested-111          [-1, 256, 64, 64]               0\n",
      "        Upsample-112        [-1, 256, 128, 128]               0\n",
      "          Conv2d-113         [-1, 64, 128, 128]         221,184\n",
      "     BatchNorm2d-114         [-1, 64, 128, 128]             128\n",
      "            ReLU-115         [-1, 64, 128, 128]               0\n",
      "          Conv2d-116         [-1, 64, 128, 128]             576\n",
      "     BatchNorm2d-117         [-1, 64, 128, 128]             128\n",
      "            ReLU-118         [-1, 64, 128, 128]               0\n",
      "     GhostModule-119        [-1, 128, 128, 128]               0\n",
      "          Conv2d-120         [-1, 64, 128, 128]          73,728\n",
      "     BatchNorm2d-121         [-1, 64, 128, 128]             128\n",
      "            ReLU-122         [-1, 64, 128, 128]               0\n",
      "          Conv2d-123         [-1, 64, 128, 128]             576\n",
      "     BatchNorm2d-124         [-1, 64, 128, 128]             128\n",
      "            ReLU-125         [-1, 64, 128, 128]               0\n",
      "     GhostModule-126        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-127        [-1, 128, 128, 128]               0\n",
      "        Upsample-128        [-1, 128, 256, 256]               0\n",
      "          Conv2d-129         [-1, 32, 256, 256]          73,728\n",
      "     BatchNorm2d-130         [-1, 32, 256, 256]              64\n",
      "            ReLU-131         [-1, 32, 256, 256]               0\n",
      "          Conv2d-132         [-1, 32, 256, 256]             288\n",
      "     BatchNorm2d-133         [-1, 32, 256, 256]              64\n",
      "            ReLU-134         [-1, 32, 256, 256]               0\n",
      "     GhostModule-135         [-1, 64, 256, 256]               0\n",
      "          Conv2d-136         [-1, 32, 256, 256]          18,432\n",
      "     BatchNorm2d-137         [-1, 32, 256, 256]              64\n",
      "            ReLU-138         [-1, 32, 256, 256]               0\n",
      "          Conv2d-139         [-1, 32, 256, 256]             288\n",
      "     BatchNorm2d-140         [-1, 32, 256, 256]              64\n",
      "            ReLU-141         [-1, 32, 256, 256]               0\n",
      "     GhostModule-142         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-143         [-1, 64, 256, 256]               0\n",
      "        Upsample-144         [-1, 64, 512, 512]               0\n",
      "          Conv2d-145         [-1, 16, 512, 512]          23,040\n",
      "     BatchNorm2d-146         [-1, 16, 512, 512]              32\n",
      "            ReLU-147         [-1, 16, 512, 512]               0\n",
      "          Conv2d-148         [-1, 16, 512, 512]             144\n",
      "     BatchNorm2d-149         [-1, 16, 512, 512]              32\n",
      "            ReLU-150         [-1, 16, 512, 512]               0\n",
      "     GhostModule-151         [-1, 32, 512, 512]               0\n",
      "          Conv2d-152         [-1, 16, 512, 512]           4,608\n",
      "     BatchNorm2d-153         [-1, 16, 512, 512]              32\n",
      "            ReLU-154         [-1, 16, 512, 512]               0\n",
      "          Conv2d-155         [-1, 16, 512, 512]             144\n",
      "     BatchNorm2d-156         [-1, 16, 512, 512]              32\n",
      "            ReLU-157         [-1, 16, 512, 512]               0\n",
      "     GhostModule-158         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-159         [-1, 32, 512, 512]               0\n",
      "       MaxPool2d-160          [-1, 256, 32, 32]               0\n",
      "          Conv2d-161          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-162          [-1, 256, 32, 32]             512\n",
      "            ReLU-163          [-1, 256, 32, 32]               0\n",
      "          Conv2d-164          [-1, 256, 32, 32]           2,304\n",
      "     BatchNorm2d-165          [-1, 256, 32, 32]             512\n",
      "            ReLU-166          [-1, 256, 32, 32]               0\n",
      "     GhostModule-167          [-1, 512, 32, 32]               0\n",
      "          Conv2d-168          [-1, 256, 32, 32]       1,179,648\n",
      "     BatchNorm2d-169          [-1, 256, 32, 32]             512\n",
      "            ReLU-170          [-1, 256, 32, 32]               0\n",
      "          Conv2d-171          [-1, 256, 32, 32]           2,304\n",
      "     BatchNorm2d-172          [-1, 256, 32, 32]             512\n",
      "            ReLU-173          [-1, 256, 32, 32]               0\n",
      "     GhostModule-174          [-1, 512, 32, 32]               0\n",
      "conv_block_nested-175          [-1, 512, 32, 32]               0\n",
      "        Upsample-176          [-1, 512, 64, 64]               0\n",
      "          Conv2d-177          [-1, 128, 64, 64]         884,736\n",
      "     BatchNorm2d-178          [-1, 128, 64, 64]             256\n",
      "            ReLU-179          [-1, 128, 64, 64]               0\n",
      "          Conv2d-180          [-1, 128, 64, 64]           1,152\n",
      "     BatchNorm2d-181          [-1, 128, 64, 64]             256\n",
      "            ReLU-182          [-1, 128, 64, 64]               0\n",
      "     GhostModule-183          [-1, 256, 64, 64]               0\n",
      "          Conv2d-184          [-1, 128, 64, 64]         294,912\n",
      "     BatchNorm2d-185          [-1, 128, 64, 64]             256\n",
      "            ReLU-186          [-1, 128, 64, 64]               0\n",
      "          Conv2d-187          [-1, 128, 64, 64]           1,152\n",
      "     BatchNorm2d-188          [-1, 128, 64, 64]             256\n",
      "            ReLU-189          [-1, 128, 64, 64]               0\n",
      "     GhostModule-190          [-1, 256, 64, 64]               0\n",
      "conv_block_nested-191          [-1, 256, 64, 64]               0\n",
      "        Upsample-192        [-1, 256, 128, 128]               0\n",
      "          Conv2d-193         [-1, 64, 128, 128]         294,912\n",
      "     BatchNorm2d-194         [-1, 64, 128, 128]             128\n",
      "            ReLU-195         [-1, 64, 128, 128]               0\n",
      "          Conv2d-196         [-1, 64, 128, 128]             576\n",
      "     BatchNorm2d-197         [-1, 64, 128, 128]             128\n",
      "            ReLU-198         [-1, 64, 128, 128]               0\n",
      "     GhostModule-199        [-1, 128, 128, 128]               0\n",
      "          Conv2d-200         [-1, 64, 128, 128]          73,728\n",
      "     BatchNorm2d-201         [-1, 64, 128, 128]             128\n",
      "            ReLU-202         [-1, 64, 128, 128]               0\n",
      "          Conv2d-203         [-1, 64, 128, 128]             576\n",
      "     BatchNorm2d-204         [-1, 64, 128, 128]             128\n",
      "            ReLU-205         [-1, 64, 128, 128]               0\n",
      "     GhostModule-206        [-1, 128, 128, 128]               0\n",
      "conv_block_nested-207        [-1, 128, 128, 128]               0\n",
      "        Upsample-208        [-1, 128, 256, 256]               0\n",
      "          Conv2d-209         [-1, 32, 256, 256]          92,160\n",
      "     BatchNorm2d-210         [-1, 32, 256, 256]              64\n",
      "            ReLU-211         [-1, 32, 256, 256]               0\n",
      "          Conv2d-212         [-1, 32, 256, 256]             288\n",
      "     BatchNorm2d-213         [-1, 32, 256, 256]              64\n",
      "            ReLU-214         [-1, 32, 256, 256]               0\n",
      "     GhostModule-215         [-1, 64, 256, 256]               0\n",
      "          Conv2d-216         [-1, 32, 256, 256]          18,432\n",
      "     BatchNorm2d-217         [-1, 32, 256, 256]              64\n",
      "            ReLU-218         [-1, 32, 256, 256]               0\n",
      "          Conv2d-219         [-1, 32, 256, 256]             288\n",
      "     BatchNorm2d-220         [-1, 32, 256, 256]              64\n",
      "            ReLU-221         [-1, 32, 256, 256]               0\n",
      "     GhostModule-222         [-1, 64, 256, 256]               0\n",
      "conv_block_nested-223         [-1, 64, 256, 256]               0\n",
      "        Upsample-224         [-1, 64, 512, 512]               0\n",
      "          Conv2d-225         [-1, 16, 512, 512]          27,648\n",
      "     BatchNorm2d-226         [-1, 16, 512, 512]              32\n",
      "            ReLU-227         [-1, 16, 512, 512]               0\n",
      "          Conv2d-228         [-1, 16, 512, 512]             144\n",
      "     BatchNorm2d-229         [-1, 16, 512, 512]              32\n",
      "            ReLU-230         [-1, 16, 512, 512]               0\n",
      "     GhostModule-231         [-1, 32, 512, 512]               0\n",
      "          Conv2d-232         [-1, 16, 512, 512]           4,608\n",
      "     BatchNorm2d-233         [-1, 16, 512, 512]              32\n",
      "            ReLU-234         [-1, 16, 512, 512]               0\n",
      "          Conv2d-235         [-1, 16, 512, 512]             144\n",
      "     BatchNorm2d-236         [-1, 16, 512, 512]              32\n",
      "            ReLU-237         [-1, 16, 512, 512]               0\n",
      "     GhostModule-238         [-1, 32, 512, 512]               0\n",
      "conv_block_nested-239         [-1, 32, 512, 512]               0\n",
      "          Conv2d-240          [-1, 1, 512, 512]              33\n",
      "================================================================\n",
      "Total params: 4,599,921\n",
      "Trainable params: 4,599,921\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 5460.00\n",
      "Params size (MB): 17.55\n",
      "Estimated Total Size (MB): 5480.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "unetplusplus_ghos = Nested_UNet_ghost().eval().cuda()\n",
    "summary(unetplusplus_ghos,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0899b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09329056739807129\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = unetplusplus_ghos(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "944ad5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module GhostModule is treated as a zero-op.\n",
      "Warning: module conv_block_nested is treated as a zero-op.\n",
      "Warning: module Nested_UNet_ghost is treated as a zero-op.\n",
      "Nested_UNet_ghost(\n",
      "  4.6 M, 100.000% Params, 70.109 GMac, 100.000% MACs, \n",
      "  (pool): MaxPool2d(0.0 M, 0.000% Params, 0.016 GMac, 0.022% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Up): Upsample(0.0 M, 0.000% Params, 0.103 GMac, 0.147% MACs, scale_factor=2.0, mode=bilinear)\n",
      "  (conv0_0): conv_block_nested(\n",
      "    0.005 M, 0.119% Params, 1.447 GMac, 2.064% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.001 M, 0.014% Params, 0.176 GMac, 0.251% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.0 M, 0.010% Params, 0.126 GMac, 0.179% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.009% Params, 0.113 GMac, 0.162% MACs, 3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.005 M, 0.105% Params, 1.271 GMac, 1.813% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.005 M, 0.101% Params, 1.221 GMac, 1.741% MACs, \n",
      "        (0): Conv2d(0.005 M, 0.100% Params, 1.208 GMac, 1.723% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1_0): conv_block_nested(\n",
      "    0.028 M, 0.619% Params, 1.875 GMac, 2.674% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.01 M, 0.209% Params, 0.635 GMac, 0.906% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.009 M, 0.202% Params, 0.61 GMac, 0.870% MACs, \n",
      "        (0): Conv2d(0.009 M, 0.200% Params, 0.604 GMac, 0.861% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.019 M, 0.410% Params, 1.239 GMac, 1.768% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.018 M, 0.402% Params, 1.214 GMac, 1.732% MACs, \n",
      "        (0): Conv2d(0.018 M, 0.401% Params, 1.208 GMac, 1.723% MACs, 64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2_0): conv_block_nested(\n",
      "    0.112 M, 2.440% Params, 1.843 GMac, 2.629% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.038 M, 0.819% Params, 0.62 GMac, 0.884% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.037 M, 0.804% Params, 0.607 GMac, 0.866% MACs, \n",
      "        (0): Conv2d(0.037 M, 0.801% Params, 0.604 GMac, 0.861% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.075 M, 1.621% Params, 1.224 GMac, 1.745% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.074 M, 1.606% Params, 1.211 GMac, 1.727% MACs, \n",
      "        (0): Conv2d(0.074 M, 1.603% Params, 1.208 GMac, 1.723% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3_0): conv_block_nested(\n",
      "    0.446 M, 9.689% Params, 1.828 GMac, 2.607% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.149 M, 3.242% Params, 0.612 GMac, 0.873% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.148 M, 3.211% Params, 0.606 GMac, 0.864% MACs, \n",
      "        (0): Conv2d(0.147 M, 3.206% Params, 0.604 GMac, 0.861% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.031% Params, 0.006 GMac, 0.009% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.007% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.297 M, 6.447% Params, 1.216 GMac, 1.734% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.295 M, 6.417% Params, 1.21 GMac, 1.725% MACs, \n",
      "        (0): Conv2d(0.295 M, 6.411% Params, 1.208 GMac, 1.723% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.031% Params, 0.006 GMac, 0.009% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.007% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv4_0): conv_block_nested(\n",
      "    1.776 M, 38.612% Params, 1.82 GMac, 2.596% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.593 M, 12.895% Params, 0.608 GMac, 0.867% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.59 M, 12.834% Params, 0.605 GMac, 0.863% MACs, \n",
      "        (0): Conv2d(0.59 M, 12.822% Params, 0.604 GMac, 0.861% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.003 M, 0.061% Params, 0.003 GMac, 0.004% MACs, \n",
      "        (0): Conv2d(0.002 M, 0.050% Params, 0.002 GMac, 0.003% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      1.183 M, 25.717% Params, 1.212 GMac, 1.729% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        1.18 M, 25.656% Params, 1.209 GMac, 1.724% MACs, \n",
      "        (0): Conv2d(1.18 M, 25.645% Params, 1.208 GMac, 1.723% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.003 M, 0.061% Params, 0.003 GMac, 0.004% MACs, \n",
      "        (0): Conv2d(0.002 M, 0.050% Params, 0.002 GMac, 0.003% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.011% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv0_1): conv_block_nested(\n",
      "    0.019 M, 0.410% Params, 4.958 GMac, 7.071% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.014 M, 0.305% Params, 3.687 GMac, 5.259% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.014 M, 0.301% Params, 3.636 GMac, 5.187% MACs, \n",
      "        (0): Conv2d(0.014 M, 0.301% Params, 3.624 GMac, 5.169% MACs, 96, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.005 M, 0.105% Params, 1.271 GMac, 1.813% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.005 M, 0.101% Params, 1.221 GMac, 1.741% MACs, \n",
      "        (0): Conv2d(0.005 M, 0.100% Params, 1.208 GMac, 1.723% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1_1): conv_block_nested(\n",
      "    0.075 M, 1.621% Params, 4.895 GMac, 6.982% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.056 M, 1.211% Params, 3.655 GMac, 5.214% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.055 M, 1.203% Params, 3.63 GMac, 5.178% MACs, \n",
      "        (0): Conv2d(0.055 M, 1.202% Params, 3.624 GMac, 5.169% MACs, 192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.019 M, 0.410% Params, 1.239 GMac, 1.768% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.018 M, 0.402% Params, 1.214 GMac, 1.732% MACs, \n",
      "        (0): Conv2d(0.018 M, 0.401% Params, 1.208 GMac, 1.723% MACs, 64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2_1): conv_block_nested(\n",
      "    0.297 M, 6.447% Params, 4.863 GMac, 6.937% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.222 M, 4.827% Params, 3.64 GMac, 5.191% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.221 M, 4.811% Params, 3.627 GMac, 5.173% MACs, \n",
      "        (0): Conv2d(0.221 M, 4.808% Params, 3.624 GMac, 5.169% MACs, 384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.075 M, 1.621% Params, 1.224 GMac, 1.745% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.074 M, 1.606% Params, 1.211 GMac, 1.727% MACs, \n",
      "        (0): Conv2d(0.074 M, 1.603% Params, 1.208 GMac, 1.723% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3_1): conv_block_nested(\n",
      "    1.183 M, 25.717% Params, 4.848 GMac, 6.914% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.886 M, 19.270% Params, 3.632 GMac, 5.180% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.885 M, 19.239% Params, 3.625 GMac, 5.171% MACs, \n",
      "        (0): Conv2d(0.885 M, 19.234% Params, 3.624 GMac, 5.169% MACs, 768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.031% Params, 0.006 GMac, 0.009% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.007% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.297 M, 6.447% Params, 1.216 GMac, 1.734% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.295 M, 6.417% Params, 1.21 GMac, 1.725% MACs, \n",
      "        (0): Conv2d(0.295 M, 6.411% Params, 1.208 GMac, 1.723% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.031% Params, 0.006 GMac, 0.009% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.025% Params, 0.005 GMac, 0.007% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.006% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv0_2): conv_block_nested(\n",
      "    0.023 M, 0.510% Params, 6.166 GMac, 8.794% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.019 M, 0.405% Params, 4.895 GMac, 6.982% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.018 M, 0.401% Params, 4.844 GMac, 6.910% MACs, \n",
      "        (0): Conv2d(0.018 M, 0.401% Params, 4.832 GMac, 6.892% MACs, 128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.005 M, 0.105% Params, 1.271 GMac, 1.813% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.005 M, 0.101% Params, 1.221 GMac, 1.741% MACs, \n",
      "        (0): Conv2d(0.005 M, 0.100% Params, 1.208 GMac, 1.723% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1_2): conv_block_nested(\n",
      "    0.093 M, 2.022% Params, 6.103 GMac, 8.705% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.074 M, 1.612% Params, 4.863 GMac, 6.937% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.074 M, 1.604% Params, 4.838 GMac, 6.901% MACs, \n",
      "        (0): Conv2d(0.074 M, 1.603% Params, 4.832 GMac, 6.892% MACs, 256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.019 M, 0.410% Params, 1.239 GMac, 1.768% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.018 M, 0.402% Params, 1.214 GMac, 1.732% MACs, \n",
      "        (0): Conv2d(0.018 M, 0.401% Params, 1.208 GMac, 1.723% MACs, 64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2_2): conv_block_nested(\n",
      "    0.37 M, 8.050% Params, 6.071 GMac, 8.660% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.296 M, 6.429% Params, 4.848 GMac, 6.914% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.295 M, 6.414% Params, 4.835 GMac, 6.896% MACs, \n",
      "        (0): Conv2d(0.295 M, 6.411% Params, 4.832 GMac, 6.892% MACs, 512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.075 M, 1.621% Params, 1.224 GMac, 1.745% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.074 M, 1.606% Params, 1.211 GMac, 1.727% MACs, \n",
      "        (0): Conv2d(0.074 M, 1.603% Params, 1.208 GMac, 1.723% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.015% Params, 0.013 GMac, 0.018% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.013% Params, 0.009 GMac, 0.013% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv0_3): conv_block_nested(\n",
      "    0.028 M, 0.610% Params, 7.374 GMac, 10.517% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.023 M, 0.505% Params, 6.103 GMac, 8.705% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.023 M, 0.502% Params, 6.052 GMac, 8.633% MACs, \n",
      "        (0): Conv2d(0.023 M, 0.501% Params, 6.04 GMac, 8.615% MACs, 160, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.005 M, 0.105% Params, 1.271 GMac, 1.813% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.005 M, 0.101% Params, 1.221 GMac, 1.741% MACs, \n",
      "        (0): Conv2d(0.005 M, 0.100% Params, 1.208 GMac, 1.723% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1_3): conv_block_nested(\n",
      "    0.111 M, 2.422% Params, 7.311 GMac, 10.428% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.093 M, 2.013% Params, 6.071 GMac, 8.660% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.092 M, 2.005% Params, 6.046 GMac, 8.624% MACs, \n",
      "        (0): Conv2d(0.092 M, 2.004% Params, 6.04 GMac, 8.615% MACs, 320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.019 M, 0.410% Params, 1.239 GMac, 1.768% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.018 M, 0.402% Params, 1.214 GMac, 1.732% MACs, \n",
      "        (0): Conv2d(0.018 M, 0.401% Params, 1.208 GMac, 1.723% MACs, 64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.008% Params, 0.025 GMac, 0.036% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.006% Params, 0.019 GMac, 0.027% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.004 GMac, 0.006% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv0_4): conv_block_nested(\n",
      "    0.033 M, 0.710% Params, 8.582 GMac, 12.240% MACs, \n",
      "    (activation): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (conv1): GhostModule(\n",
      "      0.028 M, 0.606% Params, 7.311 GMac, 10.428% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.028 M, 0.602% Params, 7.26 GMac, 10.356% MACs, \n",
      "        (0): Conv2d(0.028 M, 0.601% Params, 7.248 GMac, 10.338% MACs, 192, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv2): GhostModule(\n",
      "      0.005 M, 0.105% Params, 1.271 GMac, 1.813% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.005 M, 0.101% Params, 1.221 GMac, 1.741% MACs, \n",
      "        (0): Conv2d(0.005 M, 0.100% Params, 1.208 GMac, 1.723% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.004% Params, 0.05 GMac, 0.072% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.003% Params, 0.038 GMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.001% Params, 0.008 GMac, 0.012% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final): Conv2d(0.0 M, 0.001% Params, 0.009 GMac, 0.012% MACs, 32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       70.11 GMac\n",
      "Number of parameters:           4.6 M   \n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(unetplusplus_ghos, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d063f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 28.906437\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= unetplusplus_ghos(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be5819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:00<00:05,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 2/13 [00:00<00:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 3/13 [00:01<00:04,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 4/13 [00:01<00:03,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 5/13 [00:01<00:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 8/13 [00:03<00:01,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 69%|██████▉   | 9/13 [00:03<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 29.746869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm(range(13)):\n",
    "    inputs, _ = test_dataset[i]\n",
    "    inputs = inputs.cuda().unsqueeze(0)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= unetplusplus_ghos(inputs).data\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602391eb",
   "metadata": {},
   "source": [
    "# DeepLabV3Plus_Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b67d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, padding, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, rate):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d_same(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False):\n",
    "        super(SeparableConv2d_same, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], rate=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, reps, stride=1, dilation=1, start_with_relu=True, grow_first=True, is_last=False):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if planes != inplanes or stride != 1:\n",
    "            self.skip = nn.Conv2d(inplanes, planes, 1, stride=stride, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(planes)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        filters = inplanes\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(planes))\n",
    "            filters = planes\n",
    "\n",
    "        for i in range(reps - 1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(filters, filters, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(planes))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "\n",
    "        if stride != 1:\n",
    "            rep.append(SeparableConv2d_same(planes, planes, 3, stride=2))\n",
    "\n",
    "        if stride == 1 and is_last:\n",
    "            rep.append(SeparableConv2d_same(planes, planes, 3, stride=1))\n",
    "\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x += skip\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "884c2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified Alighed Xception\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes=3, os=16, pretrained=False):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        if os == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "        elif os == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2\n",
    "            exit_block_rates = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        # Entry flow\n",
    "        self.conv1 = nn.Conv2d(inplanes, 32, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1 = Block(64, 128, reps=2, stride=2, start_with_relu=False)\n",
    "        self.block2 = Block(128, 256, reps=2, stride=2, start_with_relu=True, grow_first=True)\n",
    "        self.block3 = Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True,\n",
    "                            is_last=True)\n",
    "\n",
    "        # Middle flow\n",
    "        self.block4  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block5  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block6  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block7  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block8  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block9  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block10 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block11 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block12 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block13 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block14 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block15 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block16 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block17 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block18 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block19 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "\n",
    "        # Exit flow\n",
    "        self.block20 = Block(728, 1024, reps=2, stride=1, dilation=exit_block_rates[0],\n",
    "                             start_with_relu=True, grow_first=False, is_last=True)\n",
    "\n",
    "        self.conv3 = SeparableConv2d_same(1024, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv4 = SeparableConv2d_same(1536, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn4 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv5 = SeparableConv2d_same(1536, 2048, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn5 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        # Init weights\n",
    "        self.__init_weight()\n",
    "\n",
    "        # Load pretrained model\n",
    "        if pretrained:\n",
    "            self.__load_xception_pretrained()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entry flow\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        print('Entry flow x shape', x.shape)\n",
    "        # Middle flow\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "        x = self.block13(x)\n",
    "        x = self.block14(x)\n",
    "        x = self.block15(x)\n",
    "        x = self.block16(x)\n",
    "        x = self.block17(x)\n",
    "        x = self.block18(x)\n",
    "        x = self.block19(x)\n",
    "        print('Middle flow x shape', x.shape)\n",
    "        # Exit flow\n",
    "        x = self.block20(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        print('Exit flow x shape', x.shape)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def __load_xception_pretrained(self):\n",
    "        pretrain_dict = model_zoo.load_url('http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "\n",
    "        for k, v in pretrain_dict.items():\n",
    "            print(k)\n",
    "            if k in state_dict:\n",
    "                if 'pointwise' in k:\n",
    "                    v = v.unsqueeze(-1).unsqueeze(-1)\n",
    "                if k.startswith('block12'):\n",
    "                    model_dict[k.replace('block12', 'block20')] = v\n",
    "                elif k.startswith('block11'):\n",
    "                    model_dict[k.replace('block11', 'block12')] = v\n",
    "                elif k.startswith('conv3'):\n",
    "                    model_dict[k] = v\n",
    "                elif k.startswith('bn3'):\n",
    "                    model_dict[k] = v\n",
    "                    model_dict[k.replace('bn3', 'bn4')] = v\n",
    "                elif k.startswith('conv4'):\n",
    "                    model_dict[k.replace('conv4', 'conv5')] = v\n",
    "                elif k.startswith('bn4'):\n",
    "                    model_dict[k.replace('bn4', 'bn5')] = v\n",
    "                else:\n",
    "                    model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, rate):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=rate, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57444ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabv3_plus(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.xception_features = Xception(nInputChannels, os, pretrained)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP_module(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP_module(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP_module(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             nn.BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(128, 48, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       nn.BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.xception_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                # torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "deff38a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry flow x shape torch.Size([1, 728, 32, 32])\n",
      "Middle flow x shape torch.Size([1, 728, 32, 32])\n",
      "Exit flow x shape torch.Size([1, 2048, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "xception_features = Xception(3, 16, False).cuda()\n",
    "input =torch.randn(1,3,512,512).cuda()\n",
    "output = xception_features(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcc3b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             864\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]              64\n",
      "              ReLU-3         [-1, 32, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "            Conv2d-7         [-1, 64, 256, 256]             576\n",
      "            Conv2d-8        [-1, 128, 256, 256]           8,192\n",
      "SeparableConv2d_same-9        [-1, 128, 256, 256]               0\n",
      "      BatchNorm2d-10        [-1, 128, 256, 256]             256\n",
      "             ReLU-11        [-1, 128, 256, 256]               0\n",
      "             ReLU-12        [-1, 128, 256, 256]               0\n",
      "           Conv2d-13        [-1, 128, 256, 256]           1,152\n",
      "           Conv2d-14        [-1, 128, 256, 256]          16,384\n",
      "SeparableConv2d_same-15        [-1, 128, 256, 256]               0\n",
      "      BatchNorm2d-16        [-1, 128, 256, 256]             256\n",
      "           Conv2d-17        [-1, 128, 128, 128]           1,152\n",
      "           Conv2d-18        [-1, 128, 128, 128]          16,384\n",
      "SeparableConv2d_same-19        [-1, 128, 128, 128]               0\n",
      "           Conv2d-20        [-1, 128, 128, 128]           8,192\n",
      "      BatchNorm2d-21        [-1, 128, 128, 128]             256\n",
      "            Block-22        [-1, 128, 128, 128]               0\n",
      "             ReLU-23        [-1, 128, 128, 128]               0\n",
      "             ReLU-24        [-1, 128, 128, 128]               0\n",
      "           Conv2d-25        [-1, 128, 128, 128]           1,152\n",
      "           Conv2d-26        [-1, 256, 128, 128]          32,768\n",
      "SeparableConv2d_same-27        [-1, 256, 128, 128]               0\n",
      "      BatchNorm2d-28        [-1, 256, 128, 128]             512\n",
      "             ReLU-29        [-1, 256, 128, 128]               0\n",
      "             ReLU-30        [-1, 256, 128, 128]               0\n",
      "           Conv2d-31        [-1, 256, 128, 128]           2,304\n",
      "           Conv2d-32        [-1, 256, 128, 128]          65,536\n",
      "SeparableConv2d_same-33        [-1, 256, 128, 128]               0\n",
      "      BatchNorm2d-34        [-1, 256, 128, 128]             512\n",
      "           Conv2d-35          [-1, 256, 64, 64]           2,304\n",
      "           Conv2d-36          [-1, 256, 64, 64]          65,536\n",
      "SeparableConv2d_same-37          [-1, 256, 64, 64]               0\n",
      "           Conv2d-38          [-1, 256, 64, 64]          32,768\n",
      "      BatchNorm2d-39          [-1, 256, 64, 64]             512\n",
      "            Block-40          [-1, 256, 64, 64]               0\n",
      "             ReLU-41          [-1, 256, 64, 64]               0\n",
      "             ReLU-42          [-1, 256, 64, 64]               0\n",
      "           Conv2d-43          [-1, 256, 64, 64]           2,304\n",
      "           Conv2d-44          [-1, 728, 64, 64]         186,368\n",
      "SeparableConv2d_same-45          [-1, 728, 64, 64]               0\n",
      "      BatchNorm2d-46          [-1, 728, 64, 64]           1,456\n",
      "             ReLU-47          [-1, 728, 64, 64]               0\n",
      "             ReLU-48          [-1, 728, 64, 64]               0\n",
      "           Conv2d-49          [-1, 728, 64, 64]           6,552\n",
      "           Conv2d-50          [-1, 728, 64, 64]         529,984\n",
      "SeparableConv2d_same-51          [-1, 728, 64, 64]               0\n",
      "      BatchNorm2d-52          [-1, 728, 64, 64]           1,456\n",
      "           Conv2d-53          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-54          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-55          [-1, 728, 32, 32]               0\n",
      "           Conv2d-56          [-1, 728, 32, 32]         186,368\n",
      "      BatchNorm2d-57          [-1, 728, 32, 32]           1,456\n",
      "            Block-58          [-1, 728, 32, 32]               0\n",
      "             ReLU-59          [-1, 728, 32, 32]               0\n",
      "             ReLU-60          [-1, 728, 32, 32]               0\n",
      "           Conv2d-61          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-62          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-63          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-64          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-65          [-1, 728, 32, 32]               0\n",
      "             ReLU-66          [-1, 728, 32, 32]               0\n",
      "           Conv2d-67          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-68          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-69          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-70          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-71          [-1, 728, 32, 32]               0\n",
      "             ReLU-72          [-1, 728, 32, 32]               0\n",
      "           Conv2d-73          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-74          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-75          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-76          [-1, 728, 32, 32]           1,456\n",
      "            Block-77          [-1, 728, 32, 32]               0\n",
      "             ReLU-78          [-1, 728, 32, 32]               0\n",
      "             ReLU-79          [-1, 728, 32, 32]               0\n",
      "           Conv2d-80          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-81          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-82          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-83          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-84          [-1, 728, 32, 32]               0\n",
      "             ReLU-85          [-1, 728, 32, 32]               0\n",
      "           Conv2d-86          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-87          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-88          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-89          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-90          [-1, 728, 32, 32]               0\n",
      "             ReLU-91          [-1, 728, 32, 32]               0\n",
      "           Conv2d-92          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-93          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-94          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-95          [-1, 728, 32, 32]           1,456\n",
      "            Block-96          [-1, 728, 32, 32]               0\n",
      "             ReLU-97          [-1, 728, 32, 32]               0\n",
      "             ReLU-98          [-1, 728, 32, 32]               0\n",
      "           Conv2d-99          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-100          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-101          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-102          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-103          [-1, 728, 32, 32]               0\n",
      "            ReLU-104          [-1, 728, 32, 32]               0\n",
      "          Conv2d-105          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-106          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-107          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-108          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-109          [-1, 728, 32, 32]               0\n",
      "            ReLU-110          [-1, 728, 32, 32]               0\n",
      "          Conv2d-111          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-112          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-113          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-114          [-1, 728, 32, 32]           1,456\n",
      "           Block-115          [-1, 728, 32, 32]               0\n",
      "            ReLU-116          [-1, 728, 32, 32]               0\n",
      "            ReLU-117          [-1, 728, 32, 32]               0\n",
      "          Conv2d-118          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-119          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-120          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-121          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-122          [-1, 728, 32, 32]               0\n",
      "            ReLU-123          [-1, 728, 32, 32]               0\n",
      "          Conv2d-124          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-125          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-126          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-127          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-128          [-1, 728, 32, 32]               0\n",
      "            ReLU-129          [-1, 728, 32, 32]               0\n",
      "          Conv2d-130          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-131          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-132          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-133          [-1, 728, 32, 32]           1,456\n",
      "           Block-134          [-1, 728, 32, 32]               0\n",
      "            ReLU-135          [-1, 728, 32, 32]               0\n",
      "            ReLU-136          [-1, 728, 32, 32]               0\n",
      "          Conv2d-137          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-138          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-139          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-140          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-141          [-1, 728, 32, 32]               0\n",
      "            ReLU-142          [-1, 728, 32, 32]               0\n",
      "          Conv2d-143          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-144          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-145          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-146          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-147          [-1, 728, 32, 32]               0\n",
      "            ReLU-148          [-1, 728, 32, 32]               0\n",
      "          Conv2d-149          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-150          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-151          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-152          [-1, 728, 32, 32]           1,456\n",
      "           Block-153          [-1, 728, 32, 32]               0\n",
      "            ReLU-154          [-1, 728, 32, 32]               0\n",
      "            ReLU-155          [-1, 728, 32, 32]               0\n",
      "          Conv2d-156          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-157          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-158          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-159          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-160          [-1, 728, 32, 32]               0\n",
      "            ReLU-161          [-1, 728, 32, 32]               0\n",
      "          Conv2d-162          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-163          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-164          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-165          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-166          [-1, 728, 32, 32]               0\n",
      "            ReLU-167          [-1, 728, 32, 32]               0\n",
      "          Conv2d-168          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-169          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-170          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-171          [-1, 728, 32, 32]           1,456\n",
      "           Block-172          [-1, 728, 32, 32]               0\n",
      "            ReLU-173          [-1, 728, 32, 32]               0\n",
      "            ReLU-174          [-1, 728, 32, 32]               0\n",
      "          Conv2d-175          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-176          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-177          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-178          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-179          [-1, 728, 32, 32]               0\n",
      "            ReLU-180          [-1, 728, 32, 32]               0\n",
      "          Conv2d-181          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-182          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-183          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-184          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-185          [-1, 728, 32, 32]               0\n",
      "            ReLU-186          [-1, 728, 32, 32]               0\n",
      "          Conv2d-187          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-188          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-189          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-190          [-1, 728, 32, 32]           1,456\n",
      "           Block-191          [-1, 728, 32, 32]               0\n",
      "            ReLU-192          [-1, 728, 32, 32]               0\n",
      "            ReLU-193          [-1, 728, 32, 32]               0\n",
      "          Conv2d-194          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-195          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-196          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-197          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-198          [-1, 728, 32, 32]               0\n",
      "            ReLU-199          [-1, 728, 32, 32]               0\n",
      "          Conv2d-200          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-201          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-202          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-203          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-204          [-1, 728, 32, 32]               0\n",
      "            ReLU-205          [-1, 728, 32, 32]               0\n",
      "          Conv2d-206          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-207          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-208          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-209          [-1, 728, 32, 32]           1,456\n",
      "           Block-210          [-1, 728, 32, 32]               0\n",
      "            ReLU-211          [-1, 728, 32, 32]               0\n",
      "            ReLU-212          [-1, 728, 32, 32]               0\n",
      "          Conv2d-213          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-214          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-215          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-216          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-217          [-1, 728, 32, 32]               0\n",
      "            ReLU-218          [-1, 728, 32, 32]               0\n",
      "          Conv2d-219          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-220          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-221          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-222          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-223          [-1, 728, 32, 32]               0\n",
      "            ReLU-224          [-1, 728, 32, 32]               0\n",
      "          Conv2d-225          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-226          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-227          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-228          [-1, 728, 32, 32]           1,456\n",
      "           Block-229          [-1, 728, 32, 32]               0\n",
      "            ReLU-230          [-1, 728, 32, 32]               0\n",
      "            ReLU-231          [-1, 728, 32, 32]               0\n",
      "          Conv2d-232          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-233          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-234          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-235          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-236          [-1, 728, 32, 32]               0\n",
      "            ReLU-237          [-1, 728, 32, 32]               0\n",
      "          Conv2d-238          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-239          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-240          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-241          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-242          [-1, 728, 32, 32]               0\n",
      "            ReLU-243          [-1, 728, 32, 32]               0\n",
      "          Conv2d-244          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-245          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-246          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-247          [-1, 728, 32, 32]           1,456\n",
      "           Block-248          [-1, 728, 32, 32]               0\n",
      "            ReLU-249          [-1, 728, 32, 32]               0\n",
      "            ReLU-250          [-1, 728, 32, 32]               0\n",
      "          Conv2d-251          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-252          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-253          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-254          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-255          [-1, 728, 32, 32]               0\n",
      "            ReLU-256          [-1, 728, 32, 32]               0\n",
      "          Conv2d-257          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-258          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-259          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-260          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-261          [-1, 728, 32, 32]               0\n",
      "            ReLU-262          [-1, 728, 32, 32]               0\n",
      "          Conv2d-263          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-264          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-265          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-266          [-1, 728, 32, 32]           1,456\n",
      "           Block-267          [-1, 728, 32, 32]               0\n",
      "            ReLU-268          [-1, 728, 32, 32]               0\n",
      "            ReLU-269          [-1, 728, 32, 32]               0\n",
      "          Conv2d-270          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-271          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-272          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-273          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-274          [-1, 728, 32, 32]               0\n",
      "            ReLU-275          [-1, 728, 32, 32]               0\n",
      "          Conv2d-276          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-277          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-278          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-279          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-280          [-1, 728, 32, 32]               0\n",
      "            ReLU-281          [-1, 728, 32, 32]               0\n",
      "          Conv2d-282          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-283          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-284          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-285          [-1, 728, 32, 32]           1,456\n",
      "           Block-286          [-1, 728, 32, 32]               0\n",
      "            ReLU-287          [-1, 728, 32, 32]               0\n",
      "            ReLU-288          [-1, 728, 32, 32]               0\n",
      "          Conv2d-289          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-290          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-291          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-292          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-293          [-1, 728, 32, 32]               0\n",
      "            ReLU-294          [-1, 728, 32, 32]               0\n",
      "          Conv2d-295          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-296          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-297          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-298          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-299          [-1, 728, 32, 32]               0\n",
      "            ReLU-300          [-1, 728, 32, 32]               0\n",
      "          Conv2d-301          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-302          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-303          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-304          [-1, 728, 32, 32]           1,456\n",
      "           Block-305          [-1, 728, 32, 32]               0\n",
      "            ReLU-306          [-1, 728, 32, 32]               0\n",
      "            ReLU-307          [-1, 728, 32, 32]               0\n",
      "          Conv2d-308          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-309          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-310          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-311          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-312          [-1, 728, 32, 32]               0\n",
      "            ReLU-313          [-1, 728, 32, 32]               0\n",
      "          Conv2d-314          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-315          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-316          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-317          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-318          [-1, 728, 32, 32]               0\n",
      "            ReLU-319          [-1, 728, 32, 32]               0\n",
      "          Conv2d-320          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-321          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-322          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-323          [-1, 728, 32, 32]           1,456\n",
      "           Block-324          [-1, 728, 32, 32]               0\n",
      "            ReLU-325          [-1, 728, 32, 32]               0\n",
      "            ReLU-326          [-1, 728, 32, 32]               0\n",
      "          Conv2d-327          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-328          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-329          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-330          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-331          [-1, 728, 32, 32]               0\n",
      "            ReLU-332          [-1, 728, 32, 32]               0\n",
      "          Conv2d-333          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-334          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-335          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-336          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-337          [-1, 728, 32, 32]               0\n",
      "            ReLU-338          [-1, 728, 32, 32]               0\n",
      "          Conv2d-339          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-340          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-341          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-342          [-1, 728, 32, 32]           1,456\n",
      "           Block-343          [-1, 728, 32, 32]               0\n",
      "            ReLU-344          [-1, 728, 32, 32]               0\n",
      "            ReLU-345          [-1, 728, 32, 32]               0\n",
      "          Conv2d-346          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-347          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-348          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-349          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-350          [-1, 728, 32, 32]               0\n",
      "            ReLU-351          [-1, 728, 32, 32]               0\n",
      "          Conv2d-352          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-353          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-354          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-355          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-356          [-1, 728, 32, 32]               0\n",
      "            ReLU-357          [-1, 728, 32, 32]               0\n",
      "          Conv2d-358          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-359          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-360          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-361          [-1, 728, 32, 32]           1,456\n",
      "           Block-362          [-1, 728, 32, 32]               0\n",
      "            ReLU-363          [-1, 728, 32, 32]               0\n",
      "            ReLU-364          [-1, 728, 32, 32]               0\n",
      "          Conv2d-365          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-366          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-367          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-368          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-369          [-1, 728, 32, 32]               0\n",
      "            ReLU-370          [-1, 728, 32, 32]               0\n",
      "          Conv2d-371          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-372         [-1, 1024, 32, 32]         745,472\n",
      "SeparableConv2d_same-373         [-1, 1024, 32, 32]               0\n",
      "     BatchNorm2d-374         [-1, 1024, 32, 32]           2,048\n",
      "          Conv2d-375         [-1, 1024, 32, 32]           9,216\n",
      "          Conv2d-376         [-1, 1024, 32, 32]       1,048,576\n",
      "SeparableConv2d_same-377         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-378         [-1, 1024, 32, 32]         745,472\n",
      "     BatchNorm2d-379         [-1, 1024, 32, 32]           2,048\n",
      "           Block-380         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-381         [-1, 1024, 32, 32]           9,216\n",
      "          Conv2d-382         [-1, 1536, 32, 32]       1,572,864\n",
      "SeparableConv2d_same-383         [-1, 1536, 32, 32]               0\n",
      "     BatchNorm2d-384         [-1, 1536, 32, 32]           3,072\n",
      "            ReLU-385         [-1, 1536, 32, 32]               0\n",
      "          Conv2d-386         [-1, 1536, 32, 32]          13,824\n",
      "          Conv2d-387         [-1, 1536, 32, 32]       2,359,296\n",
      "SeparableConv2d_same-388         [-1, 1536, 32, 32]               0\n",
      "     BatchNorm2d-389         [-1, 1536, 32, 32]           3,072\n",
      "            ReLU-390         [-1, 1536, 32, 32]               0\n",
      "          Conv2d-391         [-1, 1536, 32, 32]          13,824\n",
      "          Conv2d-392         [-1, 2048, 32, 32]       3,145,728\n",
      "SeparableConv2d_same-393         [-1, 2048, 32, 32]               0\n",
      "     BatchNorm2d-394         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-395         [-1, 2048, 32, 32]               0\n",
      "        Xception-396  [[-1, 2048, 32, 32], [-1, 128, 128, 128]]               0\n",
      "          Conv2d-397          [-1, 256, 32, 32]         524,288\n",
      "     BatchNorm2d-398          [-1, 256, 32, 32]             512\n",
      "            ReLU-399          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-400          [-1, 256, 32, 32]               0\n",
      "          Conv2d-401          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-402          [-1, 256, 32, 32]             512\n",
      "            ReLU-403          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-404          [-1, 256, 32, 32]               0\n",
      "          Conv2d-405          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-406          [-1, 256, 32, 32]             512\n",
      "            ReLU-407          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-408          [-1, 256, 32, 32]               0\n",
      "          Conv2d-409          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-410          [-1, 256, 32, 32]             512\n",
      "            ReLU-411          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-412          [-1, 256, 32, 32]               0\n",
      "AdaptiveAvgPool2d-413           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-414            [-1, 256, 1, 1]         524,288\n",
      "     BatchNorm2d-415            [-1, 256, 1, 1]             512\n",
      "            ReLU-416            [-1, 256, 1, 1]               0\n",
      "          Conv2d-417          [-1, 256, 32, 32]         327,680\n",
      "     BatchNorm2d-418          [-1, 256, 32, 32]             512\n",
      "            ReLU-419          [-1, 256, 32, 32]               0\n",
      "          Conv2d-420         [-1, 48, 128, 128]           6,144\n",
      "     BatchNorm2d-421         [-1, 48, 128, 128]              96\n",
      "            ReLU-422         [-1, 48, 128, 128]               0\n",
      "          Conv2d-423        [-1, 256, 128, 128]         700,416\n",
      "     BatchNorm2d-424        [-1, 256, 128, 128]             512\n",
      "            ReLU-425        [-1, 256, 128, 128]               0\n",
      "          Conv2d-426        [-1, 256, 128, 128]         589,824\n",
      "     BatchNorm2d-427        [-1, 256, 128, 128]             512\n",
      "            ReLU-428        [-1, 256, 128, 128]               0\n",
      "          Conv2d-429          [-1, 1, 128, 128]             257\n",
      "================================================================\n",
      "Total params: 54,607,521\n",
      "Trainable params: 54,607,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 33550644.79\n",
      "Params size (MB): 208.31\n",
      "Estimated Total Size (MB): 33550856.10\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/jamie_segmentation/lib/python3.6/site-packages/torch/nn/functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "deeplab_xcep = DeepLabv3_plus(nInputChannels=3, n_classes=1, os=16, pretrained=False, _print=True).eval().cuda()\n",
    "summary(deeplab_xcep,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0840899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07286524772644043\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = deeplab_xcep(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3eecbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 32.606476\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for id, data in enumerate(test_dataloader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= deeplab_xcep(inputs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02e91f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:00<00:05,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 2/13 [00:00<00:04,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 3/13 [00:01<00:04,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 4/13 [00:01<00:03,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 5/13 [00:01<00:03,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 8/13 [00:02<00:01,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:03<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 34.158480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm(range(13)):\n",
    "    inputs, _ = test_dataset[i]\n",
    "    inputs = inputs.cuda().unsqueeze(0)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= deeplab_xcep(inputs).data\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fac19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: module SeparableConv2d_same is treated as a zero-op.\n",
      "Warning: module Block is treated as a zero-op.\n",
      "Warning: module Xception is treated as a zero-op.\n",
      "Warning: module ASPP_module is treated as a zero-op.\n",
      "Warning: module DeepLabv3_plus is treated as a zero-op.\n",
      "DeepLabv3_plus(\n",
      "  54.608 M, 100.000% Params, 82.963 GMac, 100.000% MACs, \n",
      "  (xception_features): Xception(\n",
      "    37.775 M, 69.175% Params, 46.317 GMac, 55.828% MACs, \n",
      "    (conv1): Conv2d(0.001 M, 0.002% Params, 0.057 GMac, 0.068% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.012 GMac, 0.014% MACs, inplace=True)\n",
      "    (conv2): Conv2d(0.018 M, 0.034% Params, 1.208 GMac, 1.456% MACs, 32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (block1): Block(\n",
      "      0.053 M, 0.097% Params, 2.2 GMac, 2.652% MACs, \n",
      "      (skip): Conv2d(0.008 M, 0.015% Params, 0.134 GMac, 0.162% MACs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.010% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        0.044 M, 0.081% Params, 2.053 GMac, 2.475% MACs, \n",
      "        (0): SeparableConv2d_same(\n",
      "          0.009 M, 0.016% Params, 0.575 GMac, 0.693% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.001% Params, 0.038 GMac, 0.046% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
      "          (pointwise): Conv2d(0.008 M, 0.015% Params, 0.537 GMac, 0.647% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.017 GMac, 0.020% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.010% MACs, inplace=True)\n",
      "        (3): SeparableConv2d_same(\n",
      "          0.018 M, 0.032% Params, 1.149 GMac, 1.385% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.002% Params, 0.075 GMac, 0.091% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(0.016 M, 0.030% Params, 1.074 GMac, 1.294% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): BatchNorm2d(0.0 M, 0.000% Params, 0.017 GMac, 0.020% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SeparableConv2d_same(\n",
      "          0.018 M, 0.032% Params, 0.287 GMac, 0.346% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.002% Params, 0.019 GMac, 0.023% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(0.016 M, 0.030% Params, 0.268 GMac, 0.324% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block2): Block(\n",
      "      0.204 M, 0.373% Params, 2.111 GMac, 2.544% MACs, \n",
      "      (skip): Conv2d(0.033 M, 0.060% Params, 0.134 GMac, 0.162% MACs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        0.171 M, 0.312% Params, 1.968 GMac, 2.372% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.034 M, 0.062% Params, 0.556 GMac, 0.670% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.002% Params, 0.019 GMac, 0.023% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(0.033 M, 0.060% Params, 0.537 GMac, 0.647% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.068 M, 0.124% Params, 1.111 GMac, 1.340% MACs, \n",
      "          (conv1): Conv2d(0.002 M, 0.004% Params, 0.038 GMac, 0.046% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(0.066 M, 0.120% Params, 1.074 GMac, 1.294% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): SeparableConv2d_same(\n",
      "          0.068 M, 0.124% Params, 0.278 GMac, 0.335% MACs, \n",
      "          (conv1): Conv2d(0.002 M, 0.004% Params, 0.009 GMac, 0.011% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(0.066 M, 0.120% Params, 0.268 GMac, 0.324% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block3): Block(\n",
      "      1.452 M, 2.660% Params, 3.732 GMac, 4.499% MACs, \n",
      "      (skip): Conv2d(0.186 M, 0.341% Params, 0.191 GMac, 0.230% MACs, 256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.265 M, 2.316% Params, 3.536 GMac, 4.262% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.189 M, 0.346% Params, 0.773 GMac, 0.931% MACs, \n",
      "          (conv1): Conv2d(0.002 M, 0.004% Params, 0.009 GMac, 0.011% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(0.186 M, 0.341% Params, 0.763 GMac, 0.920% MACs, 256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.006 GMac, 0.007% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 2.198 GMac, 2.649% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.027 GMac, 0.032% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 2.171 GMac, 2.617% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.006 GMac, 0.007% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(2, 2), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block4): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block5): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block6): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block7): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block8): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block9): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block10): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block11): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block12): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block13): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block14): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block15): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block16): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block17): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block18): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block19): Block(\n",
      "      1.614 M, 2.956% Params, 1.657 GMac, 1.997% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.956% Params, 1.655 GMac, 1.995% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block20): Block(\n",
      "      3.097 M, 5.672% Params, 3.175 GMac, 3.827% MACs, \n",
      "      (skip): Conv2d(0.745 M, 1.365% Params, 0.763 GMac, 0.920% MACs, 728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skipbn): BatchNorm2d(0.002 M, 0.004% Params, 0.002 GMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        2.35 M, 4.303% Params, 2.408 GMac, 2.902% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.983% Params, 0.549 GMac, 0.662% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.971% Params, 0.543 GMac, 0.654% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.003% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.752 M, 1.377% Params, 0.77 GMac, 0.928% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.012% Params, 0.007 GMac, 0.008% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.745 M, 1.365% Params, 0.763 GMac, 0.920% MACs, 728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.002 M, 0.004% Params, 0.002 GMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): SeparableConv2d_same(\n",
      "          1.058 M, 1.937% Params, 1.083 GMac, 1.306% MACs, \n",
      "          (conv1): Conv2d(0.009 M, 0.017% Params, 0.009 GMac, 0.011% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), groups=1024, bias=False)\n",
      "          (pointwise): Conv2d(1.049 M, 1.920% Params, 1.074 GMac, 1.294% MACs, 1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3): SeparableConv2d_same(\n",
      "      1.582 M, 2.897% Params, 1.62 GMac, 1.953% MACs, \n",
      "      (conv1): Conv2d(0.009 M, 0.017% Params, 0.009 GMac, 0.011% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1024, bias=False)\n",
      "      (pointwise): Conv2d(1.573 M, 2.880% Params, 1.611 GMac, 1.941% MACs, 1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn3): BatchNorm2d(0.003 M, 0.006% Params, 0.003 GMac, 0.004% MACs, 1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv4): SeparableConv2d_same(\n",
      "      2.373 M, 4.346% Params, 2.43 GMac, 2.929% MACs, \n",
      "      (conv1): Conv2d(0.014 M, 0.025% Params, 0.014 GMac, 0.017% MACs, 1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(2.359 M, 4.320% Params, 2.416 GMac, 2.912% MACs, 1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn4): BatchNorm2d(0.003 M, 0.006% Params, 0.003 GMac, 0.004% MACs, 1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv5): SeparableConv2d_same(\n",
      "      3.16 M, 5.786% Params, 3.235 GMac, 3.900% MACs, \n",
      "      (conv1): Conv2d(0.014 M, 0.025% Params, 0.014 GMac, 0.017% MACs, 1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(3.146 M, 5.761% Params, 3.221 GMac, 3.883% MACs, 1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn5): BatchNorm2d(0.004 M, 0.008% Params, 0.004 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (aspp1): ASPP_module(\n",
      "    0.525 M, 0.961% Params, 0.538 GMac, 0.648% MACs, \n",
      "    (atrous_convolution): Conv2d(0.524 M, 0.960% Params, 0.537 GMac, 0.647% MACs, 2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp2): ASPP_module(\n",
      "    4.719 M, 8.642% Params, 4.833 GMac, 5.825% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.641% Params, 4.832 GMac, 5.824% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp3): ASPP_module(\n",
      "    4.719 M, 8.642% Params, 4.833 GMac, 5.825% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.641% Params, 4.832 GMac, 5.824% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp4): ASPP_module(\n",
      "    4.719 M, 8.642% Params, 4.833 GMac, 5.825% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.641% Params, 4.832 GMac, 5.824% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, )\n",
      "  (global_avg_pool): Sequential(\n",
      "    0.525 M, 0.961% Params, 0.003 GMac, 0.003% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (1): Conv2d(0.524 M, 0.960% Params, 0.001 GMac, 0.001% MACs, 2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(0.001 M, 0.001% Params, 0.0 GMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (conv1): Conv2d(0.328 M, 0.600% Params, 0.336 GMac, 0.404% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(0.006 M, 0.011% Params, 0.101 GMac, 0.121% MACs, 128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.002 GMac, 0.002% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (last_conv): Sequential(\n",
      "    1.292 M, 2.365% Params, 21.169 GMac, 25.516% MACs, \n",
      "    (0): Conv2d(0.7 M, 1.283% Params, 11.476 GMac, 13.832% MACs, 304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, )\n",
      "    (3): Conv2d(0.59 M, 1.080% Params, 9.664 GMac, 11.648% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, )\n",
      "    (6): Conv2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Computational complexity:       82.96 GMac\n",
      "Number of parameters:           54.61 M \n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(deeplab_xcep, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcfb01",
   "metadata": {},
   "source": [
    "# DeepLabV3Plus_Xception_ghost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13bd1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True, dilation=None, batchnorm=True):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.oup = oup\n",
    "        init_channels = math.ceil(oup / ratio)\n",
    "        new_channels = init_channels*(ratio-1)\n",
    "        if dilation:\n",
    "            self.primary_conv = nn.Sequential(\n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, dilation=dilation,bias=False),\n",
    "                nn.BatchNorm2d(init_channels) if batchnorm else nn.Sequential(),\n",
    "                nn.ReLU6(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, dilation=dilation, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels) if batchnorm else nn.Sequential(),\n",
    "                nn.ReLU6(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "        else:\n",
    "            self.primary_conv = nn.Sequential(\n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "                nn.BatchNorm2d(init_channels) if batchnorm else nn.Sequential(),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels) if batchnorm else nn.Sequential(),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )            \n",
    "    def forward(self, x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = torch.cat([x1,x2], dim=1)\n",
    "        return out[:,:self.oup,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa5bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, padding, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, rate):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d_same(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False):\n",
    "        super(SeparableConv2d_same, self).__init__()\n",
    "#         self.ghost = GhostModule(inplanes, planes, kernel_size=3, stride=stride, dilation=1, relu=False, batchnorm=False)\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], rate=self.conv1.dilation[0])\n",
    "#         x = self.ghost(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, reps, stride=1, dilation=1, start_with_relu=True, grow_first=True, is_last=False):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if planes != inplanes or stride != 1:\n",
    "            self.skip = GhostModule(inplanes, planes, kernel_size=1, stride=stride, relu=False)\n",
    "#             self.skip = nn.Conv2d(inplanes, planes, 1, stride=stride, bias=False)\n",
    "#             self.skipbn = nn.BatchNorm2d(planes)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        filters = inplanes\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "#             rep.append(GhostModule(inplanes, planes, kernel_size=3, stride=1, relu=False, dilation=dilation))\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(planes))\n",
    "            filters = planes\n",
    "\n",
    "        for i in range(reps - 1):\n",
    "            rep.append(self.relu)\n",
    "#             rep.append(GhostModule(filters, filters, kernel_size=3, stride=1, relu=False, dilation=dilation))\n",
    "            rep.append(SeparableConv2d_same(filters, filters, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "#             rep.append(GhostModule(inplanes, planes, kernel_size=3, stride=1, relu=False, dilation=dilation))\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(nn.BatchNorm2d(planes))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "\n",
    "        if stride != 1:\n",
    "            rep.append(GhostModule(planes, planes, kernel_size=3, stride=2, relu=False, batchnorm=False))\n",
    "#             rep.append(SeparableConv2d_same(planes, planes, 3, stride=2))\n",
    "\n",
    "        if stride == 1 and is_last:\n",
    "            rep.append(GhostModule(planes, planes, kernel_size=3, stride=1, relu=False, batchnorm=False))\n",
    "#             rep.append(SeparableConv2d_same(planes, planes, 3, stride=1))\n",
    "\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "#             skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x += skip\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72937f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified Alighed Xception\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes=3, os=16, pretrained=False):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        if os == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "        elif os == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2\n",
    "            exit_block_rates = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        # Entry flow\n",
    "        self.conv1 = GhostModule(inplanes, 32, kernel_size=3, stride=2)\n",
    "#         self.conv1 = nn.Conv2d(inplanes, 32, 3, stride=2, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = GhostModule(32, 64, kernel_size=3, stride=1, relu=False)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1 = Block(64, 128, reps=2, stride=2, start_with_relu=False)\n",
    "        self.block2 = Block(128, 256, reps=2, stride=2, start_with_relu=True, grow_first=True)\n",
    "        self.block3 = Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True,\n",
    "                            is_last=True)\n",
    "\n",
    "        # Middle flow\n",
    "        self.block4  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block5  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block6  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block7  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block8  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block9  = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block10 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block11 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block12 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block13 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block14 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block15 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block16 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block17 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block18 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "        self.block19 = Block(728, 728, reps=3, stride=1, dilation=middle_block_rate, start_with_relu=True, grow_first=True)\n",
    "\n",
    "        # Exit flow\n",
    "        self.block20 = Block(728, 1024, reps=2, stride=1, dilation=exit_block_rates[0],\n",
    "                             start_with_relu=True, grow_first=False, is_last=True)\n",
    "        \n",
    "        \n",
    "        self.conv3 = SeparableConv2d_same(1024, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "        \n",
    "        self.conv4 = SeparableConv2d_same(1536, 1536, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn4 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv5 = SeparableConv2d_same(1536, 2048, 3, stride=1, dilation=exit_block_rates[1])\n",
    "        self.bn5 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        # Init weights\n",
    "        self.__init_weight()\n",
    "\n",
    "        # Load pretrained model\n",
    "        if pretrained:\n",
    "            self.__load_xception_pretrained()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entry flow\n",
    "        x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        # Middle flow\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "        x = self.block13(x)\n",
    "        x = self.block14(x)\n",
    "        x = self.block15(x)\n",
    "        x = self.block16(x)\n",
    "        x = self.block17(x)\n",
    "        x = self.block18(x)\n",
    "        x = self.block19(x)\n",
    "\n",
    "        # Exit flow\n",
    "        x = self.block20(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def __load_xception_pretrained(self):\n",
    "        pretrain_dict = model_zoo.load_url('http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "\n",
    "        for k, v in pretrain_dict.items():\n",
    "            print(k)\n",
    "            if k in state_dict:\n",
    "                if 'pointwise' in k:\n",
    "                    v = v.unsqueeze(-1).unsqueeze(-1)\n",
    "                if k.startswith('block12'):\n",
    "                    model_dict[k.replace('block12', 'block20')] = v\n",
    "                elif k.startswith('block11'):\n",
    "                    model_dict[k.replace('block11', 'block12')] = v\n",
    "                elif k.startswith('conv3'):\n",
    "                    model_dict[k] = v\n",
    "                elif k.startswith('bn3'):\n",
    "                    model_dict[k] = v\n",
    "                    model_dict[k.replace('bn3', 'bn4')] = v\n",
    "                elif k.startswith('conv4'):\n",
    "                    model_dict[k.replace('conv4', 'conv5')] = v\n",
    "                elif k.startswith('bn4'):\n",
    "                    model_dict[k.replace('bn4', 'bn5')] = v\n",
    "                else:\n",
    "                    model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, rate):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if rate == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = rate\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=rate, bias=False)\n",
    "#         self.atrous_convolution = GhostModule(inplanes, planes, kernel_size=kernel_size, stride=1, dilation=rate)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bff330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabv3_plus_ghost(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus_ghost, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.xception_features = Xception(nInputChannels, os, pretrained)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            rates = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            rates = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(2048, 256, rate=rates[0])\n",
    "        self.aspp2 = ASPP_module(2048, 256, rate=rates[1])\n",
    "        self.aspp3 = ASPP_module(2048, 256, rate=rates[2])\n",
    "        self.aspp4 = ASPP_module(2048, 256, rate=rates[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             GhostModule(2048, 256, kernel_size=1, stride=1)\n",
    "#                                              nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "#                                              nn.BatchNorm2d(256),\n",
    "#                                              nn.ReLU()\n",
    "                                            )\n",
    "        self.conv1 = GhostModule(1280, 256, kernel_size=1, stride=1)\n",
    "#         self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = GhostModule(128, 48, kernel_size=1, stride=1)\n",
    "#         self.conv2 = nn.Conv2d(128, 48, 1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(GhostModule(304, 256, kernel_size=3, stride=1),\n",
    "                                       GhostModule(256, 256, kernel_size=3, stride=1),\n",
    "                                       GhostModule(256, n_classes, kernel_size=1, stride=1, relu=False, batchnorm=False)\n",
    "#                                        nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "#                                        nn.BatchNorm2d(256),\n",
    "#                                        nn.ReLU(),\n",
    "#                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "#                                        nn.BatchNorm2d(256),\n",
    "#                                        nn.ReLU(),\n",
    "#                                        nn.Conv2d(256, n_classes, kernel_size=1, stride=1)\n",
    "                                      )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.xception_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "#         low_level_features = self.bn2(low_level_features)\n",
    "#         low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.upsample(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                # torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a50c7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             864\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]              64\n",
      "              ReLU-3         [-1, 32, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "            Conv2d-7         [-1, 64, 256, 256]             576\n",
      "            Conv2d-8        [-1, 128, 256, 256]           8,192\n",
      "SeparableConv2d_same-9        [-1, 128, 256, 256]               0\n",
      "      BatchNorm2d-10        [-1, 128, 256, 256]             256\n",
      "             ReLU-11        [-1, 128, 256, 256]               0\n",
      "             ReLU-12        [-1, 128, 256, 256]               0\n",
      "           Conv2d-13        [-1, 128, 256, 256]           1,152\n",
      "           Conv2d-14        [-1, 128, 256, 256]          16,384\n",
      "SeparableConv2d_same-15        [-1, 128, 256, 256]               0\n",
      "      BatchNorm2d-16        [-1, 128, 256, 256]             256\n",
      "           Conv2d-17        [-1, 128, 128, 128]           1,152\n",
      "           Conv2d-18        [-1, 128, 128, 128]          16,384\n",
      "SeparableConv2d_same-19        [-1, 128, 128, 128]               0\n",
      "           Conv2d-20        [-1, 128, 128, 128]           8,192\n",
      "      BatchNorm2d-21        [-1, 128, 128, 128]             256\n",
      "            Block-22        [-1, 128, 128, 128]               0\n",
      "             ReLU-23        [-1, 128, 128, 128]               0\n",
      "             ReLU-24        [-1, 128, 128, 128]               0\n",
      "           Conv2d-25        [-1, 128, 128, 128]           1,152\n",
      "           Conv2d-26        [-1, 256, 128, 128]          32,768\n",
      "SeparableConv2d_same-27        [-1, 256, 128, 128]               0\n",
      "      BatchNorm2d-28        [-1, 256, 128, 128]             512\n",
      "             ReLU-29        [-1, 256, 128, 128]               0\n",
      "             ReLU-30        [-1, 256, 128, 128]               0\n",
      "           Conv2d-31        [-1, 256, 128, 128]           2,304\n",
      "           Conv2d-32        [-1, 256, 128, 128]          65,536\n",
      "SeparableConv2d_same-33        [-1, 256, 128, 128]               0\n",
      "      BatchNorm2d-34        [-1, 256, 128, 128]             512\n",
      "           Conv2d-35          [-1, 256, 64, 64]           2,304\n",
      "           Conv2d-36          [-1, 256, 64, 64]          65,536\n",
      "SeparableConv2d_same-37          [-1, 256, 64, 64]               0\n",
      "           Conv2d-38          [-1, 256, 64, 64]          32,768\n",
      "      BatchNorm2d-39          [-1, 256, 64, 64]             512\n",
      "            Block-40          [-1, 256, 64, 64]               0\n",
      "             ReLU-41          [-1, 256, 64, 64]               0\n",
      "             ReLU-42          [-1, 256, 64, 64]               0\n",
      "           Conv2d-43          [-1, 256, 64, 64]           2,304\n",
      "           Conv2d-44          [-1, 728, 64, 64]         186,368\n",
      "SeparableConv2d_same-45          [-1, 728, 64, 64]               0\n",
      "      BatchNorm2d-46          [-1, 728, 64, 64]           1,456\n",
      "             ReLU-47          [-1, 728, 64, 64]               0\n",
      "             ReLU-48          [-1, 728, 64, 64]               0\n",
      "           Conv2d-49          [-1, 728, 64, 64]           6,552\n",
      "           Conv2d-50          [-1, 728, 64, 64]         529,984\n",
      "SeparableConv2d_same-51          [-1, 728, 64, 64]               0\n",
      "      BatchNorm2d-52          [-1, 728, 64, 64]           1,456\n",
      "           Conv2d-53          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-54          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-55          [-1, 728, 32, 32]               0\n",
      "           Conv2d-56          [-1, 728, 32, 32]         186,368\n",
      "      BatchNorm2d-57          [-1, 728, 32, 32]           1,456\n",
      "            Block-58          [-1, 728, 32, 32]               0\n",
      "             ReLU-59          [-1, 728, 32, 32]               0\n",
      "             ReLU-60          [-1, 728, 32, 32]               0\n",
      "           Conv2d-61          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-62          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-63          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-64          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-65          [-1, 728, 32, 32]               0\n",
      "             ReLU-66          [-1, 728, 32, 32]               0\n",
      "           Conv2d-67          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-68          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-69          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-70          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-71          [-1, 728, 32, 32]               0\n",
      "             ReLU-72          [-1, 728, 32, 32]               0\n",
      "           Conv2d-73          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-74          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-75          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-76          [-1, 728, 32, 32]           1,456\n",
      "            Block-77          [-1, 728, 32, 32]               0\n",
      "             ReLU-78          [-1, 728, 32, 32]               0\n",
      "             ReLU-79          [-1, 728, 32, 32]               0\n",
      "           Conv2d-80          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-81          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-82          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-83          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-84          [-1, 728, 32, 32]               0\n",
      "             ReLU-85          [-1, 728, 32, 32]               0\n",
      "           Conv2d-86          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-87          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-88          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-89          [-1, 728, 32, 32]           1,456\n",
      "             ReLU-90          [-1, 728, 32, 32]               0\n",
      "             ReLU-91          [-1, 728, 32, 32]               0\n",
      "           Conv2d-92          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-93          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-94          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-95          [-1, 728, 32, 32]           1,456\n",
      "            Block-96          [-1, 728, 32, 32]               0\n",
      "             ReLU-97          [-1, 728, 32, 32]               0\n",
      "             ReLU-98          [-1, 728, 32, 32]               0\n",
      "           Conv2d-99          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-100          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-101          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-102          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-103          [-1, 728, 32, 32]               0\n",
      "            ReLU-104          [-1, 728, 32, 32]               0\n",
      "          Conv2d-105          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-106          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-107          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-108          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-109          [-1, 728, 32, 32]               0\n",
      "            ReLU-110          [-1, 728, 32, 32]               0\n",
      "          Conv2d-111          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-112          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-113          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-114          [-1, 728, 32, 32]           1,456\n",
      "           Block-115          [-1, 728, 32, 32]               0\n",
      "            ReLU-116          [-1, 728, 32, 32]               0\n",
      "            ReLU-117          [-1, 728, 32, 32]               0\n",
      "          Conv2d-118          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-119          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-120          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-121          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-122          [-1, 728, 32, 32]               0\n",
      "            ReLU-123          [-1, 728, 32, 32]               0\n",
      "          Conv2d-124          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-125          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-126          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-127          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-128          [-1, 728, 32, 32]               0\n",
      "            ReLU-129          [-1, 728, 32, 32]               0\n",
      "          Conv2d-130          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-131          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-132          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-133          [-1, 728, 32, 32]           1,456\n",
      "           Block-134          [-1, 728, 32, 32]               0\n",
      "            ReLU-135          [-1, 728, 32, 32]               0\n",
      "            ReLU-136          [-1, 728, 32, 32]               0\n",
      "          Conv2d-137          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-138          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-139          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-140          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-141          [-1, 728, 32, 32]               0\n",
      "            ReLU-142          [-1, 728, 32, 32]               0\n",
      "          Conv2d-143          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-144          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-145          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-146          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-147          [-1, 728, 32, 32]               0\n",
      "            ReLU-148          [-1, 728, 32, 32]               0\n",
      "          Conv2d-149          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-150          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-151          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-152          [-1, 728, 32, 32]           1,456\n",
      "           Block-153          [-1, 728, 32, 32]               0\n",
      "            ReLU-154          [-1, 728, 32, 32]               0\n",
      "            ReLU-155          [-1, 728, 32, 32]               0\n",
      "          Conv2d-156          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-157          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-158          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-159          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-160          [-1, 728, 32, 32]               0\n",
      "            ReLU-161          [-1, 728, 32, 32]               0\n",
      "          Conv2d-162          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-163          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-164          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-165          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-166          [-1, 728, 32, 32]               0\n",
      "            ReLU-167          [-1, 728, 32, 32]               0\n",
      "          Conv2d-168          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-169          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-170          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-171          [-1, 728, 32, 32]           1,456\n",
      "           Block-172          [-1, 728, 32, 32]               0\n",
      "            ReLU-173          [-1, 728, 32, 32]               0\n",
      "            ReLU-174          [-1, 728, 32, 32]               0\n",
      "          Conv2d-175          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-176          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-177          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-178          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-179          [-1, 728, 32, 32]               0\n",
      "            ReLU-180          [-1, 728, 32, 32]               0\n",
      "          Conv2d-181          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-182          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-183          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-184          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-185          [-1, 728, 32, 32]               0\n",
      "            ReLU-186          [-1, 728, 32, 32]               0\n",
      "          Conv2d-187          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-188          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-189          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-190          [-1, 728, 32, 32]           1,456\n",
      "           Block-191          [-1, 728, 32, 32]               0\n",
      "            ReLU-192          [-1, 728, 32, 32]               0\n",
      "            ReLU-193          [-1, 728, 32, 32]               0\n",
      "          Conv2d-194          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-195          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-196          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-197          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-198          [-1, 728, 32, 32]               0\n",
      "            ReLU-199          [-1, 728, 32, 32]               0\n",
      "          Conv2d-200          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-201          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-202          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-203          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-204          [-1, 728, 32, 32]               0\n",
      "            ReLU-205          [-1, 728, 32, 32]               0\n",
      "          Conv2d-206          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-207          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-208          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-209          [-1, 728, 32, 32]           1,456\n",
      "           Block-210          [-1, 728, 32, 32]               0\n",
      "            ReLU-211          [-1, 728, 32, 32]               0\n",
      "            ReLU-212          [-1, 728, 32, 32]               0\n",
      "          Conv2d-213          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-214          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-215          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-216          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-217          [-1, 728, 32, 32]               0\n",
      "            ReLU-218          [-1, 728, 32, 32]               0\n",
      "          Conv2d-219          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-220          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-221          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-222          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-223          [-1, 728, 32, 32]               0\n",
      "            ReLU-224          [-1, 728, 32, 32]               0\n",
      "          Conv2d-225          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-226          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-227          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-228          [-1, 728, 32, 32]           1,456\n",
      "           Block-229          [-1, 728, 32, 32]               0\n",
      "            ReLU-230          [-1, 728, 32, 32]               0\n",
      "            ReLU-231          [-1, 728, 32, 32]               0\n",
      "          Conv2d-232          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-233          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-234          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-235          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-236          [-1, 728, 32, 32]               0\n",
      "            ReLU-237          [-1, 728, 32, 32]               0\n",
      "          Conv2d-238          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-239          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-240          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-241          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-242          [-1, 728, 32, 32]               0\n",
      "            ReLU-243          [-1, 728, 32, 32]               0\n",
      "          Conv2d-244          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-245          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-246          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-247          [-1, 728, 32, 32]           1,456\n",
      "           Block-248          [-1, 728, 32, 32]               0\n",
      "            ReLU-249          [-1, 728, 32, 32]               0\n",
      "            ReLU-250          [-1, 728, 32, 32]               0\n",
      "          Conv2d-251          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-252          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-253          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-254          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-255          [-1, 728, 32, 32]               0\n",
      "            ReLU-256          [-1, 728, 32, 32]               0\n",
      "          Conv2d-257          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-258          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-259          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-260          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-261          [-1, 728, 32, 32]               0\n",
      "            ReLU-262          [-1, 728, 32, 32]               0\n",
      "          Conv2d-263          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-264          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-265          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-266          [-1, 728, 32, 32]           1,456\n",
      "           Block-267          [-1, 728, 32, 32]               0\n",
      "            ReLU-268          [-1, 728, 32, 32]               0\n",
      "            ReLU-269          [-1, 728, 32, 32]               0\n",
      "          Conv2d-270          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-271          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-272          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-273          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-274          [-1, 728, 32, 32]               0\n",
      "            ReLU-275          [-1, 728, 32, 32]               0\n",
      "          Conv2d-276          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-277          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-278          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-279          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-280          [-1, 728, 32, 32]               0\n",
      "            ReLU-281          [-1, 728, 32, 32]               0\n",
      "          Conv2d-282          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-283          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-284          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-285          [-1, 728, 32, 32]           1,456\n",
      "           Block-286          [-1, 728, 32, 32]               0\n",
      "            ReLU-287          [-1, 728, 32, 32]               0\n",
      "            ReLU-288          [-1, 728, 32, 32]               0\n",
      "          Conv2d-289          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-290          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-291          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-292          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-293          [-1, 728, 32, 32]               0\n",
      "            ReLU-294          [-1, 728, 32, 32]               0\n",
      "          Conv2d-295          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-296          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-297          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-298          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-299          [-1, 728, 32, 32]               0\n",
      "            ReLU-300          [-1, 728, 32, 32]               0\n",
      "          Conv2d-301          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-302          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-303          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-304          [-1, 728, 32, 32]           1,456\n",
      "           Block-305          [-1, 728, 32, 32]               0\n",
      "            ReLU-306          [-1, 728, 32, 32]               0\n",
      "            ReLU-307          [-1, 728, 32, 32]               0\n",
      "          Conv2d-308          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-309          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-310          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-311          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-312          [-1, 728, 32, 32]               0\n",
      "            ReLU-313          [-1, 728, 32, 32]               0\n",
      "          Conv2d-314          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-315          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-316          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-317          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-318          [-1, 728, 32, 32]               0\n",
      "            ReLU-319          [-1, 728, 32, 32]               0\n",
      "          Conv2d-320          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-321          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-322          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-323          [-1, 728, 32, 32]           1,456\n",
      "           Block-324          [-1, 728, 32, 32]               0\n",
      "            ReLU-325          [-1, 728, 32, 32]               0\n",
      "            ReLU-326          [-1, 728, 32, 32]               0\n",
      "          Conv2d-327          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-328          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-329          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-330          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-331          [-1, 728, 32, 32]               0\n",
      "            ReLU-332          [-1, 728, 32, 32]               0\n",
      "          Conv2d-333          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-334          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-335          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-336          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-337          [-1, 728, 32, 32]               0\n",
      "            ReLU-338          [-1, 728, 32, 32]               0\n",
      "          Conv2d-339          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-340          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-341          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-342          [-1, 728, 32, 32]           1,456\n",
      "           Block-343          [-1, 728, 32, 32]               0\n",
      "            ReLU-344          [-1, 728, 32, 32]               0\n",
      "            ReLU-345          [-1, 728, 32, 32]               0\n",
      "          Conv2d-346          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-347          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-348          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-349          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-350          [-1, 728, 32, 32]               0\n",
      "            ReLU-351          [-1, 728, 32, 32]               0\n",
      "          Conv2d-352          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-353          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-354          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-355          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-356          [-1, 728, 32, 32]               0\n",
      "            ReLU-357          [-1, 728, 32, 32]               0\n",
      "          Conv2d-358          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-359          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-360          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-361          [-1, 728, 32, 32]           1,456\n",
      "           Block-362          [-1, 728, 32, 32]               0\n",
      "            ReLU-363          [-1, 728, 32, 32]               0\n",
      "            ReLU-364          [-1, 728, 32, 32]               0\n",
      "          Conv2d-365          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-366          [-1, 728, 32, 32]         529,984\n",
      "SeparableConv2d_same-367          [-1, 728, 32, 32]               0\n",
      "     BatchNorm2d-368          [-1, 728, 32, 32]           1,456\n",
      "            ReLU-369          [-1, 728, 32, 32]               0\n",
      "            ReLU-370          [-1, 728, 32, 32]               0\n",
      "          Conv2d-371          [-1, 728, 32, 32]           6,552\n",
      "          Conv2d-372         [-1, 1024, 32, 32]         745,472\n",
      "SeparableConv2d_same-373         [-1, 1024, 32, 32]               0\n",
      "     BatchNorm2d-374         [-1, 1024, 32, 32]           2,048\n",
      "          Conv2d-375         [-1, 1024, 32, 32]           9,216\n",
      "          Conv2d-376         [-1, 1024, 32, 32]       1,048,576\n",
      "SeparableConv2d_same-377         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-378         [-1, 1024, 32, 32]         745,472\n",
      "     BatchNorm2d-379         [-1, 1024, 32, 32]           2,048\n",
      "           Block-380         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-381         [-1, 1024, 32, 32]           9,216\n",
      "          Conv2d-382         [-1, 1536, 32, 32]       1,572,864\n",
      "SeparableConv2d_same-383         [-1, 1536, 32, 32]               0\n",
      "     BatchNorm2d-384         [-1, 1536, 32, 32]           3,072\n",
      "            ReLU-385         [-1, 1536, 32, 32]               0\n",
      "          Conv2d-386         [-1, 1536, 32, 32]          13,824\n",
      "          Conv2d-387         [-1, 1536, 32, 32]       2,359,296\n",
      "SeparableConv2d_same-388         [-1, 1536, 32, 32]               0\n",
      "     BatchNorm2d-389         [-1, 1536, 32, 32]           3,072\n",
      "            ReLU-390         [-1, 1536, 32, 32]               0\n",
      "          Conv2d-391         [-1, 1536, 32, 32]          13,824\n",
      "          Conv2d-392         [-1, 2048, 32, 32]       3,145,728\n",
      "SeparableConv2d_same-393         [-1, 2048, 32, 32]               0\n",
      "     BatchNorm2d-394         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-395         [-1, 2048, 32, 32]               0\n",
      "        Xception-396  [[-1, 2048, 32, 32], [-1, 128, 128, 128]]               0\n",
      "          Conv2d-397          [-1, 256, 32, 32]         524,288\n",
      "     BatchNorm2d-398          [-1, 256, 32, 32]             512\n",
      "            ReLU-399          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-400          [-1, 256, 32, 32]               0\n",
      "          Conv2d-401          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-402          [-1, 256, 32, 32]             512\n",
      "            ReLU-403          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-404          [-1, 256, 32, 32]               0\n",
      "          Conv2d-405          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-406          [-1, 256, 32, 32]             512\n",
      "            ReLU-407          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-408          [-1, 256, 32, 32]               0\n",
      "          Conv2d-409          [-1, 256, 32, 32]       4,718,592\n",
      "     BatchNorm2d-410          [-1, 256, 32, 32]             512\n",
      "            ReLU-411          [-1, 256, 32, 32]               0\n",
      "     ASPP_module-412          [-1, 256, 32, 32]               0\n",
      "AdaptiveAvgPool2d-413           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-414            [-1, 256, 1, 1]         524,288\n",
      "     BatchNorm2d-415            [-1, 256, 1, 1]             512\n",
      "            ReLU-416            [-1, 256, 1, 1]               0\n",
      "          Conv2d-417          [-1, 256, 32, 32]         327,680\n",
      "     BatchNorm2d-418          [-1, 256, 32, 32]             512\n",
      "            ReLU-419          [-1, 256, 32, 32]               0\n",
      "          Conv2d-420         [-1, 48, 128, 128]           6,144\n",
      "     BatchNorm2d-421         [-1, 48, 128, 128]              96\n",
      "            ReLU-422         [-1, 48, 128, 128]               0\n",
      "          Conv2d-423        [-1, 256, 128, 128]         700,416\n",
      "     BatchNorm2d-424        [-1, 256, 128, 128]             512\n",
      "            ReLU-425        [-1, 256, 128, 128]               0\n",
      "          Conv2d-426        [-1, 256, 128, 128]         589,824\n",
      "     BatchNorm2d-427        [-1, 256, 128, 128]             512\n",
      "            ReLU-428        [-1, 256, 128, 128]               0\n",
      "          Conv2d-429          [-1, 1, 128, 128]             257\n",
      "================================================================\n",
      "Total params: 54,607,521\n",
      "Trainable params: 54,607,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 33550644.79\n",
      "Params size (MB): 208.31\n",
      "Estimated Total Size (MB): 33550856.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "deeplab_xcep_ghost = DeepLabv3_plus_ghost(nInputChannels=3, n_classes=1, os=16, pretrained=False, _print=True).eval().cuda()\n",
    "summary(deeplab_xcep,  (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6068d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07524251937866211\n"
     ]
    }
   ],
   "source": [
    "input =torch.randn(1,3,720,960).cuda()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_start = time.time()\n",
    "\n",
    "output = deeplab_xcep_ghost(input)\n",
    "torch.cuda.synchronize()\n",
    "time_end = time.time()\n",
    "infer_time = time_end - time_start\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69fea971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:00<00:05,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 2/13 [00:00<00:04,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 3/13 [00:01<00:04,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 31%|███       | 4/13 [00:01<00:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 38%|███▊      | 5/13 [00:01<00:03,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 62%|██████▏   | 8/13 [00:03<00:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:03<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "FPS: 32.179107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm(range(13)):\n",
    "    inputs, _ = test_dataset[i]\n",
    "    inputs = inputs.cuda().unsqueeze(0)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    predict= deeplab_xcep_ghost(inputs).data\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    res.append(end-start)\n",
    "time_sum = 0\n",
    "for i in res:\n",
    "    time_sum += i\n",
    "    \n",
    "print(\"FPS: %f\"%(1.0/(time_sum/len(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e793743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: module GhostModule is treated as a zero-op.\n",
      "Warning: module SeparableConv2d_same is treated as a zero-op.\n",
      "Warning: module Block is treated as a zero-op.\n",
      "Warning: module Xception is treated as a zero-op.\n",
      "Warning: module ASPP_module is treated as a zero-op.\n",
      "Warning: module DeepLabv3_plus_ghost is treated as a zero-op.\n",
      "DeepLabv3_plus_ghost(\n",
      "  58.854 M, 100.000% Params, 78.535 GMac, 100.000% MACs, \n",
      "  (xception_features): Xception(\n",
      "    43.091 M, 73.216% Params, 52.634 GMac, 67.020% MACs, \n",
      "    (conv1): GhostModule(\n",
      "      0.001 M, 0.001% Params, 0.044 GMac, 0.056% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.0 M, 0.001% Params, 0.031 GMac, 0.040% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.001% Params, 0.028 GMac, 0.036% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.000% Params, 0.013 GMac, 0.016% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.000% Params, 0.009 GMac, 0.012% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.005 GMac, 0.007% MACs, inplace=True)\n",
      "    (conv2): GhostModule(\n",
      "      0.01 M, 0.016% Params, 0.631 GMac, 0.804% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.009 M, 0.016% Params, 0.608 GMac, 0.774% MACs, \n",
      "        (0): Conv2d(0.009 M, 0.016% Params, 0.604 GMac, 0.769% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.001% Params, 0.023 GMac, 0.029% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.000% Params, 0.019 GMac, 0.024% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (block1): Block(\n",
      "      0.106 M, 0.180% Params, 3.072 GMac, 3.912% MACs, \n",
      "      (skip): GhostModule(\n",
      "        0.005 M, 0.008% Params, 0.081 GMac, 0.103% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.004 M, 0.007% Params, 0.069 GMac, 0.088% MACs, \n",
      "          (0): Conv2d(0.004 M, 0.007% Params, 0.067 GMac, 0.085% MACs, 64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.001 M, 0.001% Params, 0.012 GMac, 0.015% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.001% Params, 0.009 GMac, 0.012% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.011% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        0.101 M, 0.172% Params, 2.983 GMac, 3.799% MACs, \n",
      "        (0): SeparableConv2d_same(\n",
      "          0.009 M, 0.015% Params, 0.575 GMac, 0.732% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.001% Params, 0.038 GMac, 0.048% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
      "          (pointwise): Conv2d(0.008 M, 0.014% Params, 0.537 GMac, 0.684% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.017 GMac, 0.021% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.008 GMac, 0.011% MACs, inplace=True)\n",
      "        (3): SeparableConv2d_same(\n",
      "          0.018 M, 0.030% Params, 1.149 GMac, 1.463% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.002% Params, 0.075 GMac, 0.096% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(0.016 M, 0.028% Params, 1.074 GMac, 1.367% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): BatchNorm2d(0.0 M, 0.000% Params, 0.017 GMac, 0.021% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): GhostModule(\n",
      "          0.074 M, 0.126% Params, 1.217 GMac, 1.550% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            0.074 M, 0.125% Params, 1.208 GMac, 1.538% MACs, \n",
      "            (0): Conv2d(0.074 M, 0.125% Params, 1.208 GMac, 1.538% MACs, 128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.001 M, 0.001% Params, 0.009 GMac, 0.012% MACs, \n",
      "            (0): Conv2d(0.001 M, 0.001% Params, 0.009 GMac, 0.012% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block2): Block(\n",
      "      0.417 M, 0.708% Params, 2.983 GMac, 3.799% MACs, \n",
      "      (skip): GhostModule(\n",
      "        0.018 M, 0.031% Params, 0.074 GMac, 0.094% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.017 M, 0.028% Params, 0.068 GMac, 0.087% MACs, \n",
      "          (0): Conv2d(0.016 M, 0.028% Params, 0.067 GMac, 0.085% MACs, 128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.001 M, 0.002% Params, 0.006 GMac, 0.007% MACs, \n",
      "          (0): Conv2d(0.001 M, 0.002% Params, 0.005 GMac, 0.006% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (1): BatchNorm2d(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        0.399 M, 0.678% Params, 2.903 GMac, 3.696% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.034 M, 0.058% Params, 0.556 GMac, 0.708% MACs, \n",
      "          (conv1): Conv2d(0.001 M, 0.002% Params, 0.019 GMac, 0.024% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(0.033 M, 0.056% Params, 0.537 GMac, 0.684% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.006 GMac, 0.008% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.068 M, 0.115% Params, 1.111 GMac, 1.415% MACs, \n",
      "          (conv1): Conv2d(0.002 M, 0.004% Params, 0.038 GMac, 0.048% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(0.066 M, 0.111% Params, 1.074 GMac, 1.367% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): GhostModule(\n",
      "          0.296 M, 0.503% Params, 1.213 GMac, 1.544% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            0.295 M, 0.501% Params, 1.208 GMac, 1.538% MACs, \n",
      "            (0): Conv2d(0.295 M, 0.501% Params, 1.208 GMac, 1.538% MACs, 256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.001 M, 0.002% Params, 0.005 GMac, 0.006% MACs, \n",
      "            (0): Conv2d(0.001 M, 0.002% Params, 0.005 GMac, 0.006% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block3): Block(\n",
      "      3.214 M, 5.461% Params, 5.536 GMac, 7.049% MACs, \n",
      "      (skip): GhostModule(\n",
      "        0.098 M, 0.166% Params, 0.1 GMac, 0.128% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.094 M, 0.160% Params, 0.096 GMac, 0.122% MACs, \n",
      "          (0): Conv2d(0.093 M, 0.158% Params, 0.095 GMac, 0.122% MACs, 256, 364, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 364, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.004 M, 0.007% Params, 0.004 GMac, 0.005% MACs, \n",
      "          (0): Conv2d(0.003 M, 0.006% Params, 0.003 GMac, 0.004% MACs, 364, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=364, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 364, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        3.116 M, 5.295% Params, 5.432 GMac, 6.917% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.189 M, 0.321% Params, 0.773 GMac, 0.984% MACs, \n",
      "          (conv1): Conv2d(0.002 M, 0.004% Params, 0.009 GMac, 0.012% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(0.186 M, 0.317% Params, 0.763 GMac, 0.972% MACs, 256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.006 GMac, 0.008% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 2.198 GMac, 2.798% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.027 GMac, 0.034% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 2.171 GMac, 2.764% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.006 GMac, 0.008% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): GhostModule(\n",
      "          2.388 M, 4.058% Params, 2.446 GMac, 3.114% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            2.385 M, 4.052% Params, 2.442 GMac, 3.110% MACs, \n",
      "            (0): Conv2d(2.385 M, 4.052% Params, 2.442 GMac, 3.110% MACs, 728, 364, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.003 M, 0.006% Params, 0.003 GMac, 0.004% MACs, \n",
      "            (0): Conv2d(0.003 M, 0.006% Params, 0.003 GMac, 0.004% MACs, 364, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=364, bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block4): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block5): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block6): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block7): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block8): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block9): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block10): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block11): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block12): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block13): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block14): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block15): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block16): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block17): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block18): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block19): Block(\n",
      "      1.614 M, 2.742% Params, 1.657 GMac, 2.110% MACs, \n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        1.614 M, 2.742% Params, 1.655 GMac, 2.107% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "        (7): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block20): Block(\n",
      "      6.395 M, 10.865% Params, 6.551 GMac, 8.342% MACs, \n",
      "      (skip): GhostModule(\n",
      "        0.379 M, 0.645% Params, 0.388 GMac, 0.495% MACs, \n",
      "        (primary_conv): Sequential(\n",
      "          0.374 M, 0.635% Params, 0.383 GMac, 0.487% MACs, \n",
      "          (0): Conv2d(0.373 M, 0.633% Params, 0.382 GMac, 0.486% MACs, 728, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "        (cheap_operation): Sequential(\n",
      "          0.006 M, 0.010% Params, 0.006 GMac, 0.007% MACs, \n",
      "          (0): Conv2d(0.005 M, 0.008% Params, 0.005 GMac, 0.006% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "          (1): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "      (rep): Sequential(\n",
      "        6.015 M, 10.221% Params, 6.161 GMac, 7.845% MACs, \n",
      "        (0): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "        (1): SeparableConv2d_same(\n",
      "          0.537 M, 0.912% Params, 0.549 GMac, 0.700% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.53 M, 0.901% Params, 0.543 GMac, 0.691% MACs, 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
      "        (4): SeparableConv2d_same(\n",
      "          0.752 M, 1.278% Params, 0.77 GMac, 0.981% MACs, \n",
      "          (conv1): Conv2d(0.007 M, 0.011% Params, 0.007 GMac, 0.009% MACs, 728, 728, kernel_size=(3, 3), stride=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(0.745 M, 1.267% Params, 0.763 GMac, 0.972% MACs, 728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(0.002 M, 0.003% Params, 0.002 GMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): GhostModule(\n",
      "          4.723 M, 8.025% Params, 4.837 GMac, 6.158% MACs, \n",
      "          (primary_conv): Sequential(\n",
      "            4.719 M, 8.017% Params, 4.832 GMac, 6.152% MACs, \n",
      "            (0): Conv2d(4.719 M, 8.017% Params, 4.832 GMac, 6.152% MACs, 1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "          (cheap_operation): Sequential(\n",
      "            0.005 M, 0.008% Params, 0.005 GMac, 0.006% MACs, \n",
      "            (0): Conv2d(0.005 M, 0.008% Params, 0.005 GMac, 0.006% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "            (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "            (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv3): SeparableConv2d_same(\n",
      "      1.582 M, 2.688% Params, 1.62 GMac, 2.063% MACs, \n",
      "      (conv1): Conv2d(0.009 M, 0.016% Params, 0.009 GMac, 0.012% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1024, bias=False)\n",
      "      (pointwise): Conv2d(1.573 M, 2.672% Params, 1.611 GMac, 2.051% MACs, 1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn3): BatchNorm2d(0.003 M, 0.005% Params, 0.003 GMac, 0.004% MACs, 1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv4): SeparableConv2d_same(\n",
      "      2.373 M, 4.032% Params, 2.43 GMac, 3.094% MACs, \n",
      "      (conv1): Conv2d(0.014 M, 0.023% Params, 0.014 GMac, 0.018% MACs, 1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(2.359 M, 4.009% Params, 2.416 GMac, 3.076% MACs, 1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn4): BatchNorm2d(0.003 M, 0.005% Params, 0.003 GMac, 0.004% MACs, 1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv5): SeparableConv2d_same(\n",
      "      3.16 M, 5.368% Params, 3.235 GMac, 4.120% MACs, \n",
      "      (conv1): Conv2d(0.014 M, 0.023% Params, 0.014 GMac, 0.018% MACs, 1536, 1536, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(3.146 M, 5.345% Params, 3.221 GMac, 4.102% MACs, 1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn5): BatchNorm2d(0.004 M, 0.007% Params, 0.004 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (aspp1): ASPP_module(\n",
      "    0.525 M, 0.892% Params, 0.538 GMac, 0.685% MACs, \n",
      "    (atrous_convolution): Conv2d(0.524 M, 0.891% Params, 0.537 GMac, 0.684% MACs, 2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp2): ASPP_module(\n",
      "    4.719 M, 8.018% Params, 4.833 GMac, 6.153% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.017% Params, 4.832 GMac, 6.152% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp3): ASPP_module(\n",
      "    4.719 M, 8.018% Params, 4.833 GMac, 6.153% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.017% Params, 4.832 GMac, 6.152% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (aspp4): ASPP_module(\n",
      "    4.719 M, 8.018% Params, 4.833 GMac, 6.153% MACs, \n",
      "    (atrous_convolution): Conv2d(4.719 M, 8.017% Params, 4.832 GMac, 6.152% MACs, 2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "    (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  )\n",
      "  (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  (global_avg_pool): Sequential(\n",
      "    0.264 M, 0.448% Params, 0.002 GMac, 0.003% MACs, \n",
      "    (0): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, output_size=(1, 1))\n",
      "    (1): GhostModule(\n",
      "      0.264 M, 0.448% Params, 0.0 GMac, 0.000% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.262 M, 0.446% Params, 0.0 GMac, 0.000% MACs, \n",
      "        (0): Conv2d(0.262 M, 0.445% Params, 0.0 GMac, 0.000% MACs, 2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.002% Params, 0.0 GMac, 0.000% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.002% Params, 0.0 GMac, 0.000% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1): GhostModule(\n",
      "    0.166 M, 0.281% Params, 0.17 GMac, 0.216% MACs, \n",
      "    (primary_conv): Sequential(\n",
      "      0.164 M, 0.279% Params, 0.168 GMac, 0.214% MACs, \n",
      "      (0): Conv2d(0.164 M, 0.278% Params, 0.168 GMac, 0.214% MACs, 1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    )\n",
      "    (cheap_operation): Sequential(\n",
      "      0.001 M, 0.002% Params, 0.002 GMac, 0.002% MACs, \n",
      "      (0): Conv2d(0.001 M, 0.002% Params, 0.001 GMac, 0.002% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (1): BatchNorm2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2): GhostModule(\n",
      "    0.003 M, 0.006% Params, 0.056 GMac, 0.072% MACs, \n",
      "    (primary_conv): Sequential(\n",
      "      0.003 M, 0.005% Params, 0.052 GMac, 0.066% MACs, \n",
      "      (0): Conv2d(0.003 M, 0.005% Params, 0.05 GMac, 0.064% MACs, 128, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "    )\n",
      "    (cheap_operation): Sequential(\n",
      "      0.0 M, 0.000% Params, 0.005 GMac, 0.006% MACs, \n",
      "      (0): Conv2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "      (1): BatchNorm2d(0.0 M, 0.000% Params, 0.001 GMac, 0.001% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (last_conv): Sequential(\n",
      "    0.649 M, 1.102% Params, 10.637 GMac, 13.544% MACs, \n",
      "    (0): GhostModule(\n",
      "      0.352 M, 0.598% Params, 5.769 GMac, 7.346% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.35 M, 0.595% Params, 5.744 GMac, 7.314% MACs, \n",
      "        (0): Conv2d(0.35 M, 0.595% Params, 5.738 GMac, 7.306% MACs, 304, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.002% Params, 0.025 GMac, 0.032% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.002% Params, 0.019 GMac, 0.024% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): GhostModule(\n",
      "      0.297 M, 0.504% Params, 4.863 GMac, 6.193% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.295 M, 0.502% Params, 4.838 GMac, 6.160% MACs, \n",
      "        (0): Conv2d(0.295 M, 0.501% Params, 4.832 GMac, 6.152% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.001 M, 0.002% Params, 0.025 GMac, 0.032% MACs, \n",
      "        (0): Conv2d(0.001 M, 0.002% Params, 0.019 GMac, 0.024% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.003% MACs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): GhostModule(\n",
      "      0.0 M, 0.000% Params, 0.004 GMac, 0.006% MACs, \n",
      "      (primary_conv): Sequential(\n",
      "        0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.000% Params, 0.004 GMac, 0.005% MACs, 256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "      )\n",
      "      (cheap_operation): Sequential(\n",
      "        0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, \n",
      "        (0): Conv2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "        (2): Sequential(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Computational complexity:       78.54 GMac\n",
      "Number of parameters:           58.85 M \n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(deeplab_xcep_ghost, (3, 512, 512), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
